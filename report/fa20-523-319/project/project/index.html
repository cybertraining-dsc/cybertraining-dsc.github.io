<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.83.1"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Detect and classify pathologies in chest X-rays using PyTorch library | Cybertraining</title><meta name=description content="by the Digital Science Center"><meta property="og:title" content="Detect and classify pathologies in chest X-rays using PyTorch library"><meta property="og:description" content="Chest X-rays reveal many diseases. Early detection of disease often improves the survival chance for Patients. It is one of the important tools for Radiologists to detect and identify underlying health conditions. However, they are two major drawbacks. First, it takes time to analyze a radiograph. Second,  Radiologists make errors. Whether it is an error in diagnosis or delay in diagnosis, both outcomes result in a loss of life. With the technological advances in AI, Deep Learning models address these drawbacks. The  Deep Learning models analyze the X-rays like a Radiologist and accurately predict much better than the Radiologists. In our project, first, we develop a Deep Learning model and train our model to use the labels for Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion that corresponds to 5 different diseases, respectively. Second, we test our model's performance: how well our model predicts the diseases. Finally, we visualize our model's performance using the AUC-ROC curve."><meta property="og:type" content="article"><meta property="og:url" content="/report/fa20-523-319/project/project/"><meta property="article:section" content="report"><meta property="article:published_time" content="2021-03-15T00:00:00+00:00"><meta property="article:modified_time" content="2021-03-15T00:00:00+00:00"><meta property="og:site_name" content="Cybertraining"><meta itemprop=name content="Detect and classify pathologies in chest X-rays using PyTorch library"><meta itemprop=description content="Chest X-rays reveal many diseases. Early detection of disease often improves the survival chance for Patients. It is one of the important tools for Radiologists to detect and identify underlying health conditions. However, they are two major drawbacks. First, it takes time to analyze a radiograph. Second,  Radiologists make errors. Whether it is an error in diagnosis or delay in diagnosis, both outcomes result in a loss of life. With the technological advances in AI, Deep Learning models address these drawbacks. The  Deep Learning models analyze the X-rays like a Radiologist and accurately predict much better than the Radiologists. In our project, first, we develop a Deep Learning model and train our model to use the labels for Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion that corresponds to 5 different diseases, respectively. Second, we test our model's performance: how well our model predicts the diseases. Finally, we visualize our model's performance using the AUC-ROC curve."><meta itemprop=datePublished content="2021-03-15T00:00:00+00:00"><meta itemprop=dateModified content="2021-03-15T00:00:00+00:00"><meta itemprop=wordCount content="3344"><meta itemprop=keywords content="project,ai,health,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Detect and classify pathologies in chest X-rays using PyTorch library"><meta name=twitter:description content="Chest X-rays reveal many diseases. Early detection of disease often improves the survival chance for Patients. It is one of the important tools for Radiologists to detect and identify underlying health conditions. However, they are two major drawbacks. First, it takes time to analyze a radiograph. Second,  Radiologists make errors. Whether it is an error in diagnosis or delay in diagnosis, both outcomes result in a loss of life. With the technological advances in AI, Deep Learning models address these drawbacks. The  Deep Learning models analyze the X-rays like a Radiologist and accurately predict much better than the Radiologists. In our project, first, we develop a Deep Learning model and train our model to use the labels for Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion that corresponds to 5 different diseases, respectively. Second, we test our model's performance: how well our model predicts the diseases. Finally, we visualize our model's performance using the AUC-ROC curve."><link rel=preload href=/scss/main.min.f1d8af03c6fdc7a4791232f48aaeeacc2141515c23db240de46e28a072b0be0a.css as=style><link href=/scss/main.min.f1d8af03c6fdc7a4791232f48aaeeacc2141515c23db240de46e28a072b0be0a.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script></head><body class=td-page><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><rect x="198.8952" y="225.1043" style="fill:#5b7fc0" width="122.6266" height="13.8671"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zm7.993 21.8577c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><rect x="198.8952" y="170.69" style="fill:#d95140" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><rect x="199.3456" y="279.5436" style="fill:#56a55c" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><rect x="198.8952" y="333.6497" style="fill:#f1bc42" width="122.6266" height="13.8671"/></g></g></svg></span><span class="text-uppercase font-weight-bold">Cybertraining</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/about/><span>About</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/docs/><i class="fas fa-book"></i><span>Content</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://github.com/cybertraining-dsc/cybertraining-dsc.github.io/ target=_blank><i class="fab fa-github"></i><span>GitHub</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><script>$(function(){$("#td-section-nav a").removeClass("active"),$("#td-section-nav #m-reportfa20-523-319projectproject").addClass("active"),$("#td-section-nav #m-reportfa20-523-319projectproject-li span").addClass("td-sidebar-nav-active-item"),$("#td-section-nav #m-reportfa20-523-319projectproject").parents("li").addClass("active-path"),$("#td-section-nav li.active-path").addClass("show"),$("#td-section-nav li.active-path").children("input").prop('checked',!0),$("#td-section-nav #m-reportfa20-523-319projectproject-li").siblings("li").addClass("show"),$("#td-section-nav #m-reportfa20-523-319projectproject-li").children("ul").children("li").addClass("show"),$("#td-sidebar-menu").toggleClass("d-none")})</script><div id=td-sidebar-menu class="td-sidebar__inner d-none"><form class="td-sidebar__search d-flex align-items-center"><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-docs-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav foldable-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child" id=m-report-li><a href=/report/ class="align-left pl-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-report><span>Reports</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-362project-li><input type=checkbox id=m-reportsu21-reu-362project-check>
<label for=m-reportsu21-reu-362project-check><a href=/report/su21-reu-362/project/ title="Investigating the Classification of Breast Cancer Subtypes using KMeans" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-362project><span>AI in Healthcare</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-378project-li><input type=checkbox id=m-reportsu21-reu-378project-check>
<label for=m-reportsu21-reu-378project-check><a href=/report/su21-reu-378/project/ title="Project: Detection of Autism Spectrum Disorder with a Facial Image using Artificial Intelligence" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-378project><span>Autism Detection</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-377project-li><input type=checkbox id=m-reportsu21-reu-377project-check>
<label for=m-reportsu21-reu-377project-check><a href=/report/su21-reu-377/project/ title="Project: Analyzing the Advantages and Disadvantages of Artificial Intelligence for Breast Cancer Detection in Women" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-377project><span>Breast Cancer Detection</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-369project-li><input type=checkbox id=m-reportsu21-reu-369project-check>
<label for=m-reportsu21-reu-369project-check><a href=/report/su21-reu-369/project/ title="Increasing Cervical Cancer Risk Analysis" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-369project><span>Cervical Cancer</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-365project-li><input type=checkbox id=m-reportsu21-reu-365project-check>
<label for=m-reportsu21-reu-365project-check><a href=/report/su21-reu-365/project/ title="Cyber Attacks Detection Using AI Algorithms" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-365project><span>Cyber Attacks Detection</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-376project-li><input type=checkbox id=m-reportsu21-reu-376project-check>
<label for=m-reportsu21-reu-376project-check><a href=/report/su21-reu-376/project/ title="Report: Dentronics: Classifying Dental Implant Systems by using Automated Deep Learning" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-376project><span>Dentronics</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reporthid-exampleproject-li><input type=checkbox id=m-reporthid-exampleproject-check>
<label for=m-reporthid-exampleproject-check><a href=/report/hid-example/project/ title class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reporthid-exampleproject><span>Example</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-370project-li><input type=checkbox id=m-reportsu21-reu-370project-check>
<label for=m-reportsu21-reu-370project-check><a href=/report/su21-reu-370/project/ title="Report: Aquatic Animals Classification Using AI" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-370project><span>Fish Classification</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-364project-li><input type=checkbox id=m-reportsu21-reu-364project-check>
<label for=m-reportsu21-reu-364project-check><a href=/report/su21-reu-364/project/ title="Project: Hand Tracking with AI" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-364project><span>Hand Tracking</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-366project-li><input type=checkbox id=m-reportsu21-reu-366project-check>
<label for=m-reportsu21-reu-366project-check><a href=/report/su21-reu-366/project/ title="Review: Handwriting Recognition Using AI" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-366project><span>Handwriting</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-372project-li><input type=checkbox id=m-reportsu21-reu-372project-check>
<label for=m-reportsu21-reu-372project-check><a href=/report/su21-reu-372/project/ title="Project: Analyzing Hashimoto disease causes, symptoms and cases improvements using Topic Modeling" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-372project><span>Hashimoto disorder, causes, symptoms and possible cure</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-360project-li><input type=checkbox id=m-reportsu21-reu-360project-check>
<label for=m-reportsu21-reu-360project-check><a href=/report/su21-reu-360/project/ title="Project: Classification of Hyperspectral Images" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-360project><span>Hyperspectral Images</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-371project-li><input type=checkbox id=m-reportsu21-reu-371project-check>
<label for=m-reportsu21-reu-371project-check><a href=/report/su21-reu-371/project/ title="Project: Detecting Multiple Sclerosis Symptoms using AI" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-371project><span>Multiple Sclerosis and AI</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-363project-li><input type=checkbox id=m-reportsu21-reu-363project-check>
<label for=m-reportsu21-reu-363project-check><a href=/report/su21-reu-363/project/ title="Report: AI in Orthodontics" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-363project><span>Orthodontics</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-361project-li><input type=checkbox id=m-reportsu21-reu-361project-check>
<label for=m-reportsu21-reu-361project-check><a href=/report/su21-reu-361/project/ title="Time Series Analysis of Blockchain-Based Cryptocurrency Price Changes" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-361project><span>Time Series Cryptocurrency</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsu21-reu-375project-li><input type=checkbox id=m-reportsu21-reu-375project-check>
<label for=m-reportsu21-reu-375project-check><a href=/report/su21-reu-375/project/ title="Analysis of Covid-19 Vaccination Rates in Different Races" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsu21-reu-375project><span>Vaccination Rate Analysis</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-312projectproject-li><input type=checkbox id=m-reportfa20-523-312projectproject-check>
<label for=m-reportfa20-523-312projectproject-check><a href=/report/fa20-523-312/project/project/ title="Aquatic Toxicity Analysis with the aid of Autonomous Surface Vehicle (ASV)" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-312projectproject><span>ASV</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-328reportreport-li><input type=checkbox id=m-reportfa20-523-328reportreport-check>
<label for=m-reportfa20-523-328reportreport-check><a href=/report/fa20-523-328/report/report/ title="How Big Data has Affected Statistics in Baseball" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-328reportreport><span>Baseball</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-343reportreport-li><input type=checkbox id=m-reportfa20-523-343reportreport-check>
<label for=m-reportfa20-523-343reportreport-check><a href=/report/fa20-523-343/report/report/ title="Predictive Model For Pitches Thrown By Major League Baseball Pitchers" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-343reportreport><span>Baseball</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-317reportreport-li><input type=checkbox id=m-reportfa20-523-317reportreport-check>
<label for=m-reportfa20-523-317reportreport-check><a href=/report/fa20-523-317/report/report/ title="Big Data Analytics in the National Basketball Association" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-317reportreport><span>Basketball</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-329reportreport-li><input type=checkbox id=m-reportfa20-523-329reportreport-check>
<label for=m-reportfa20-523-329reportreport-check><a href=/report/fa20-523-329/report/report/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-329reportreport><span>Big Data in E-Commerce</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-330projectproject-li><input type=checkbox id=m-reportfa20-523-330projectproject-check>
<label for=m-reportfa20-523-330projectproject-check><a href=/report/fa20-523-330/project/project/ title="Big Data Analytics in Brazilian E-Commerce" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-330projectproject><span>Brazilian E-Commerce</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-349projectproject-li><input type=checkbox id=m-reportfa20-523-349projectproject-check>
<label for=m-reportfa20-523-349projectproject-check><a href=/report/fa20-523-349/project/project/ title="Rank Forecasting in Car Racing" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-349projectproject><span>Car Racing</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-334reportreport-li><input type=checkbox id=m-reportfa20-523-334reportreport-check>
<label for=m-reportfa20-523-334reportreport-check><a href=/report/fa20-523-334/report/report/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-334reportreport><span>Change of Internet Capabilities Throughout the World</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsp21-599-355project-li><input type=checkbox id=m-reportsp21-599-355project-check>
<label for=m-reportsp21-599-355project-check><a href=/report/sp21-599-355/project/ title="Project: Chat Bots in Customer Service" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsp21-599-355project><span>Chat Bot</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-342projectproject-li><input type=checkbox id=m-reportfa20-523-342projectproject-check>
<label for=m-reportfa20-523-342projectproject-check><a href=/report/fa20-523-342/project/project/ title="COVID-19 Analysis" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-342projectproject><span>COVID-19</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-332projectproject-li><input type=checkbox id=m-reportfa20-523-332projectproject-check>
<label for=m-reportfa20-523-332projectproject-check><a href=/report/fa20-523-332/project/project/ title="Analyzing the Relationship of Cryptocurrencies with Foriegn Exchange Rates and Global Stock Market Indices" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-332projectproject><span>Cryptocurrencies</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsp21-599-359project-li><input type=checkbox id=m-reportsp21-599-359project-check>
<label for=m-reportsp21-599-359project-check><a href=/report/sp21-599-359/project/ title="Project: Deep Learning in Drug Discovery" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsp21-599-359project><span>Drug Discovery</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-339projectproject-li><input type=checkbox id=m-reportfa20-523-339projectproject-check>
<label for=m-reportfa20-523-339projectproject-check><a href=/report/fa20-523-339/project/project/ title="Big Data Application in E-commerce" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-339projectproject><span>E-commerce</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-314projectproject-li><input type=checkbox id=m-reportfa20-523-314projectproject-check>
<label for=m-reportfa20-523-314projectproject-check><a href=/report/fa20-523-314/project/project/ title="Residential Power Usage Prediction" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-314projectproject><span>Energy consumption</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-340reportreport-li><input type=checkbox id=m-reportfa20-523-340reportreport-check>
<label for=m-reportfa20-523-340reportreport-check><a href=/report/fa20-523-340/report/report/ title="Big Data Applications in the Gaming Industry" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-340reportreport><span>Gaming</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsp21-599-356project-li><input type=checkbox id=m-reportsp21-599-356project-check>
<label for=m-reportsp21-599-356project-check><a href=/report/sp21-599-356/project/ title="Project: Forecasting Natural Gas Demand/Supply" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsp21-599-356project><span>Gas Demand/Supply</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-315reportreport-li><input type=checkbox id=m-reportfa20-523-315reportreport-check>
<label for=m-reportfa20-523-315reportreport-check><a href=/report/fa20-523-315/report/report/ title="Big Data on Gesture Recognition and Machine Learning" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-315reportreport><span>Gesture Recognitio</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-352reportreport-li><input type=checkbox id=m-reportfa20-523-352reportreport-check>
<label for=m-reportfa20-523-352reportreport-check><a href=/report/fa20-523-352/report/report/ title="Big Data in the Healthcare Industry" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-352reportreport><span>Healthcare</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-309projectproject-li><input type=checkbox id=m-reportfa20-523-309projectproject-check>
<label for=m-reportfa20-523-309projectproject-check><a href=/report/fa20-523-309/project/project/ title="Analysis of Various Machine Learning Classification Techniques in Detecting Heart Disease" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-309projectproject><span>Heart Desease</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-323projectproject-li><input type=checkbox id=m-reportfa20-523-323projectproject-check>
<label for=m-reportfa20-523-323projectproject-check><a href=/report/fa20-523-323/project/project/ title="Predicting Hotel Reservation Cancellation Rates" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-323projectproject><span>Hotel reservations</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-326projectproject-li><input type=checkbox id=m-reportfa20-523-326projectproject-check>
<label for=m-reportfa20-523-326projectproject-check><a href=/report/fa20-523-326/project/project/ title="Analysis of Future of Buffalo Breeds and Milk Production Growth in India" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-326projectproject><span>Milk Production</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-341projectproject-li><input type=checkbox id=m-reportfa20-523-341projectproject-check>
<label for=m-reportfa20-523-341projectproject-check><a href=/report/fa20-523-341/project/project/ title="Music Mood Classification" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-341projectproject><span>Music Classification</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-333projectproject-li><input type=checkbox id=m-reportfa20-523-333projectproject-check>
<label for=m-reportfa20-523-333projectproject-check><a href=/report/fa20-523-333/project/project/ title="Does Modern Day Music Lack Uniqueness Compared to Music before the 21st Century" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-333projectproject><span>Music uniquness</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-301projectproject-li><input type=checkbox id=m-reportfa20-523-301projectproject-check>
<label for=m-reportfa20-523-301projectproject-check><a href=/report/fa20-523-301/project/project/ title="NBA Performance and Injury" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-301projectproject><span>NBA</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-308projectproject-li><input type=checkbox id=m-reportfa20-523-308projectproject-check>
<label for=m-reportfa20-523-308projectproject-check><a href=/report/fa20-523-308/project/project/ title="NFL Regular Season Skilled Position Player Performance as a Predictor of Playoff Appearance Overtime" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-308projectproject><span>NFL</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsp21-599-358project-li><input type=checkbox id=m-reportsp21-599-358project-check>
<label for=m-reportsp21-599-358project-check><a href=/report/sp21-599-358/project/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsp21-599-358project><span>Project: Training A Vehicle Using Camera Feed from Vehicle Simulation</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportsp21-599-357project-li><input type=checkbox id=m-reportsp21-599-357project-check>
<label for=m-reportsp21-599-357project-check><a href=/report/sp21-599-357/project/ title="Project: Structural Protein Sequences Classification" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportsp21-599-357project><span>Protein Sequencing</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-304reportreport-li><input type=checkbox id=m-reportfa20-523-304reportreport-check>
<label for=m-reportfa20-523-304reportreport-check><a href=/report/fa20-523-304/report/report/ title="How Big Data Can Eliminate Racial Bias and Structural Discrimination" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-304reportreport><span>Racial bias</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-337projectproject-li><input type=checkbox id=m-reportfa20-523-337projectproject-check>
<label for=m-reportfa20-523-337projectproject-check><a href=/report/fa20-523-337/project/project/ title="Online Store Customer Revenue Prediction" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-337projectproject><span>Revenue Prediction</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-316projectproject-li><input type=checkbox id=m-reportfa20-523-316projectproject-check>
<label for=m-reportfa20-523-316projectproject-check><a href=/report/fa20-523-316/project/project/ title="Sentiment Analysis and Visualization using a US-election dataset for the 2020 Election" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-316projectproject><span>Sentiment</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-305projectproject-li><input type=checkbox id=m-reportfa20-523-305projectproject-check>
<label for=m-reportfa20-523-305projectproject-check><a href=/report/fa20-523-305/project/project/ title="Estimating Soil Moisture Content Using Weather Data" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-305projectproject><span>Soil Moisture</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-331reportreport-li><input type=checkbox id=m-reportfa20-523-331reportreport-check>
<label for=m-reportfa20-523-331reportreport-check><a href=/report/fa20-523-331/report/report/ title="Big Data in Sports Game Predictions and How It is Used in Sports Gambling" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-331reportreport><span>Sports Gambeling</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-313projectproject-li><input type=checkbox id=m-reportfa20-523-313projectproject-check>
<label for=m-reportfa20-523-313projectproject-check><a href=/report/fa20-523-313/project/project/ title="Analyzing LSTM Performance on Predicting the Stock Market for Multiple Time Steps" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-313projectproject><span>Stock MArket</span></a></label></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-reportfa20-523-336projectproject-li><input type=checkbox id=m-reportfa20-523-336projectproject-check>
<label for=m-reportfa20-523-336projectproject-check><a href=/report/fa20-523-336/project/project/ title="Stock Price Reactions to Earnings Announcements" class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-reportfa20-523-336projectproject><span>Stock prices</span></a></label></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"><a href=https://github.com/cybertraining-dsc/fa20-523-319/edit/main/project/project.md target=_blank><i class="fa fa-edit fa-fw"></i> Edit this page</a>
<a id=print href=/report/printview/><i class="fa fa-print fa-fw"></i> Print entire section</a></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#1-introduction>1. Introduction</a></li><li><a href=#2-overview-of-pytorch-library>2. Overview Of PyTorch Library</a></li><li><a href=#3-overview-of-densenet>3. Overview of DenseNet</a><ul><li><a href=#31-dense-blocks>3.1 Dense blocks</a></li><li><a href=#32-transition-layers>3.2 Transition layers</a></li></ul></li><li><a href=#4-overview-of-chexpert-dataset>4. Overview of CheXpert Dataset</a><ul><li><a href=#41-data-collection>4.1 Data Collection</a></li><li><a href=#42-data-labelling>4.2 Data Labelling</a></li><li><a href=#43-label-extraction>4.3 Label Extraction</a></li><li><a href=#44-label-classification>4.4 Label Classification</a></li><li><a href=#45-label-aggregation>4.5 Label Aggregation</a></li></ul></li><li><a href=#5-overview-of-auc-roc-curve>5. Overview Of AUC-ROC Curve</a><ul><li><a href=#51-sensitivitytrue-positive-rate-tpr>5.1 Sensitivity/True Positive Rate (TPR)</a></li><li><a href=#52-false-negative-rate-fnr>5.2 False Negative Rate (FNR)</a></li><li><a href=#53-specificitytrue-negative-rate-tnr>5.3 Specificity/True Negative Rate (TNR)</a></li><li><a href=#54-false-positive-rate-fpr>5.4 False Positive Rate (FPR)</a></li><li><a href=#55-purpose-of-auc-roc-curve>5.5 Purpose of AUC-ROC curve</a></li><li><a href=#56-definition-of-auc-roc>5.6 Definition of AUC-ROC</a></li></ul></li><li><a href=#6-chest-x-rays---multi-image-classification-using-deep-learning-model>6. Chest X-Rays - Multi-Image Classification Using Deep Learning Model</a><ul><li><a href=#61-load-and-split-chest-x-rays-dataset>6.1 Load and split Chest X-rays Dataset</a></li><li><a href=#62-build-and-train-baseline-deep-learning-model>6.2 Build and train baseline Deep Learning model</a></li><li><a href=#63-evaluate-the-model>6.3 Evaluate the model</a></li><li><a href=#64-predict-the-pathologies>6.4 Predict the pathologies</a></li><li><a href=#65-calculate-the-auc-roc-score>6.5 Calculate the AUC-ROC score</a></li></ul></li><li><a href=#7-results-and-analysis>7. Results and Analysis</a></li><li><a href=#8-conclusion>8. Conclusion</a></li><li><a href=#9-future-plans>9. Future Plans</a></li><li><a href=#10-acknowledgements>10. Acknowledgements</a></li><li><a href=#11-references>11. References</a></li><li><a href=#12-appendix>12. Appendix</a><ul><li><a href=#121-project-plan>12.1 Project Plan</a></li></ul></li></ul></nav></div><div class="taxonomy taxonomy-terms-cloud taxo-tags"><h5 class=taxonomy-title>Tag Cloud</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=/tags/report/ data-taxonomy-term=report><span class=taxonomy-label>report</span><span class=taxonomy-count>4</span></a></li><li><a class=taxonomy-term href=/tags/ai/ data-taxonomy-term=ai><span class=taxonomy-label>ai</span><span class=taxonomy-count>65</span></a></li><li><a class=taxonomy-term href=/tags/application/ data-taxonomy-term=application><span class=taxonomy-label>application</span><span class=taxonomy-count>14</span></a></li><li><a class=taxonomy-term href=/tags/assignment/ data-taxonomy-term=assignment><span class=taxonomy-label>assignment</span><span class=taxonomy-count>8</span></a></li><li><a class=taxonomy-term href=/tags/biology/ data-taxonomy-term=biology><span class=taxonomy-label>biology</span><span class=taxonomy-count>2</span></a></li><li><a class=taxonomy-term href=/tags/blockchain/ data-taxonomy-term=blockchain><span class=taxonomy-label>blockchain</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/chocolatey/ data-taxonomy-term=chocolatey><span class=taxonomy-label>chocolatey</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/cloud/ data-taxonomy-term=cloud><span class=taxonomy-label>cloud</span><span class=taxonomy-count>4</span></a></li><li><a class=taxonomy-term href=/tags/cloudmesh/ data-taxonomy-term=cloudmesh><span class=taxonomy-label>cloudmesh</span><span class=taxonomy-count>2</span></a></li><li><a class=taxonomy-term href=/tags/colab/ data-taxonomy-term=colab><span class=taxonomy-label>colab</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/collab/ data-taxonomy-term=collab><span class=taxonomy-label>collab</span><span class=taxonomy-count>10</span></a></li><li><a class=taxonomy-term href=/tags/commerce/ data-taxonomy-term=commerce><span class=taxonomy-label>commerce</span><span class=taxonomy-count>3</span></a></li><li><a class=taxonomy-term href=/tags/communication/ data-taxonomy-term=communication><span class=taxonomy-label>communication</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/comunication/ data-taxonomy-term=comunication><span class=taxonomy-label>comunication</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/contrib/ data-taxonomy-term=contrib><span class=taxonomy-label>contrib</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/covid/ data-taxonomy-term=covid><span class=taxonomy-label>covid</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/cyberattacks/ data-taxonomy-term=cyberattacks><span class=taxonomy-label>cyberattacks</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/cybersecurity/ data-taxonomy-term=cybersecurity><span class=taxonomy-label>cybersecurity</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/data-science/ data-taxonomy-term=data-science><span class=taxonomy-label>data science</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/devops/ data-taxonomy-term=devops><span class=taxonomy-label>devops</span><span class=taxonomy-count>7</span></a></li><li><a class=taxonomy-term href=/tags/dl/ data-taxonomy-term=dl><span class=taxonomy-label>dl</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/download/ data-taxonomy-term=download><span class=taxonomy-label>download</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/energy/ data-taxonomy-term=energy><span class=taxonomy-label>energy</span><span class=taxonomy-count>3</span></a></li><li><a class=taxonomy-term href=/tags/environment/ data-taxonomy-term=environment><span class=taxonomy-label>environment</span><span class=taxonomy-count>3</span></a></li><li><a class=taxonomy-term href=/tags/faq/ data-taxonomy-term=faq><span class=taxonomy-label>FAQ</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/figure/ data-taxonomy-term=figure><span class=taxonomy-label>figure</span><span class=taxonomy-count>2</span></a></li><li><a class=taxonomy-term href=/tags/finance/ data-taxonomy-term=finance><span class=taxonomy-label>finance</span><span class=taxonomy-count>13</span></a></li><li><a class=taxonomy-term href=/tags/git/ data-taxonomy-term=git><span class=taxonomy-label>git</span><span class=taxonomy-count>9</span></a></li><li><a class=taxonomy-term href=/tags/graph/ data-taxonomy-term=graph><span class=taxonomy-label>graph</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/health/ data-taxonomy-term=health><span class=taxonomy-label>health</span><span class=taxonomy-count>19</span></a></li><li><a class=taxonomy-term href=/tags/iot/ data-taxonomy-term=iot><span class=taxonomy-label>IoT</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/jupyter/ data-taxonomy-term=jupyter><span class=taxonomy-label>jupyter</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/kmeans/ data-taxonomy-term=kmeans><span class=taxonomy-label>kmeans</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/lecture/ data-taxonomy-term=lecture><span class=taxonomy-label>lecture</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/lifestle/ data-taxonomy-term=lifestle><span class=taxonomy-label>lifestle</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/lifestyle/ data-taxonomy-term=lifestyle><span class=taxonomy-label>lifestyle</span><span class=taxonomy-count>3</span></a></li><li><a class=taxonomy-term href=/tags/mermaid/ data-taxonomy-term=mermaid><span class=taxonomy-label>mermaid</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/ml/ data-taxonomy-term=ml><span class=taxonomy-label>ml</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/mnist/ data-taxonomy-term=mnist><span class=taxonomy-label>mnist</span><span class=taxonomy-count>10</span></a></li><li><a class=taxonomy-term href=/tags/mobility/ data-taxonomy-term=mobility><span class=taxonomy-label>mobility</span><span class=taxonomy-count>2</span></a></li><li><a class=taxonomy-term href=/tags/module/ data-taxonomy-term=module><span class=taxonomy-label>module</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/nlp/ data-taxonomy-term=nlp><span class=taxonomy-label>nlp</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/notebook/ data-taxonomy-term=notebook><span class=taxonomy-label>notebook</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/nvidia/ data-taxonomy-term=nvidia><span class=taxonomy-label>nvidia</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/physics/ data-taxonomy-term=physics><span class=taxonomy-label>physics</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/plotviz/ data-taxonomy-term=plotviz><span class=taxonomy-label>plotviz</span><span class=taxonomy-count>2</span></a></li><li><a class=taxonomy-term href=/tags/project/ data-taxonomy-term=project><span class=taxonomy-label>project</span><span class=taxonomy-count>47</span></a></li><li><a class=taxonomy-term href=/tags/pycharm/ data-taxonomy-term=pycharm><span class=taxonomy-label>pycharm</span><span class=taxonomy-count>2</span></a></li><li><a class=taxonomy-term href=/tags/python/ data-taxonomy-term=python><span class=taxonomy-label>python</span><span class=taxonomy-count>35</span></a></li><li><a class=taxonomy-term href=/tags/radar/ data-taxonomy-term=radar><span class=taxonomy-label>radar</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/report/ data-taxonomy-term=report><span class=taxonomy-label>report</span><span class=taxonomy-count>14</span></a></li><li><a class=taxonomy-term href=/tags/rest/ data-taxonomy-term=rest><span class=taxonomy-label>rest</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/reu/ data-taxonomy-term=reu><span class=taxonomy-label>reu</span><span class=taxonomy-count>27</span></a></li><li><a class=taxonomy-term href=/tags/sensor/ data-taxonomy-term=sensor><span class=taxonomy-label>sensor</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/space/ data-taxonomy-term=space><span class=taxonomy-label>space</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/sport/ data-taxonomy-term=sport><span class=taxonomy-label>sport</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/sports/ data-taxonomy-term=sports><span class=taxonomy-label>sports</span><span class=taxonomy-count>7</span></a></li><li><a class=taxonomy-term href=/tags/ssh/ data-taxonomy-term=ssh><span class=taxonomy-label>ssh</span><span class=taxonomy-count>2</span></a></li><li><a class=taxonomy-term href=/tags/statistics/ data-taxonomy-term=statistics><span class=taxonomy-label>statistics</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/transportation/ data-taxonomy-term=transportation><span class=taxonomy-label>transportation</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/tutorial/ data-taxonomy-term=tutorial><span class=taxonomy-label>tutorial</span><span class=taxonomy-count>11</span></a></li><li><a class=taxonomy-term href=/tags/usecases/ data-taxonomy-term=usecases><span class=taxonomy-label>usecases</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/venv/ data-taxonomy-term=venv><span class=taxonomy-label>venv</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=/tags/web/ data-taxonomy-term=web><span class=taxonomy-label>web</span><span class=taxonomy-count>1</span></a></li></ul></div><div class="taxonomy taxonomy-terms-cloud taxo-categories"><h5 class=taxonomy-title>Cloud of Categories</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=/categories/sample/ data-taxonomy-term=sample><span class=taxonomy-label>sample</span><span class=taxonomy-count>4</span></a></li></ul></div></aside><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><nav aria-label=breadcrumb class="d-none d-md-block d-print-none"><ol class="breadcrumb spb-1"><li class=breadcrumb-item><a href=/report/>Reports</a></li><li class="breadcrumb-item active" aria-current=page><a href=/report/fa20-523-319/project/project/>X-rays</a></li></ol></nav><div class=td-content><h1>Detect and classify pathologies in chest X-rays using PyTorch library</h1><div class=lead>Chest X-rays reveal many diseases. Early detection of disease often improves the survival chance for Patients. It is one of the important tools for Radiologists to detect and identify underlying health conditions. However, they are two major drawbacks. First, it takes time to analyze a radiograph. Second, Radiologists make errors. Whether it is an error in diagnosis or delay in diagnosis, both outcomes result in a loss of life. With the technological advances in AI, Deep Learning models address these drawbacks. The Deep Learning models analyze the X-rays like a Radiologist and accurately predict much better than the Radiologists. In our project, first, we develop a Deep Learning model and train our model to use the labels for Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion that corresponds to 5 different diseases, respectively. Second, we test our model&rsquo;s performance: how well our model predicts the diseases. Finally, we visualize our model&rsquo;s performance using the AUC-ROC curve.</div><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-tags"><h5 class=taxonomy-title>Tags:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=/tags/project/ data-taxonomy-term=project><span class=taxonomy-label>project</span></a></li><li><a class=taxonomy-term href=/tags/ai/ data-taxonomy-term=ai><span class=taxonomy-label>ai</span></a></li><li><a class=taxonomy-term href=/tags/health/ data-taxonomy-term=health><span class=taxonomy-label>health</span></a></li></ul></div><p class=reading-time><i class="fa fa-clock" aria-hidden=true></i> 16 minute read</p></header><p><a href=https://github.com/cybertraining-dsc/fa20-523-319/actions><img src=https://github.com/cybertraining-dsc/fa20-523-319/workflows/Check%20Report/badge.svg alt="Check Report"></a>
<a href=https://github.com/cybertraining-dsc/fa20-523-319/actions><img src=https://github.com/cybertraining-dsc/fa20-523-319/workflows/Status/badge.svg alt=Status></a>
Status: final</p><p>Rama Asuri, <a href=https://github.com/cybertraining-dsc/fa20-523-319/>fa20-523-319</a>, <a href=https://github.com/cybertraining-dsc/fa20-523-319/blob/main/project/project.md>Edit</a></p><p>Code: <a href=https://github.com/cybertraining-dsc/fa20-523-319/blob/main/project/project.ipynb>project.ipynb</a></p><div class="pageinfo pageinfo-primary"><h2 id=abstract>Abstract</h2><p>Chest X-rays reveal many diseases. Early detection of disease often improves the survival chance for Patients. It is one of the important tools for Radiologists to detect and identify underlying health conditions. However, they are two major drawbacks. First, it takes time to analyze a radiograph. Second, Radiologists make errors. Whether it is an error in diagnosis or delay in diagnosis, both outcomes result in a loss of life. With the technological advances in AI, Deep Learning models address these drawbacks. The Deep Learning models analyze the X-rays like a Radiologist and accurately predict much better than the Radiologists. In our project, first, we develop a Deep Learning model and train our model to use the labels for Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion that corresponds to 5 different diseases, respectively. Second, we test our model&rsquo;s performance: how well our model predicts the diseases. Finally, we visualize our model&rsquo;s performance using the AUC-ROC curve.</p><p>Contents</p><div class=toc><nav id=TableOfContents><ul><li><a href=#1-introduction>1. Introduction</a></li><li><a href=#2-overview-of-pytorch-library>2. Overview Of PyTorch Library</a></li><li><a href=#3-overview-of-densenet>3. Overview of DenseNet</a><ul><li><a href=#31-dense-blocks>3.1 Dense blocks</a></li><li><a href=#32-transition-layers>3.2 Transition layers</a></li></ul></li><li><a href=#4-overview-of-chexpert-dataset>4. Overview of CheXpert Dataset</a><ul><li><a href=#41-data-collection>4.1 Data Collection</a></li><li><a href=#42-data-labelling>4.2 Data Labelling</a></li><li><a href=#43-label-extraction>4.3 Label Extraction</a></li><li><a href=#44-label-classification>4.4 Label Classification</a></li><li><a href=#45-label-aggregation>4.5 Label Aggregation</a></li></ul></li><li><a href=#5-overview-of-auc-roc-curve>5. Overview Of AUC-ROC Curve</a><ul><li><a href=#51-sensitivitytrue-positive-rate-tpr>5.1 Sensitivity/True Positive Rate (TPR)</a></li><li><a href=#52-false-negative-rate-fnr>5.2 False Negative Rate (FNR)</a></li><li><a href=#53-specificitytrue-negative-rate-tnr>5.3 Specificity/True Negative Rate (TNR)</a></li><li><a href=#54-false-positive-rate-fpr>5.4 False Positive Rate (FPR)</a></li><li><a href=#55-purpose-of-auc-roc-curve>5.5 Purpose of AUC-ROC curve</a></li><li><a href=#56-definition-of-auc-roc>5.6 Definition of AUC-ROC</a></li></ul></li><li><a href=#6-chest-x-rays---multi-image-classification-using-deep-learning-model>6. Chest X-Rays - Multi-Image Classification Using Deep Learning Model</a><ul><li><a href=#61-load-and-split-chest-x-rays-dataset>6.1 Load and split Chest X-rays Dataset</a></li><li><a href=#62-build-and-train-baseline-deep-learning-model>6.2 Build and train baseline Deep Learning model</a></li><li><a href=#63-evaluate-the-model>6.3 Evaluate the model</a></li><li><a href=#64-predict-the-pathologies>6.4 Predict the pathologies</a></li><li><a href=#65-calculate-the-auc-roc-score>6.5 Calculate the AUC-ROC score</a></li></ul></li><li><a href=#7-results-and-analysis>7. Results and Analysis</a></li><li><a href=#8-conclusion>8. Conclusion</a></li><li><a href=#9-future-plans>9. Future Plans</a></li><li><a href=#10-acknowledgements>10. Acknowledgements</a></li><li><a href=#11-references>11. References</a></li><li><a href=#12-appendix>12. Appendix</a><ul><li><a href=#121-project-plan>12.1 Project Plan</a></li></ul></li></ul></nav></div></div><p><strong>Keywords:</strong> PyTorch, CheXpert</p><h2 id=1-introduction>1. Introduction</h2><p>Radiologists widely use chest X-Rays to identify and detect underlying conditions. However, analyzing Chest X-Rays takes too much time, and accurately diagnosing without errors requires considerable experience. On the one hand, if the analyzing process is expedited, it might result in misdiagnosis, but on the other hand, lack of experience means long analysis time and/or errors; even with the correct diagnosis, it might be too late to prescribe a treatment. Radiologists are up against time and experience. With the advancements in AI, Deep Learning can easily solve this problem quickly and efficiently.</p><p>Deep Learning methods are becoming very reliable at achieving expert-level performance using large labeled datasets. Deep learning is a technique to extract and transform data using multiple layers of neural networks. Each layer takes inputs from previous layers and incrementally refines it. An algorithm is used to train these layers to minimize errors and improve these layers' overall accuracy <sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. It enables the network to learn to perform a specified task and gain an expert level performance by training on large datasets. The scope of this project is to identify and detect the following 5 pathologies using an image classification algorithm: Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion. We use the CheXpert dataset, which consists of Chest X-rays. CheXpert dataset contains 224,316 chest Radiographs of 65,240 patients. The dataset has 14 observations in radiology reports and captures uncertainties inherent in radiograph interpretation using uncertainty labels. Our focus is on 5 observations (Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion). We impute uncertainty labels with randomly selected Boolean values. Our Deep Learning models are developed using the PyTorch library, enabling fast, flexible experimentation and efficient production through a user-friendly front-end, distributed training, and ecosystem of tools and libraries <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. It was primarily developed by Facebook&rsquo;s AI Research lab (FAIR) and used for Computer Vision and NLP applications. PyTorch supports Python and C++ interfaces. There are popular Deep Learning applications built using PyTorch, including Tesla Autopilot, Uber&rsquo;s Pyro <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup>.</p><p>In this analysis, first, we begin with an overview of the PyTorch library and DenseNet. We cover DenseNet architecture and advantages over ResNet for Multi-Image classification problems. Second, we explain the CheXpert dataset and how the classifiers are labeled, including uncertainties. Next, we cover the AUC-ROC curve&rsquo;s basic definitions and how it measures a model&rsquo;s performance. Finally, we explain how our Deep Learning model classifies pathologies and conclude with our model&rsquo;s performance and results.</p><h2 id=2-overview-of-pytorch-library>2. Overview Of PyTorch Library</h2><p>The PyTorch library is based on Python and is used for developing Python deep learning models. Many of the early adopters of the PyTorch are from the research community. It grew into one of the most popular libraries for deep learning projects. PyTorch provides great insight into Deep Learning. PyTorch is widely used in real-world applications. PyTorch makes an excellent choice for introducing deep learning because of clear syntax, streamlined API, and easy debugging. PyTorch provides a core data structure, the tensor, a multidimensional array similar to NumPy arrays. It performs accelerated mathematical operations on dedicated hardware, making it convenient to design neural network architectures and train them on individual machines or parallel computing resources <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup>.</p><h2 id=3-overview-of-densenet>3. Overview of DenseNet</h2><p>We use a pre-trained DenseNet model, which classifies the images. DenseNet is new Convolutional Neural Network architecture which is efficient on image classification benchmarks as compared to ResNet <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>. RestNets, Highway networks, and deep and wide neural networks add more inter-layer connections than the direct connection in adjacent layers to boost information flow and layers. Similar to ResNet, DenseNet adds shortcuts among layers. Different from ResNet, a layer in dense receives all the outputs of previous layers and concatenate them in the depth dimension. In ResNet, a layer only receives outputs from the last two layers, and the outputs are added together on the individual same depth. Therefore it will not change the depth by adding shortcuts. In other words, in ResNet the output of layer of k is x[k] = f(w * x[k-1] + x[k-2]), while in DenseNet it is x[k] = f(w * H(x[k-1], x[k-2], &mldr; x[1])) where H means stacking over the depth dimension. Besides, ResNet makes learn the identity function easy, while DenseNet directly adds an identity function <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>.</p><p>Figure 1 shows the DenseNet architecture.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/densetnet.png alt="Figure 1"></p><p><strong>Figure 1:</strong> DenseNet Architecture <sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup></p><p>As shown in Figure 1, DenseNet contains a feature layer (convolutional layer) capturing low-level features from images, several dense blocks, and transition layers between adjacent dense blocks <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup>.</p><h3 id=31-dense-blocks>3.1 Dense blocks</h3><p>Dense block contains several dense layers. The depth of a dense layer output is called growth_rate. Every dense layer receives all the output of its previous layers. The input depth for the kth layer is (k-1)*growth_rate + input_depth_of_first_layer. By adding more layers in a dense block, the depth will grow linearly. For example, if the growth rate is 30 and after 100 layers, the depth will be over 3000. However, this could lead to a computational explosion. It is addressed by introducing a transition layer to reduce and abstract the features after a dense block with a limited number of dense layers to circumvent this problem <sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup>. A 1x1 convolutional layer (bottleneck layer) is added to reduce the computation, which makes the second convolutional layer always has a fixed input depth. It is also easy to see the size (width and height) of the feature maps keeps the same through the dense layer, making it easy to stack any number of dense layers together to build a dense block. For example, densenet121 has four dense blocks with 6, 12, 24, and 16 dense layers. With repetition, it is not that difficult to make 112 layers <sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup>.</p><h3 id=32-transition-layers>3.2 Transition layers</h3><p>In general, the size of every layer&rsquo;s output in Convolutional Neural Network decreases to abstract higher-level features. In DenseNet, the transition layers take this responsibility while the dense blocks keep the size and depth. Every transition layer contains a 1x1 convolutional layer and a 2x2 average pooling layer to reduce the size to half. However, transition layers also receive all the output from all the last dense block layers. So the 1*1 convolutional layer reduces the depth to a fixed number, while the average pooling reduces the size.</p><h2 id=4-overview-of-chexpert-dataset>4. Overview of CheXpert Dataset</h2><p>CheXpert is a large public dataset. It contains an interpreted chest radiograph consisting of 224,316 chest radiographs
of 65,240 patients labeled for the presence of 14 observations as positive, negative, or uncertain <sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup>.</p><p>Figure 2 shows the CheXpert 14 labels and the Probability <sup id=fnref:9><a href=#fn:9 class=footnote-ref role=doc-noteref>9</a></sup>. Our analysis is to predict the probability of 5 different observations (Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion) from multi-view chest radiographs shown in Figure 2</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/chest_disease.png alt="Figure 2"></p><p><strong>Figure 2:</strong> Probability of different observations <sup id=fnref:9><a href=#fn:9 class=footnote-ref role=doc-noteref>9</a></sup>.</p><h3 id=41-data-collection>4.1 Data Collection</h3><p>CheXpert dataset is a collection of chest radiographic studies from Stanford Hospital, performed between October 2002 and July 2017 in inpatient and outpatient centers, along with their associated radiology reports. Based on studies, a sampled set of 1000 reports were created for manual review by a board-certified radiologist to determine the feasibility for extraction of observations. The final set consists of 14 observations based on the prevalence in the reports and clinical relevance, conforming to the Fleischner Societys recommended glossary. <em>Pneumonia</em>, despite
being a clinical diagnosis, <em>Pneumonia</em> was included as a label to represent the images that suggested primary infection as the diagnosis. The <em>No Finding</em> observation was intended to capture the absence of all pathologies <sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup>.</p><h3 id=42-data-labelling>4.2 Data Labelling</h3><p>Labels developed using an automated, rule-based labeler to extract observations from the free text radiology reports to be used as structured labels for the images <sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup>.</p><h3 id=43-label-extraction>4.3 Label Extraction</h3><p>The labeler extracts the pathologies mentioned in the list of observations from the Impression section of radiology reports, summarizing the key findings in the radiographic study. Multiple board-certified radiologists manually curated a large list of phrases to match various observations mentioned in the reports <sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup>.</p><h3 id=44-label-classification>4.4 Label Classification</h3><p>Labeler extracts the mentions of observations and classify them as negative (&ldquo;no evidence of pulmonary edema, pleural effusions or pneumothorax&rdquo;), uncertain (&ldquo;diffuse reticular pattern may represent mild interstitial pulmonary edema&rdquo;), or positive (&ldquo;moderate bilateral effusions and bibasilar opacities&rdquo;). The &lsquo;uncertain&rsquo; label can capture both the uncertainty of a radiologist in the diagnosis as well as the ambiguity inherent in the report (&ldquo;heart size is stable&rdquo;). The mention classification stage is a 3-phase pipeline consisting of pre-negation uncertainty, negation, and post-negation uncertainty. Each phase consists of rules that are matched against the mention; if a match is found, the mention is classified accordingly (as uncertain in the first or third phase and as negative in the second phase). If a mention is not matched in any of the phases, it is classified as positive <sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup>.</p><h3 id=45-label-aggregation>4.5 Label Aggregation</h3><p>CheXpert dataset use the classification for each mention of observations to arrive at a final label for 14 observations that consist of 12 pathologies and the &ldquo;Support Devices&rdquo; and &ldquo;No Finding&rdquo; observations. Observations with at least one mention positively classified in the report are assigned a positive (1) label. An observation is assigned an uncertain (u) label if it has no positively classified mentions and at least one uncertain mention, and a negative label if there is at least one negatively classified mention. We assign (blank) if there is no mention of an observation. The &ldquo;No Finding&rdquo; observation is assigned a positive label (1) if there is no pathology classified as positive or uncertain <sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup>.</p><h2 id=5-overview-of-auc-roc-curve>5. Overview Of AUC-ROC Curve</h2><p>AUC-ROC stands for Area Under Curve - Receiver Operating Characteristics. It visualizes how well a machine learning classifier is performing. However, it works for only binary classification problems <sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>. In our project, we extend it to evaluate Multi-Image classification problem. AUC-ROC curve is a performance measurement for classification problems at various threshold settings. ROC is a probability curve, and AUC represents the degree or measure of separability. Higher the AUC, the better the model is at predicting 0s as 0s and 1s as 1s. By analogy, the Higher the AUC, the model distinguishes between patients with the disease and no disease <sup id=fnref:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup>.</p><p>Figure 3 shows Confusion Matrix. We use Confusion Matrix to explain Sensitivity and Specificity.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/confusion_matrix.png alt="Figure 3"></p><p><strong>Figure 3:</strong> Confusion Matrix</p><h3 id=51-sensitivitytrue-positive-rate-tpr>5.1 Sensitivity/True Positive Rate (TPR)</h3><p>Sensitivity/True Positive Rate (TPR) explains what proportion of the positive class got correctly classified. A simple example would be determining what proportion of the actual sick people are correctly detected by the model <sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/TPR.png alt="Figure 4"></p><h3 id=52-false-negative-rate-fnr>5.2 False Negative Rate (FNR)</h3><p>False Negative Rate (FNR) explains what proportion of the positive class is incorrectly classified by the classifier. A higher TPR and a lower FNR means correctly classify the positive class <sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/FNR.png alt="Figure 5"></p><h3 id=53-specificitytrue-negative-rate-tnr>5.3 Specificity/True Negative Rate (TNR)</h3><p>Specificity/True Negative Rate (TNR) indicates what proportion of the negative class is classified correctly. For example, Specificity determines what proportion of actual healthy people are correctly classified as healthy by the model <sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/TNR.png alt="Figure 6"></p><h3 id=54-false-positive-rate-fpr>5.4 False Positive Rate (FPR)</h3><p>False Positive Rate (FPR) indicates what proportion of the negative class got incorrectly classified by the classifier. A higher TNR and a lower FPR means the model correctly classifies the negative class<sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/FPR.png alt="Figure 7"></p><h3 id=55-purpose-of-auc-roc-curve>5.5 Purpose of AUC-ROC curve</h3><p>A machine learning classification model can predict the actual class of the data point directly or predict its probability of belonging to different classes. The example for the former case is where a model can classify whether a patient is healthy or not healthy. In the latter case, a model can predict a patient&rsquo;s probability of being healthy or not healthy and provide more control over the result by enabling a way to tune the model&rsquo;s behavior by changing the threshold values. This is powerful because it eliminates the possibility of building a completely new model to achieve a different range of results <sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>. A threshold value helps to interpret the probability and map the probability to a class label. For example, a threshold value such as 0.5, where all values equal to or greater than the threshold, is mapped to one class and rests to another class <sup id=fnref:12><a href=#fn:12 class=footnote-ref role=doc-noteref>12</a></sup>.</p><p>Introducing different thresholds for classifying positive class for data points will inadvertently change the Sensitivity and Specificity of the model. Furthermore, one of these thresholds will probably give a better result than the others, depending on whether we aim to lower the number of False Negatives or False Positives <sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>.
As seen in Figure 8, the metrics change with the changing threshold values. We can generate different confusion matrices and compare the various metrics. However, it is very inefficient. Instead, we can generate a plot between some of these metrics so that we can easily visualize which threshold is giving us a better result. The AUC-ROC curve solves just that <sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/aucroc.png alt="Figure 8"></p><p><strong>Figure 8:</strong> Probability of prediction and metrics <sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>.</p><h3 id=56-definition-of-auc-roc>5.6 Definition of AUC-ROC</h3><p>The Receiver Operator Characteristic (ROC) curve is an evaluation metric for binary classification problems. It is a probability curve that plots the TPR against FPR at various threshold values and essentially separates the signal from the noise. The Area Under the Curve (AUC) is the measure of a classifier&rsquo;s ability to distinguish between classes and is used as a summary of the ROC curve. The higher the AUC, the better the model&rsquo;s performance at distinguishing between the positive and negative classes. When AUC = 1, the classifier can perfectly distinguish between all the Positive and the Negative class points correctly. If, however, the AUC had been 0, then the classifier would be predicting all Negatives as Positives and all Positives as Negatives. When 0.5&lt;AUC&lt;1, there is a high chance that the classifier will be able to distinguish the positive class values from the negative class values. This is because the classifier can detect more True positives and True negatives than False negatives and False positives. When AUC=0.5, then the classifier is not able to distinguish between Positive and Negative class points. It means either the classifier is predicting random class or constant class for all the data points. Therefore, the higher the AUC value for a classifier, the better its ability to distinguish between positive and negative classes. In the AUC-ROC curve, a higher X-axis value indicates a higher number of False positives than True negatives. Simultaneously, a higher Y-axis value indicates a higher number of True positives than False negatives. So, the choice of the threshold depends on balancing between False positives and False negatives <sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup>.</p><h2 id=6-chest-x-rays---multi-image-classification-using-deep-learning-model>6. Chest X-Rays - Multi-Image Classification Using Deep Learning Model</h2><p>Our Deep Learning model loads and processes the raw data files and implement a Python class to represent data by
converting it into a format usable by PyTorch. We then, visualize the training and validation data.</p><p>Our approach to predicting pathologies will have 5 steps.</p><ul><li>Load and split Chest X-rays Dataset</li><li>Build and train baseline Deep Learning model</li><li>Evaluate the model</li><li>Predict the pathologies</li><li>Calculate the AUC-ROC score</li></ul><h3 id=61-load-and-split-chest-x-rays-dataset>6.1 Load and split Chest X-rays Dataset</h3><p>We load and split the dataset to 90% for training and 10% for validation randomly.</p><h3 id=62-build-and-train-baseline-deep-learning-model>6.2 Build and train baseline Deep Learning model</h3><p>We use the PyTorch library to implement and train DenseNet CNN as a baseline model. With initial weights from ImageNet, we retrain all layers. In PyTorch, we implement a subclass for the PyTorch to transform CheXpert Dataset and create a custom data loading process. The Image Augmentation is executed within this subclass. Additionally, a DataLoader also needs to be created. We shuffle the dataset for the training dataloader. We also create a validation dataloader, which is different from the training dataloader and does not require shuffling. In the baseline model, we use DenseNet pre-trained on the ImageNet dataset. The model&rsquo;s classifier is replaced with a new dense layer and use the CheXpert labels to train <sup id=fnref:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup>. The number of trainable parameters 6968206 (~7 million).</p><h3 id=63-evaluate-the-model>6.3 Evaluate the model</h3><p>To evaluate the model, we implement a function to validate the model on the validation dataset.</p><h3 id=64-predict-the-pathologies>6.4 Predict the pathologies</h3><p>We use our model to predict 1 of the 5 pathologies - Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion. Our model uses a test dataset.</p><h3 id=65-calculate-the-auc-roc-score>6.5 Calculate the AUC-ROC score</h3><p>We have multiple labels, and we need to calculate the AUCROC-score for each class against the rest of the classifiers.</p><h2 id=7-results-and-analysis>7. Results and Analysis</h2><p>Figure 9 shows training loss, Validation loss and validation AUC-ROC score after training our Deep Learning model for 7 hours.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/Train.png alt="Figure 9"></p><p><strong>Figure 9:</strong> Training loss, Validation loss and validation AUC-ROC score</p><p>Figure 10 shows model predicts False Positives. Below is AUCROC table.
<img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/roc.png alt="Figure 10"></p><p><strong>Figure 10:</strong> AUC - ROC data</p><p>This graph is taken from Stanford CheXpert dataset. Based on Figure 11 <sup id=fnref:13><a href=#fn:13 class=footnote-ref role=doc-noteref>13</a></sup>, our AUCROC value is around 85%.</p><p><img src=https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/aucroc_stanford.png alt="Figure 11"></p><p><strong>Figure 11:</strong> AUC - ROC Curve <sup id=fnref:13><a href=#fn:13 class=footnote-ref role=doc-noteref>13</a></sup></p><h2 id=8-conclusion>8. Conclusion</h2><p>Our model achieves the best AUC on Edema (0.89) and the worst on Plural(0.65). The AUC of all other observations is around 0.78. Our model achieves above 0.65 overall predictions.</p><h2 id=9-future-plans>9. Future Plans</h2><p>As the next steps, we will work to improve the model&rsquo;s algorithm and leverage DenseNet architecture to train using smaller dataset.</p><h2 id=10-acknowledgements>10. Acknowledgements</h2><p>The author would like to thank Dr. Gregor Von Laszewski, Dr. Geoffrey Fox, and the associate instructors for providing continuous guidance and feedback for this final project.</p><h2 id=11-references>11. References</h2><h2 id=12-appendix>12. Appendix</h2><h3 id=121-project-plan>12.1 Project Plan</h3><ul><li>October 26, 2020<ul><li>Test train and validate functionality on PyTorch Dataset</li><li>Update Project.md with project plan</li></ul></li><li>November 02, 2020<ul><li>Test train and validate functionality on manual uploaded CheXpert Dataset</li><li>Update project.md with specific details about Deep learning models</li></ul></li><li>November 09, 2020<ul><li>Test train and validate functionality on downloaded CheXpert Dataset using &ldquo;wget&rdquo;</li><li>Update project.md with details about train and validation data set</li><li>Capture improvements to loss function</li></ul></li><li>November 16, 2020<ul><li>Self review - code and project.md</li></ul></li><li>December 02, 2020<ul><li>Review with TA/Professor - code and project.md</li></ul></li><li>December 07, 2020<ul><li>Final submission - code and project.md</li></ul></li></ul><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p>Howard, Jeremy; Gugger, Sylvain. Deep Learning for Coders with fastai and PyTorch . O&rsquo;Reilly Media. Kindle Edition <a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527/ref=sr_1_5?dchild=1&keywords=pytorch&qid=1606487426&sr=8-5">https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527/ref=sr_1_5?dchild=1&keywords=pytorch&qid=1606487426&sr=8-5</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2 role=doc-endnote><p>An open source machine learning framework that accelerates the path from research prototyping to production deployment <a href=https://pytorch.org/>https://pytorch.org/</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3 role=doc-endnote><p>Overview of PyTorch Library <a href=https://en.wikipedia.org/wiki/PyTorch>https://en.wikipedia.org/wiki/PyTorch</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4 role=doc-endnote><p>Introduction to PyTorch and documentation <a href=https://pytorch.org/deep-learning-with-pytorch>https://pytorch.org/deep-learning-with-pytorch</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5 role=doc-endnote><p>The efficiency of densenet121 <a href=https://medium.com/@smallfishbigsea/densenet-2b0889854a92>https://medium.com/@smallfishbigsea/densenet-2b0889854a92</a>&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6 role=doc-endnote><p>Densetnet architecture <a href=https://miro.medium.com/max/1050/1*znemMaROmOd1CzMJlcI0aA.png>https://miro.medium.com/max/1050/1*znemMaROmOd1CzMJlcI0aA.png</a>&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7 role=doc-endnote><p>Densely Connected Convolutional Networks <a href=https://arxiv.org/pdf/1608.06993.pdf>https://arxiv.org/pdf/1608.06993.pdf</a>&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8 role=doc-endnote><p>Whitepaper - CheXpert Dataset and Labelling <a href=https://arxiv.org/pdf/1901.07031.pdf>https://arxiv.org/pdf/1901.07031.pdf</a>&#160;<a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:9 role=doc-endnote><p>Chest X-ray Dataset <a href=https://stanfordmlgroup.github.io/competitions/chexpert/>https://stanfordmlgroup.github.io/competitions/chexpert/</a>&#160;<a href=#fnref:9 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:10 role=doc-endnote><p>Overview of AUC-ROC Curve in Machine Learning <a href=https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/>https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/</a>&#160;<a href=#fnref:10 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:11 role=doc-endnote><p>PyTorch Deep Learning Model for CheXpert Dataset <a href=https://www.kaggle.com/hmchuong/chexpert-pytorch-densenet121>https://www.kaggle.com/hmchuong/chexpert-pytorch-densenet121</a>&#160;<a href=#fnref:11 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:12 role=doc-endnote><p>Definition of Threshold <a href="https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/#:~:text=The%20decision%20for%20converting%20a,in%20the%20range%20between%200">https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/#:~:text=The%20decision%20for%20converting%20a,in%20the%20range%20between%200</a>&#160;<a href=#fnref:12 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:13 role=doc-endnote><p>AUCROC curves from CheXpert &lt;>&#160;<a href=#fnref:13 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section><div class="text-muted mt-5 pt-3 border-top"></div></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Gregor von Laszewski" aria-label="Gregor von Laszewski"><a class=text-white target=_blank rel=noopener href=https://laszewski.github.io aria-label="Gregor von Laszewski"><i class="fa fa-envelope"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/cybertraining-dsc/cybertraining-dsc.github.io/ aria-label=GitHub><i class="fab fa-github"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2022 Indiana University, 2020 All Rights Reserved</small><p class=mt-2><a href=/about/>About Cybertraining</a></p></div></div></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js integrity=sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/mermaid@8.9.2/dist/mermaid.min.js integrity=sha384-uQikAXnCAqsMb3ygtdqBYvcwvHUkzGIpjdGyy9owhURXHUxLC5LgTcSxJQH/RzjK crossorigin=anonymous></script><script src=/js/deflate.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.css integrity=sha384-Cqd8ihRLum0CCg8rz0hYKPoLZ3uw+gES2rXQXycqnL5pgVQIflxAUDS7ZSjITLb5 crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/katex.min.js integrity=sha384-1Or6BdeNQb0ezrmtGeqQHFpppNd7a/gw29xeiSikBbsb44xu3uAo8c7FwbF5jhbd crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/mhchem.min.js integrity=sha384-LIgAiYlGSAdpNC9+YDjDPF6JeS/RRIumtNo0CmyQERZ/+g0h9MbuYQwf/5pQ4Y4M crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.13.2/dist/contrib/auto-render.min.js integrity=sha384-vZTG03m+2yp6N6BNi5iM4rW4oIwk5DfcNdFfxkk9ZWpDriOkXX8voJBFrAO7MpVl crossorigin=anonymous onload=renderMathInElement(document.body,null)></script><script src=/js/main.min.758c0b1476eb0de973b63d0030f104f41a6eb3afb9908681605af4a48eb73018.js integrity="sha256-dYwLFHbrDelztj0AMPEE9Bpus6+5kIaBYFr0pI63MBg=" crossorigin=anonymous></script></body></html>