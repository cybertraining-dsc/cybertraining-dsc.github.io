<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cybertraining – health</title>
    <link>/tags/health/</link>
    <description>Recent content in health on Cybertraining</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 15 Mar 2021 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="/tags/health/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Health Informatics</title>
      <link>/docs/modules/bigdataapplications/2019/applications/health/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/docs/modules/bigdataapplications/2019/applications/health/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://drive.google.com/open?id=0B6wqDMIyK2P7UGRJNmlkYkNkQk0&#34;&gt;&lt;img src=&#34;images/presentation.png&#34; alt=&#34;Presentation&#34;&gt; Health Informatics
(131)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This section starts by discussing general aspects of Big Data and Health
including data sizes, different areas including genomics, EBI, radiology
and the Quantified Self movement. We review current state of health care
and trends associated with it including increased use of Telemedicine.
We summarize an industry survey by GE and Accenture and an impressive
exemplar Cloud-based medicine system from Potsdam. We give some details
of big data in medicine. Some remarks on Cloud computing and Health
focus on security and privacy issues.&lt;/p&gt;
&lt;p&gt;We survey an April 2013 McKinsey report on the Big Data revolution in US
health care; a Microsoft report in this area and a European Union report
on how Big Data will allow patient centered care in the future. Examples
are given of the Internet of Things, which will have great impact on
health including wearables. A study looks at 4 scenarios for healthcare
in 2032. Two are positive, one middle of the road and one negative. The
final topic is Genomics, Proteomics and Information Visualization.&lt;/p&gt;
&lt;h2 id=&#34;big-data-and-health&#34;&gt;Big Data and Health&lt;/h2&gt;
&lt;p&gt;This lesson starts with general aspects of Big Data and Health including
listing subareas where Big data important. Data sizes are given in
radiology, genomics, personalized medicine, and the Quantified Self
movement, with sizes and access to European Bioinformatics Institute.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ZkM-yZJQ1Cg&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Big Data and Health
(10:02)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;status-of-healthcare-today&#34;&gt;Status of Healthcare Today&lt;/h2&gt;
&lt;p&gt;This covers trends of costs and type of healthcare with low cost genomes
and an aging population. Social media and government Brain initiative.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=x9TpdMBqYrk&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Status of Healthcare Today
(16:09)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;telemedicine-virtual-health&#34;&gt;Telemedicine (Virtual Health)&lt;/h2&gt;
&lt;p&gt;This describes increasing use of telemedicine and how we tried and
failed to do this in 1994.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Pe4CVXQaL_U&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Telemedicine
(8:21)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;medical-big-data-in-the-clouds&#34;&gt;Medical Big Data in the Clouds&lt;/h2&gt;
&lt;p&gt;An impressive exemplar Cloud-based medicine system from Potsdam.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=GldSVijkJcM&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Medical Big Data in the Clouds
(15:02)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;medical-image-big-data&#34;&gt;Medical image Big Data&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=GOcVtwx2R2k&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Medical Image Big Data
(6:33)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;clouds-and-health&#34;&gt;Clouds and Health&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://youtu.be/9Whkl_UPS5g&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Clouds and Health (4:35)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;mckinsey-report-on-the-big-data-revolution-in-us-health-care&#34;&gt;McKinsey Report on the big-data revolution in US health care&lt;/h3&gt;
&lt;p&gt;This lesson covers 9 aspects of the McKinsey report. These are the
convergence of multiple positive changes has created a tipping point for&lt;/p&gt;
&lt;p&gt;innovation; Primary data pools are at the heart of the big data
revolution in healthcare; Big data is changing the paradigm: these are
the value pathways; Applying early successes at scale could reduce US
healthcare costs by $300 billion to $450 billion; Most new big-data
applications target consumers and providers across pathways; Innovations
are weighted towards influencing individual decision-making levers; Big
data innovations use a range of public, acquired, and proprietary data&lt;/p&gt;
&lt;p&gt;types; Organizations implementing a big data transformation should
provide the leadership required for the associated cultural
transformation; Companies must develop a range of big data capabilities.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=fu-TWnIk980&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; McKinsey Report
(14:53)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;microsoft-report-on-big-data-in-health&#34;&gt;Microsoft Report on Big Data in Health&lt;/h3&gt;
&lt;p&gt;This lesson identifies data sources as Clinical Data, Pharma &amp;amp; Life
Science Data, Patient &amp;amp; Consumer Data, Claims &amp;amp; Cost Data and
Correlational Data. Three approaches are Live data feed, Advanced
analytics and Social analytics.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://youtu.be/PjffvVgj1PE&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Microsoft Report on Big Data in Health
(2:26)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;eu-report-on-redesigning-health-in-europe-for-2020&#34;&gt;EU Report on Redesigning health in Europe for 2020&lt;/h3&gt;
&lt;p&gt;This lesson summarizes an EU Report on Redesigning health in Europe for
2020. The power of data is seen as a lever for change in My Data, My
decisions; Liberate the data; Connect up everything; Revolutionize
health; and Include Everyone removing the current correlation between
health and wealth.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://youtu.be/9mbt_ZSs0iw&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; EU Report on Redesigning health in Europe for 2020
(5:00)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;medicine-and-the-internet-of-things&#34;&gt;Medicine and the Internet of Things&lt;/h3&gt;
&lt;p&gt;The Internet of Things will have great impact on health including
telemedicine and wearables. Examples are given.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Jk3EeFzZnuU&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Medicine and the Internet of Things
(8:17)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;extrapolating-to-2032&#34;&gt;Extrapolating to 2032&lt;/h3&gt;
&lt;p&gt;A study looks at 4 scenarios for healthcare in 2032. Two are positive,
one middle of the road and one negative.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=a5G4HACeokg&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Extrapolating to 2032
(15:13)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;genomics-proteomics-and-information-visualization&#34;&gt;Genomics, Proteomics and Information Visualization&lt;/h3&gt;
&lt;p&gt;A study of an Azure application with an Excel frontend and a cloud BLAST
backend starts this lesson. This is followed by a big data analysis of
personal genomics and an analysis of a typical DNA sequencing analytics
pipeline. The Protein Sequence Universe is defined and used to motivate
Multi dimensional Scaling MDS. Sammon&amp;rsquo;s method is defined and its use
illustrated by a metagenomics example. Subtleties in use of MDS include
a monotonic mapping of the dissimilarity function. The application to
the COG Proteomics dataset is discussed. We note that the MDS approach
is related to the well known chisq method and some aspects of nonlinear
minimization of chisq (Least Squares) are discussed.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=zGzBtxq1ZRE&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Genomics, Proteomics and Information Visualization
(6:56)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Next we continue the discussion of the COG Protein Universe introduced
in the last lesson. It is shown how Proteomics clusters are clearly seen
in the Universe browser. This motivates a side remark on different
clustering methods applied to metagenomics. Then we discuss the
Generative Topographic Map GTM method that can be used in dimension
reduction when original data is in a metric space and is in this case
faster than MDS as GTM computational complexity scales like N not N
squared as seen in MDS.&lt;/p&gt;
&lt;p&gt;Examples are given of GTM including an application to topic models in
Information Retrieval. Indiana University has developed a deterministic
annealing improvement of GTM. 3 separate clusterings are projected for
visualization and show very different structure emphasizing the
importance of visualizing results of data analytics. The final slide
shows an application of MDS to generate and visualize phylogenetic
trees.&lt;/p&gt;
&lt;p&gt;\TODO{These two videos need to be uploaded to youtube}
&lt;a href=&#34;https://drive.google.com/file/d/0B5plU-u0wqMobXdEQWRHWl95UTA/view?usp=sharing&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Genomics, Proteomics and Information Visualization I
(10:33)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://drive.google.com/file/d/0B5plU-u0wqModlhmdVUwdGlQNTA/view?usp=sharing&#34;&gt;&lt;img src=&#34;images/video.png&#34; alt=&#34;Video&#34;&gt; Genomics, Proteomics and Information Visualization: II
(7:41)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://drive.google.com/open?id=0B8936_ytjfjmX0lEMWhMX2kwRHc&#34;&gt;&lt;img src=&#34;images/presentation.png&#34; alt=&#34;Presentation&#34;&gt; Proteomics and Information Visualization
(131)&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;resources&#34;&gt;Resources&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.nci.nih.gov/display/CIP/CIP+Survey+of+Biomedical+Imaging+Archives&#34;&gt;https://wiki.nci.nih.gov/display/CIP/CIP+Survey+of+Biomedical+Imaging+Archives&lt;/a&gt; [@wiki-nih-cip-survey]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://grids.ucs.indiana.edu/ptliupages/publications/Where%20does%20all%20the%20data%20come%20from%20v7.pdf&#34;&gt;http://grids.ucs.indiana.edu/ptliupages/publications/Where\%20does\%20all\%20the\%20data\%20come\%20from\%20v7.pdf&lt;/a&gt; [@fox2011does]&lt;/li&gt;
&lt;li&gt;&lt;del&gt;&lt;a href=&#34;http://www.ieee-icsc.org/ICSC2010/Tony%20Hey%20-%2020100923.pdf&#34;&gt;http://www.ieee-icsc.org/ICSC2010/Tony\%20Hey\%20-\%2020100923.pdf&lt;/a&gt;&lt;/del&gt;(this link does not exist any longer)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://quantifiedself.com/larry-smarr/&#34;&gt;http://quantifiedself.com/larry-smarr/&lt;/a&gt; [@smarr13self]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.ebi.ac.uk/Information/Brochures/&#34;&gt;http://www.ebi.ac.uk/Information/Brochures/&lt;/a&gt; [@www-ebi-aboutus]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.kpcb.com/internet-trends&#34;&gt;http://www.kpcb.com/internet-trends&lt;/a&gt; [@www-kleinerperkins-internet-trends]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/drsteventucker/wearable-health-fitness-trackers-and-the-quantified-self&#34;&gt;http://www.slideshare.net/drsteventucker/wearable-health-fitness-trackers-and-the-quantified-self&lt;/a&gt; [@www-slideshare-wearable-quantified-self]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.siam.org/meetings/sdm13/sun.pdf&#34;&gt;http://www.siam.org/meetings/sdm13/sun.pdf&lt;/a&gt; [@archive&amp;ndash;big-data-analytics-healthcare]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/Calico_%28company%29&#34;&gt;http://en.wikipedia.org/wiki/Calico_\%28company\%29&lt;/a&gt; [@www-wiki-calico]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/GSW_Worldwide/2015-health-trends&#34;&gt;http://www.slideshare.net/GSW_Worldwide/2015-health-trends&lt;/a&gt; [@www-slideshare-2015-health trends]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.accenture.com/SiteCollectionDocuments/PDF/Accenture-Industrial-Internet-Changing-Competitive-Landscape-Industries.pdf&#34;&gt;http://www.accenture.com/SiteCollectionDocuments/PDF/Accenture-Industrial-Internet-Changing-Competitive-Landscape-Industries.pdf&lt;/a&gt; [@www-accenture-insight-industrial-internet]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/schappy/how-realtime-analysis-turns-big-medical-data-into-precision-medicine&#34;&gt;http://www.slideshare.net/schappy/how-realtime-analysis-turns-big-medical-data-into-precision-medicine&lt;/a&gt; [@www-slideshare-big-medical-data-medicine]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://medcitynews.com/2013/03/the-body-in-bytes-medical-images-as-a-source-of-healthcare-big-data-infographic/&#34;&gt;http://medcitynews.com/2013/03/the-body-in-bytes-medical-images-as-a-source-of-healthcare-big-data-infographic/&lt;/a&gt; [@medcitynews-bytes-medical-images]&lt;/li&gt;
&lt;li&gt;&lt;del&gt;&lt;a href=&#34;http://healthinformatics.wikispaces.com/file/view/cloud_computing.ppt&#34;&gt;http://healthinformatics.wikispaces.com/file/view/cloud_computing.ppt&lt;/a&gt;&lt;/del&gt; (this link does not exist any longer)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mckinsey.com/~/media/mckinsey/industries/healthcare%20systems%20and%20services/our%20insights/the%20big%20data%20revolution%20in%20us%20health%20care/the_big_data_revolution_in_healthcare.ashx&#34;&gt;https://www.mckinsey.com/~/media/mckinsey/industries/healthcare%20systems%20and%20services/our%20insights/the%20big%20data%20revolution%20in%20us%20health%20care/the_big_data_revolution_in_healthcare.ashx&lt;/a&gt; [@www-mckinsey-industries-healthcare]&lt;/li&gt;
&lt;li&gt;&lt;del&gt;&lt;a href=&#34;https://partner.microsoft.com/download/global/40193764&#34;&gt;https://partner.microsoft.com/download/global/40193764&lt;/a&gt;&lt;/del&gt; (this link does not exist any longer)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ec.europa.eu/eip/ageing/file/353/download_en?token=8gECi1RO&#34;&gt;https://ec.europa.eu/eip/ageing/file/353/download_en?token=8gECi1RO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;del&gt;&lt;a href=&#34;http://www.liveathos.com/apparel/app&#34;&gt;http://www.liveathos.com/apparel/app&lt;/a&gt;&lt;/del&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://debategraph.org/Poster.aspx?aID=77&#34;&gt;http://debategraph.org/Poster.aspx?aID=77&lt;/a&gt; [@debategraph-poster]&lt;/li&gt;
&lt;li&gt;&lt;del&gt;&lt;a href=&#34;http://www.oerc.ox.ac.uk/downloads/presentations-from-events/microsoftworkshop/gannon&#34;&gt;http://www.oerc.ox.ac.uk/downloads/presentations-from-events/microsoftworkshop/gannon&lt;/a&gt;&lt;/del&gt;(this link does not exist any longer)&lt;/li&gt;
&lt;li&gt;&lt;del&gt;&lt;a href=&#34;http://www.delsall.org&#34;&gt;http://www.delsall.org&lt;/a&gt;&lt;/del&gt; (this link does not exist any longer)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://salsahpc.indiana.edu/millionseq/mina/16SrRNA_index.html&#34;&gt;http://salsahpc.indiana.edu/millionseq/mina/16SrRNA_index.html&lt;/a&gt; [@www-salsahpc-millionseq]&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.geatbx.com/docu/fcnindex-01.html&#34;&gt;http://www.geatbx.com/docu/fcnindex-01.html&lt;/a&gt; [@www-geatbx-parametric-optimization]&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Report: COVID-19 Analysis</title>
      <link>/report/fa20-523-342/project/project/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-342/project/project/</guid>
      <description>
        
        
        &lt;h1 id=&#34;covid-19-analysis&#34;&gt;COVID-19 Analysis&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-342/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/workflows/Check%20Report/badge.svg&#34; alt=&#34;Check Report&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-342/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/workflows/Status/badge.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
Status: final approved, Type: Project&lt;/p&gt;
&lt;p&gt;Hany Boles, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-342/&#34;&gt;fa20-523-342&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-342/blob/main/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;By the end of 2019, healthcare across the world started to see a new type of Flu and they called it Coronavirus or Covid-19. This new type of Flu developed across the world and it appeared there is no one treatment could be used to treat it yet, scientists found different treatments that apply to different age ranges. In this project, We will try to work on comparison analysis between USA and China on number of new cases and new deaths and trying to find factors played big roles in this spread.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-data-sets&#34;&gt;2. Data-Sets&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-preparing-covid-19-data-set&#34;&gt;2.1 Preparing COVID 19 Data-Set&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#22-preparing-weather-data-set&#34;&gt;2.2 preparing Weather Data-Set&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-methodology&#34;&gt;3. Methodology&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-processing-the-data&#34;&gt;4. Processing the Data&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-conclusion-and-future-work&#34;&gt;5. Conclusion and Future Work&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-acknowledgements&#34;&gt;6. Acknowledgements&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-references&#34;&gt;7. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; Corona Virus, Covid 19, Health&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;While the world is ready to start 2020 we heard about a new type of the Flu that it appears to be started in China and from there it went to the entire world. It appeared to affect all ages but its severity did depend on other factors that related to age, health conditions if the patient is a smoker or not?&lt;/p&gt;
&lt;p&gt;This new disease attacked aggressively the respiratory system for the patient and then all the human body causing death. The recovery from this disease appeared to vary from area to area across the globe, Also the death percentage as well was and still vary from area to area. and then we decided to perform the analysis on weather temperature from one side and the covid 19 new cases and new death on the other side to see if the weather temperature plays a role or not with it.&lt;/p&gt;
&lt;h2 id=&#34;2-data-sets&#34;&gt;2. Data-Sets&lt;/h2&gt;
&lt;p&gt;After observing many datasets &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; to get a better understanding if there are common factors in the areas that have the larger number of new Covid 19 cases, we decided to proceed with the dataset provided by the World Health Organization &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; because this dateset is being updated on a daily basis and has the most accurate data. Currently it appears that we are getting a second wave of coronavirus and so we will try to get the most recent data. We were able to use Webscraping to get the data we need from the World Health Organization website which is updated daily.&lt;/p&gt;
&lt;p&gt;For the weather datasets, we looked at several datasets &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; and we decided to use the data provided by visualcrossing website &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. This website helped us in getting the data we need which is daily average temperatures in the United States of America and China. We started to collect the data from 1/3/2020.&lt;/p&gt;
&lt;h3 id=&#34;21-preparing-covid-19-data-set&#34;&gt;2.1 Preparing COVID 19 Data-Set&lt;/h3&gt;
&lt;p&gt;We started to work on Covid 19 dataset and we found that it is better to use webscraping to gather the dataset so every time we run the python script, we will get the most recent data and then we opened the CSV file and added it to a dataframe.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/webscrap.jpg&#34; alt=&#34;Figure 1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt;: Downloading the Covid 19 dataset.&lt;/p&gt;
&lt;p&gt;We then filtered only on United States of America so we can get all data belong to United States of America.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/usa.jpg&#34; alt=&#34;Figure 2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt;: Capturing only USA data&lt;/p&gt;
&lt;p&gt;Then we made 2 seperate graphs to depict the number of new cases and the number of new deaths in the USA throughout 2020 as shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/usa_new_cases_deaths1.jpg&#34; alt=&#34;Figure 3&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3&lt;/strong&gt;: USA New Covid 19 cases and new deaths.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/china.jpg&#34; alt=&#34;Figure 4&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 4&lt;/strong&gt;: Capturing China data.&lt;/p&gt;
&lt;p&gt;We also made 2 seperate graphs to depict the number of new cases and the number of new deaths in China throughout 2020 as shown below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/china_new_cases_deaths.jpg&#34; alt=&#34;Figure 5&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 5&lt;/strong&gt;: China New Covid 19 cases and new deaths&lt;/p&gt;
&lt;h3 id=&#34;22-preparing-weather-data-set&#34;&gt;2.2 preparing Weather Data-Set&lt;/h3&gt;
&lt;p&gt;For the weather temperature dataset, we cleaned all the un-needed data from the csv file we received from Visualcrossing website &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;, then we merged the temperature column with the csv file we prepared for the covid 19, so now we have one file per country that contains Date, Temperature, New cases, new deaths.&lt;/p&gt;
&lt;h2 id=&#34;3-methodology&#34;&gt;3. Methodology&lt;/h2&gt;
&lt;p&gt;We utilized the Indiana University system to process the collected data as it will need a strong system to process it. Also, we utilized Python, matplotlib for visualization purposes, and Jupyter notebook as programming software and platform.&lt;/p&gt;
&lt;h2 id=&#34;4-processing-the-data&#34;&gt;4. Processing the Data&lt;/h2&gt;
&lt;p&gt;We started to process the final dataset we prepared and we examined the data for any correlation between the temperature and new cases for the United States of America and we found that there is no correlation there.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/usa_new_dataset.jpg&#34; alt=&#34;Figure 6&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 6&lt;/strong&gt;: USA Dataset after merging the data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/usacorr.jpg&#34; alt=&#34;Figure 7&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 7&lt;/strong&gt;: Correlation between the temperature and the new covid 19 cases for the United States of America.&lt;/p&gt;
&lt;p&gt;Then we also processed the data for China and got the same results as the United States of America. We then looked at the analysis and in the case of the United States of America we found there is a correlation between the new covid cases and the current (cumulative) cases. On the contrary, for China we found no correlation between the new Covid cases and the current (cumulative) cases.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/usacorrheat.jpg&#34; alt=&#34;Figure 8&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 8&lt;/strong&gt;: Heat map depicting the correlations between new cases, cumulative cases, new deaths, and cumulative deaths, respectively for the United States of America.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/chinacorr.jpg&#34; alt=&#34;Figure 9&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 9&lt;/strong&gt;: Correlation between the new covid 19 cases and the current cases for China.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/chinacorrheat.jpg&#34; alt=&#34;Figure 10&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 10&lt;/strong&gt;: Heat map depicting the correlations between new cases, cumulative cases, new deaths, and cumulative deaths, respectively for China.&lt;/p&gt;
&lt;p&gt;We started to observe more data from another country so we chose the United Kingdom, and we found a correlation between the new covid 19 cases and the current (cumulative) cases.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/uk_correlation.jpg&#34; alt=&#34;Figure 11&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 11&lt;/strong&gt;: Correlation between the new covid 19 cases and the current cases for the United Kingdom.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-342/raw/main/project/images/ukcorrheat.jpg&#34; alt=&#34;Figure 12&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 12&lt;/strong&gt;: Heat map depicting the correlations between new cases, cumulative cases, new deaths, and cumulative deaths, respectively for the United Kingdom.&lt;/p&gt;
&lt;h2 id=&#34;5-conclusion-and-future-work&#34;&gt;5. Conclusion and Future Work&lt;/h2&gt;
&lt;p&gt;After processing  all the data gathered in  search of a correlation between the weather, more specifically temperature, and the number of new cases in both China and the United States of America, the results clearly indicate  that the number of new cases and temperature are uncorrelated.  Nonetheless, the results suggest that there is a strong positive correlation (correlation coefficient &amp;gt; 0.8) between the number of new cases and the cumulative number of current cases in United states of America and United Kingdom. Hence, it appears that, in the absence of other mitigating factors, the number of the new cases will increase as long as the cumulative number of current cases keeps increasing.&lt;/p&gt;
&lt;p&gt;While the new covid 19 cases and the current cases at China are uncorrelated, this might be due to false reporting or due to different factors are being used at China to reduce the number of the new cases.&lt;/p&gt;
&lt;p&gt;Given the more recent developments pertaining to the discovery and distribution of vaccines it is suggested that the model be modified to include the number of vaccinations administered.  The objective in this case will be to discover any correlation between the number of new cases and both the number of the current cases as well as the number of vaccinations being given across at least the United Sates. Depending on the outcome it maybe possible to determine how effective the vaccines are and maybe predict, if possible, if ever the number of cases will diminish to zero.&lt;/p&gt;
&lt;h2 id=&#34;6-acknowledgements&#34;&gt;6. Acknowledgements&lt;/h2&gt;
&lt;p&gt;The author would like to thank Dr. Geoffrey Fox, Dr. Gregor von Laszewski, and the associate instructors in the &lt;em&gt;FA20-BL-ENGR-E534-11530: Big Data Applications&lt;/em&gt; course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their assistance, suggestions, and aid provided during working on this project.&lt;/p&gt;
&lt;h2 id=&#34;7-references&#34;&gt;7. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Covid19.who.int. 2020. [online] Available at: &lt;a href=&#34;https://covid19.who.int/table&#34;&gt;https://covid19.who.int/table&lt;/a&gt; [Accessed 19 December 2020].&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Datatopics.worldbank.org. 2020. Understanding The Coronavirus (COVID-19) Pandemic Through Data | Universal Health Coverage Data | World Bank. [online] Available at: &lt;a href=&#34;http://datatopics.worldbank.org/universal-health-coverage/coronavirus/&#34;&gt;http://datatopics.worldbank.org/universal-health-coverage/coronavirus/&lt;/a&gt; [Accessed 19 December 2020].&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Kaggle.com. 2020. COVID-19 Open Research Dataset Challenge (CORD-19). [online] Available at: &lt;a href=&#34;https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge&#34;&gt;https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge&lt;/a&gt; [Accessed 19 December 2020].&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Visualcrossing.com. 2020. Weather Data Services | Visual Crossing. [online] Available at: &lt;a href=&#34;https://www.visualcrossing.com/weather/weather-data-services#/editDataDefinition&#34;&gt;https://www.visualcrossing.com/weather/weather-data-services#/editDataDefinition&lt;/a&gt; [Accessed 19 December 2020].&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;The Weather Channel. 2020. National And Local Weather Radar, Daily Forecast, Hurricane And Information From The Weather Channel And Weather.Com. [online] Available at: &lt;a href=&#34;https://weather.com/&#34;&gt;https://weather.com/&lt;/a&gt; [Accessed 22 December 2020].&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Climate.gov. 2020. Dataset Gallery | NOAA Climate.Gov. [online] Available at: &lt;a href=&#34;https://www.climate.gov/maps-data/datasets/formats/csv/variables/precipitation&#34;&gt;https://www.climate.gov/maps-data/datasets/formats/csv/variables/precipitation&lt;/a&gt; [Accessed 22 December 2020].&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: Project: Deep Learning in Drug Discovery</title>
      <link>/report/sp21-599-359/project/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/report/sp21-599-359/project/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/sp21-599-359/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/sp21-599-359/workflows/Check%20Report/badge.svg&#34; alt=&#34;Check  Report&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/cybertraining-dsc/sp21-599-359/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/sp21-599-359/workflows/Status/badge.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
Status: final, Type: Project&lt;/p&gt;
&lt;p&gt;Anesu Chaora, &lt;a href=&#34;https://github.com/cybertraining-dsc/sp21-599-359/&#34;&gt;sp21-599-359&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/sp21-599-359/blob/main/project/index.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Code: &lt;a href=&#34;https://github.com/cybertraining-dsc/sp21-599-359/blob/main/project/code/predicting_molecular_activity.ipynb&#34;&gt;predicting_molecular_activity.ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Machine learning has been a mainstay in drug discovery for decades. Artificial neural networks have been used in computational approaches to drug discovery since the 1990s [^1]. Under traditional approaches, emphasis in drug discovery was placed on understanding chemical molecular fingerprints, in order to predict biological activity. More recently however, deep learning approaches have been adopted instead of computational methods. This paper outlines work conducted in predicting drug molecular activity, using deep learning approaches.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#11-de-novo-molecular-design&#34;&gt;1.1. De novo molecular design&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#12-bioactivity-prediction&#34;&gt;1.2. Bioactivity prediction&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-related-work&#34;&gt;2. Related Work&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-merck-molecular-activity-challenge-on-kaggle&#34;&gt;2.1. Merck Molecular Activity Challenge on Kaggle&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#22-the-dataset&#34;&gt;2.2. The Dataset&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#23-a-deep-learning-algorithm&#34;&gt;2.3. A Deep Learning Algorithm&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-project-implementation&#34;&gt;3. Project Implementation&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-tools-and-environment&#34;&gt;3.1. Tools and Environment&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-implementation-overview&#34;&gt;3.2. Implementation Overview&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#33-benchmarks&#34;&gt;3.3. Benchmarks&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#34-findings&#34;&gt;3.4. Findings&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-discussion&#34;&gt;4. Discussion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-conclusion&#34;&gt;5. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-acknowledgments&#34;&gt;6. Acknowledgments&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-appendix&#34;&gt;7. Appendix&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; Deep Learning, drug discovery.&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;h3 id=&#34;11-de-novo-molecular-design&#34;&gt;1.1. De novo molecular design&lt;/h3&gt;
&lt;p&gt;Deep learning (DL) is finding uses in developing novel chemical structures. Methods that employ variational autoencoders (VAE) have been used to generate new chemical structures. Approaches have involved encoding input string molecule structures, then reparametrizing the underlying latent variables, before searching for viable solutions in the latent space by using methods such as Bayesian optimizations. The results are then decoded back into simplified molecular-input line-entry system (SMILES) notation, for recovery of molecular descriptors. Variations to this method involve using generative adversarial networks (GAN)s, as subnetworks in the architecture, to generate the new chemical structures &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Other approaches for developing new chemical structures involve recurrent neural networks (RNN), to generate new valid SMILES strings, after training the RNNs on copious quantities of known SMILES datasets. The RNNs use probability distributions learned from training sets, to generate new strings that correspond to molecular structures &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. Variations to this approach incorporate reinforcement learning to reward models for new chemical structures, while punishing them for undesirable results &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;12-bioactivity-prediction&#34;&gt;1.2. Bioactivity prediction&lt;/h3&gt;
&lt;p&gt;Computational methods have been used in drug development for decades &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. The emergence of high-throughput screening (HTS), in which automated equipment is used to conduct large assays of scientific experiments on molecular compounds in parallel, has resulted in generation of enormous amounts of data that require processing. Quantitative structure activity relationship (QSAR) models for predicting the biological activity responses to physiochemical properties of predictor chemicals, extensively use machine learning models like support vector machines (SVM) and random decision forests (RF) for processing &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;While deep learning (DL) approaches have an advantage over single-layer machine learning methods, when predicting biological activity responses to properties of predictor chemicals, they have only recently been used for this &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. The need to interpret how predictions are made through computationally oriented drug discovery, is seen - in part - as a factor to why DL approaches have not been adopted as quickly in this area &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. However, because DL models can learn complex non-linear data patterns, using their multiple hidden layers to capture patterns in data, they are better suited for processing complex life sciences data, than other machine learning approaches &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Their applications have included profiling tumors at molecular level and predicting drug responses, based on pharmacological and biological molecular structures, functions, and dynamics. This is attributed to their ability to handle high dimensionality in data features, making them appealing for use in predicting drug response &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;For example, deep neural networks were used in models that won NIH’s Toxi21 Challenge &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt; on using chemical structure data only to predict compounds of concern to human health &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;. DL models were also found to perform better than standard RF models &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt; in predicting the biological activities of molecular compounds in the Merck Molecular Activity Challenge on Kaggle &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;. Details of the challenge follow.&lt;/p&gt;
&lt;h2 id=&#34;2-related-work&#34;&gt;2. Related Work&lt;/h2&gt;
&lt;h3 id=&#34;21-merck-molecular-activity-challenge-on-kaggle&#34;&gt;2.1. Merck Molecular Activity Challenge on Kaggle&lt;/h3&gt;
&lt;p&gt;A challenge to identify the best statistical techniques for predicting molecular activity was issued by Merck &amp;amp; Co Pharmaceutical, through Kaggle in October of 2012. The stated goal of the challenge was to ‘help develop safe and effective medicines by predicting molecular activity’ for effects that were both on and off target &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;22-the-dataset&#34;&gt;2.2. The Dataset&lt;/h3&gt;
&lt;p&gt;A &lt;a href=&#34;https://www.kaggle.com/c/MerckActivity/data&#34;&gt;dataset&lt;/a&gt; was provided for the challenge &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;. It consisted of 15 molecular activity datasets. Each dataset contained rows corresponding to assays of biological activity for chemical compounds. The datasets were subdivided into training and test set files. The training and test dataset split was done by dates of testing &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;, with test set dates consisting of assays conducted after the training set assays.&lt;/p&gt;
&lt;p&gt;The training set files each had a column with molecular descriptors that were formulated from chemical molecular structures. A second column in the files contained numeric values, corresponding to raw activity measures. These were not normalized, and indicated measures in different units.&lt;/p&gt;
&lt;p&gt;The remainder of the columns in each training dataset file indicated disguised substructures of molecules. Values in each row, under the substructure (atom pair and donor-acceptor pair) codes, corresponded to the frequencies at which each of the substructures appeared in each compound. Figure 1 shows part of the head row for one of the training dataset files, and the first records in the file.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/sp21-599-359/raw/develop/project/images/training_set.jpg&#34; alt=&#34;Figure 1&#34;&gt;
&lt;strong&gt;Figure 1&lt;/strong&gt;: Head Row of 1 of 15 Training Dataset files&lt;/p&gt;
&lt;p&gt;The test dataset files were similar (Figure 2) to the training files, except they did not include the column for activity measures. The challenge presented was to predict the activity measures for the test dataset.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/sp21-599-359/raw/develop/project/images/test_set.jpg&#34; alt=&#34;Figure 2&#34;&gt;
&lt;strong&gt;Figure 2&lt;/strong&gt;: Head Row of 1 of 15 Test Dataset files&lt;/p&gt;
&lt;h3 id=&#34;23-a-deep-learning-algorithm&#34;&gt;2.3. A Deep Learning Algorithm&lt;/h3&gt;
&lt;p&gt;The entry that won the Merck Molecular Activity Challenge on Kaggle used an ensemble of methods that included a fully connected neural network as the main contributor to the high accuracy in predicting molecular activity &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;. Evaluations of predictions for molecular activity for the test set assays were then determined using the mean of the correlation coefficient (R2) of the 15 data sets. Sample code in R was provided for evaluating the correlation coefficient. The code, and formula for R2 are appended in Appendix 1.&lt;/p&gt;
&lt;p&gt;An approach of employing convolutional networks on substructures of molecules, to concentrate learning on localized features, while reducing the number of parameters in the overall network, was also proposed in literature on improving molecular activity predictions. This methodology of identifying molecular substructures as graph convolutions, prior to further processing, was discussed by authors &lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;, &lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;In line with the above research, an ensemble of networks for predicting molecular activity was planned for this project, using the Merck dataset, and hyperparameter configurations found optimal by the cited authors. Recognized optimal activation functions, for different neural network types and prediction types &lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;, were also earmarked for use on the project.&lt;/p&gt;
&lt;h2 id=&#34;3-project-implementation&#34;&gt;3. Project Implementation&lt;/h2&gt;
&lt;p&gt;Implementation details for the project were as follows:&lt;/p&gt;
&lt;h3 id=&#34;31-tools-and-environment&#34;&gt;3.1. Tools and Environment&lt;/h3&gt;
&lt;p&gt;The Python programming language (version 3.7.10) was used on Google Colab (&lt;a href=&#34;https://colab.research.google.com&#34;&gt;https://colab.research.google.com&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;A subscription account to the service was employed, for access to more RAM (High-RAM runtime shape) during development, although the free standard subscription will suffice for the version of code included in this repository.&lt;/p&gt;
&lt;p&gt;Google Colab GPU hardware accelerators were used in the runtime configuration.&lt;/p&gt;
&lt;p&gt;Prerequisites for the code included packages from &lt;a href=&#34;http://cloudmesh.github.io/&#34;&gt;Cloudmesh&lt;/a&gt;, for benchmarking performance, and from &lt;a href=&#34;https://www.kaggle.com/&#34;&gt;Kaggle&lt;/a&gt;, for API access to related data.&lt;/p&gt;
&lt;p&gt;Keras libraries were used for implementing the molecular activity prediction model.&lt;/p&gt;
&lt;h3 id=&#34;32-implementation-overview&#34;&gt;3.2. Implementation Overview&lt;/h3&gt;
&lt;p&gt;This project&amp;rsquo;s implementation of a molecular activity prediction model consisted of a fully connected neural network.  The network used the Adam &lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt; optimization algorithm, at a learning rate of 0.001 and beta_1 calibration of 0.5. Mean Squared Error (MSE) was used for the loss function, and R-Squared &lt;sup id=&#34;fnref:15&#34;&gt;&lt;a href=&#34;#fn:15&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;15&lt;/a&gt;&lt;/sup&gt; for the metric. Batch sizes were set at 128. These parameter choices were selected by referencing the choices of other prior investigators &lt;sup id=&#34;fnref:16&#34;&gt;&lt;a href=&#34;#fn:16&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;16&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;The network was trained on the 15 datasets separately, by iterating through the storage location containing preprocessed data, and sampling the data into training, evaluation and prediction datasets - before running the training. The evaluation and prediction steps, for each dataset, where also executed during the iteration of each molecular activity dataset. Running the processing in this way was necessitated by the fact that the 15 datasets each had different feature set columns, corresponding to different molecular substructures. As such, they could not be readily processed through a single dataframe.&lt;/p&gt;
&lt;p&gt;An additional compounding factor was that the data was missing the molecular activity results (actual readings) associated with the dataset provided for testing. These were not available through Kaggle as the original competition withheld these from contestants, reserving them as a means for evaluating the accuracy of the models submitted. In the absence of this data, for validating the results of this project, the available training data was split into samples that were then used for the exercise. The training of the fully connected network was allocated 80% of the data, while the testing/evaluation of the model was allocated 10% of the data. The remaining data (10%) was used for evaluating predictions.&lt;/p&gt;
&lt;h3 id=&#34;33-benchmarks&#34;&gt;3.3. Benchmarks&lt;/h3&gt;
&lt;p&gt;Benchmarks captured during code execution, using cloudmesh-common &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;, were as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The data download process from Kaggle, through the Kaggle data API, took 29 seconds.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Data preprocessing scripts took 8 minutes and 56 seconds to render the data ready for training and evaluation. Preprocessing of data included iterating through the issued datasets separately, since each file contained different combinations of feature columns (molecular substructures).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The model training, evaluation and prediction step took 7 minutes and 45 seconds.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;34-findings&#34;&gt;3.4. Findings&lt;/h3&gt;
&lt;p&gt;The square of the correlation coefficient (R^2) values obtained (coefficient of determination) &lt;sup id=&#34;fnref:17&#34;&gt;&lt;a href=&#34;#fn:17&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;17&lt;/a&gt;&lt;/sup&gt; during training and evaluation were considerably low (&amp;lt; 0.1). A value of one (1) would indicate a goodness of fit for the model that implies that the model is completely on target with predicting accurate outcomes (molecular activity) from the independent variables (substructures/feature sets). Such a model would thus fully account for the predictions, given a set of substructures as inputs. A value of zero (0) would indicate a total lack of correlation between the input feature values and the predicted outputs. As such, it would imply that there is a lot of unexplained variance in the outputs of the model. The square of the correlation coefficient values obtained for this model (&amp;lt;0.1) therefore imply that it either did not learn enough, or other unexplained (by the model) variance caused unreliable predictions.&lt;/p&gt;
&lt;h2 id=&#34;4-discussion&#34;&gt;4. Discussion&lt;/h2&gt;
&lt;p&gt;An overwhelming proportion of the data elements provided through the datasets were zeros (0)s, indicating that no frequencies of the molecular substructures/features were present in the molecules represented by particular rows of data elements. This disproportionate representation of absent molecular substructure frequencies, versus the significantly lower instances where there were frequencies appears to have had an effect of dampening the learning of the fully connected neural network.&lt;/p&gt;
&lt;p&gt;This supports approaches that advocated for the use of convolutional neural networks &lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;, &lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt; as auxiliary components to help focus learning on pertinent substructures. While the planning phase of this project had incorporated inclusion of such, the investigator ran out of time to implement an ensemble network that would include the suggestions.&lt;/p&gt;
&lt;p&gt;Apart from employing convolutions, other preprocessing approaches for rescaling, and normalizing, the data features and activations &lt;sup id=&#34;fnref:16&#34;&gt;&lt;a href=&#34;#fn:16&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;16&lt;/a&gt;&lt;/sup&gt; could have helped the learning, and subsequently the predictions made. This reinforces the fact that deep learning models, as is true of other machine learning approaches, rely deeply on the quality and preparation of data fed into them.&lt;/p&gt;
&lt;h2 id=&#34;5-conclusion&#34;&gt;5. Conclusion&lt;/h2&gt;
&lt;p&gt;Deep learning is a very powerful new approach to solving many machine learning problems, including some that have eluded solutions till now. While deep learning models offer robust and sophisticated ways of learning patterns in data, they are still only half the story. The quality and appropriate preparation of the data fed into models is equally important when seeking to have meaningful results.&lt;/p&gt;
&lt;h2 id=&#34;6-acknowledgments&#34;&gt;6. Acknowledgments&lt;/h2&gt;
&lt;p&gt;Acknowledgements go to Dr. Geoffrey Fox for his excellent guidance on ways to think about deep learning approaches, and for his instructorship of the course &amp;lsquo;ENG-E599: AI-First Engineering&amp;rsquo;, for which this project is a deliverable. Acknowledgements also go to Dr. Gregor von Laszewski for his astute tips and recommendations on technical matters, and on coding and documention etiquette.&lt;/p&gt;
&lt;h2 id=&#34;7-appendix&#34;&gt;7. Appendix&lt;/h2&gt;
&lt;p&gt;Square of the Correlation Coefficient (R2) Formula:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/sp21-599-359/raw/develop/project/images/correlation_coefficient.jpg&#34; alt=&#34;Figure 3&#34;&gt;
&lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Sample R2 Code in the R Programming Language:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Rsquared &amp;lt;- function(x,y) {
  # Returns R-squared.
  # R2 = \frac{[\sum_i(x_i-\bar x)(y_i-\bar y)]^2}{\sum_i(x_i-\bar x)^2 \sum_j(y_j-\bar y)^2}
  # Arugments: x = solution activities
  #            y = predicted activities
  if ( length(x) != length(y) ) {
    warning(&amp;quot;Input vectors must be same length!&amp;quot;)
  }
  else {
    avx &amp;lt;- mean(x)
    avy &amp;lt;- mean(y)
    num &amp;lt;- sum( (x-avx)*(y-avy) )
    num &amp;lt;- num*num
    denom &amp;lt;- sum( (x-avx)*(x-avx) ) * sum( (y-avy)*(y-avy) )
    return(num/denom)
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Hongming Chen, O. E. (2018). The rise of deep learning in drug discovery. Elsevier.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Marwin H. S. Segler, T. K. (2018). Generating Focused Molecule Libraries for Drug Discovery with Recurrent Neural Networks. America Chemical Society.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;N Jaques, S. G. (2017). Sequence Tutor: Conservative Fine-Tuning of Sequence Generation Models with KL-control. Proceedings of the 34th International Conference on Machine Learning, PMLR (pp. 1645-1654). MLResearchPress.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Gregory Sliwoski, S. K. (2014). Computational Methods in Drug Discovery. Pharmacol Rev, 334 - 395.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Delora Baptista, P. G. (2020). Deep learning for drug response prediction in cancer. Briefings in Bioinformatics, 22, 2021, 360–379.&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Erik Gawehn, J. A. (2016). Deep Learning in Drug Discovery. Molecular Informatics, 3 - 14.&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;National Institute of Health. (2014, November 14). Tox21 Data Challenge 2014. Retrieved from [tripod.nih.gov:] &lt;a href=&#34;https://tripod.nih.gov/tox21/challenge/&#34;&gt;https://tripod.nih.gov/tox21/challenge/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Andreas Mayr, G. K. (2016). Deeptox: Toxicity Prediction using Deep Learning. Frontiers in Environmental Science.&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Junshui Ma, R. P. (2015). Deep Neural Nets as a Method for Quantitative Structure-Activity Relationships. Journal of Chemical Information and Modeling, 263-274.&amp;#160;&lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Kaggle. (n.d.). Merck Molecular Activity Challenge. Retrieved from [Kaggle.com:] &lt;a href=&#34;https://www.kaggle.com/c/MerckActivity&#34;&gt;https://www.kaggle.com/c/MerckActivity&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:11&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Kearnes, S., McCloskey, K., Berndl, M., Pande, V., &amp;amp; Riley, P. (2016). Molecular graph convolutions: moving beyond fingerprints. Switzerland: Springer International Publishing .&amp;#160;&lt;a href=&#34;#fnref:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:12&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Mikael Henaff, J. B. (2015). Deep Convolutional Networks on Graph-Structured Data.&amp;#160;&lt;a href=&#34;#fnref:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:13&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Bronlee, J. (2021, January 22). How to Choose an Activation Function for Deep Learning. Retrieved from [https://machinelearningmastery.com:] &lt;a href=&#34;https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/&#34;&gt;https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:13&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:14&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Keras. (2021). Adam. Retrieved from [https://keras.io:] &lt;a href=&#34;https://keras.io/api/optimizers/adam/&#34;&gt;https://keras.io/api/optimizers/adam/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:14&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:15&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Keras. (2021). Regression Metrics. Retrieved from [https://keras.io:] &lt;a href=&#34;https://keras.io/api/metrics/regression_metrics/&#34;&gt;https://keras.io/api/metrics/regression_metrics/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:15&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:16&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;RuwanT (2017, May 16). Merk. Retrieved from [https://github.com:] &lt;a href=&#34;https://github.com/RuwanT/merck/blob/master/README.md&#34;&gt;https://github.com/RuwanT/merck/blob/master/README.md&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:16&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:17&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Wikipedia (2021). Coefficient of Determination. Retrieved from [https://wikipedia.org:] &lt;a href=&#34;https://en.wikipedia.org/wiki/Coefficient_of_determination&#34;&gt;https://en.wikipedia.org/wiki/Coefficient_of_determination&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:17&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: Big Data on Gesture Recognition and Machine Learning</title>
      <link>/report/fa20-523-315/report/report/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-315/report/report/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-315/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-315/workflows/Check%20Report/badge.svg&#34; alt=&#34;Check Report&#34;&gt;&lt;/a&gt; 
&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-315/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-315/workflows/Status/badge.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
Status: final, Type: Report&lt;/p&gt;
&lt;p&gt;Sunny Xu, Peiran Zhao, Kris Zhang, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-315/&#34;&gt;fa20-523-315&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-315/blob/main/report/report.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Since our technology is more and more advanced as time goes by, traditional human-computer interaction has become increasingly difficult to meet people&amp;rsquo;s demands. In this digital era, people need faster and more efficient methods to obtain information and data. Traditional and single input and output devices are not fast and convenient enough, it also requires users to learn their own methods of use, which is extremely inefficient and completely a waste of time. Therefore, artificial intelligence comes out, and its rise has followed the changeover times, and it satisfied people&amp;rsquo;s needs. At the same time, gesture is one of the most important way for human to deliver information. It is simple, efficient, convenient, and universally acceptable. Therefore, gesture recognition has become an emerging field in intelligent human-computer interaction field, with great potential and future.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background&#34;&gt;2. Background&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-gesture-recognition&#34;&gt;3. Gesture Recognition&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-hand-gesture&#34;&gt;3.1 Hand Gesture&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#311-hand-gesture-recognition-and-big-data&#34;&gt;3.1.1 Hand Gesture Recognition and Big Data&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#312-principles-of-hand-gesture-recognition&#34;&gt;3.1.2 Principles of Hand Gesture Recognition&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#313-gesture-segmentation-and-algorithm-the-biggest-difficulty-of-gesture-recognition&#34;&gt;3.1.3 Gesture Segmentation and Algorithm, The Biggest Difficulty of Gesture Recognition.&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-body-gesture&#34;&gt;3.2 Body Gesture&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#321-introduction-to-body-gesture&#34;&gt;3.2.1 Introduction to Body Gesture&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#322-body-gesture-and-big-data&#34;&gt;3.2.2 Body Gesture and Big Data&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#323-random-forest-algorithm-in-body-gesture-recognition&#34;&gt;3.2.3 Random Forest Algorithm in Body Gesture Recognition&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#33-face-gesture&#34;&gt;3.3 Face Gesture&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#331-introduction-to-face-gesture-facial-expression&#34;&gt;3.3.1 Introduction to Face Gesture (Facial Expression)&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#332-sense-organs-on-the-face&#34;&gt;3.3.2 Sense Organs on The Face&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#333-facial-expression-and-big-data&#34;&gt;3.3.3 Facial Expression and Big Data&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#334-the-problem-with-detecting-emotion-for-technology-nowadays&#34;&gt;3.3.4 The Problem with Detecting Emotion for Technology Nowadays&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#335-classification-algorithms&#34;&gt;3.3.5 Classification Algorithms&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-conclusion&#34;&gt;4. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-references&#34;&gt;5. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; gesture recognition, human, technology, big data, artificial intelligence, body language, facial expression&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Technology is probably one of the most attracting things for people nowadays. Whether it is the new iPhone coming out or some random new technology that is bring into our life. It is a matter of fact that technology has become one of the essential parts of our life and our society. Simply, our life will change a lot without technology. As of today, since technology is improving so fast, there are many things that can be related to AI and machine learning. A lot of the ordinary things around our life becomes data. And the reason why they become data is because there is a need for them in having better technology to improve our life. For example, language was stored into data to produce technology like translator to provide convenience for people that does not speak the language. Another example is that roads were stored into data to produce GPS to guide direction for people. Nowadays, people values communication and interaction between others. Since gesture recognition is one of the most important ways to understand people and know their emotion, it becomes a popular field of study for many scientists. There are multiply field of study in gesture recognition and each require a lot of amount of time to know them well. For the report, we do research about hand gesture, body gesture and facial expression. Of course, there will be a lot of other fields related to gesture recognition, for example, like animal gestures. They all can be stored into data and get study in the research by scientists. Many people might have question about how gesture recognition are has anything to do with technology. They simply do not think that they can be related, but in fact, they are related. Companies like Intel and Microsoft have already created so many studies for new technology in that field. For example, Intel proposed combining facial recognition with device recognition to authenticate users. Studying gestures recognition will often reveal what the think. For example, when someone is lying, their eye will tend to look around and they tend to touch their nose with their hand, etc. So, studying gesture recognition will not only help people understand much more about human beings and it can also help our technology grow. For example, in AI and machine learning, studying gestures recognition will make or improve AI and machine learning to better understand humans and be more human-like.&lt;/p&gt;
&lt;h2 id=&#34;2-background&#34;&gt;2. Background&lt;/h2&gt;
&lt;p&gt;Nowadays, people are doing more and more high-tech research, which also makes various high-tech products appear in society. For people, electricity is as important as water and air. Can&amp;rsquo;t imagine life without electricity. We can realize that technology is changing everything about people from all aspects. People living in the high-tech era are also forced to learn and understand the usage of various high-tech products. As a representative of high technology, artificial intelligence has also attracted widespread attention from society. Due to the emergence of artificial intelligence, people have also begun to realize that maintaining human characteristics is also an important aspect of high technology.&lt;/p&gt;
&lt;p&gt;People&amp;rsquo;s living environment is inseparable from high technology. As for the use of human body information, almost every high-tech has different usage &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. For example, face recognition is used in many places to check-in. This kind of technology enables the machine to store the information of the human face and determine whether it is indeed the right person by judging the five senses. We are most familiar with using this technology in airports, customs, and companies to check in at work. Not only that, but the smartphones we use every day are also unlocked through this face recognition technology. Another example is the game console that we are very familiar with. Game consoles such as Xbox and PS already have methods for identifying people&amp;rsquo;s bodies. They can identify several key points of people through the images received by their own cameras, thus inputting this line of action into the world of the game.&lt;/p&gt;
&lt;p&gt;Many researchers are now studying other applications of human movements, gestures, and facial expressions. One of the most influential ones is that Google’s scientists have developed a new computer vision method for hand perception. Google researchers identified the movement of a hand through twenty-one 3D points on the hand. Research Engineers Valentin Bazarevsky and Fan Zhang stated that &amp;ldquo;The ability to perceive the shape and motion of hands can be a vital component in improving the user experience across a variety of technological domains and platforms &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&amp;rdquo; This model can currently identify many common cultural features. gesture. They have done experiments. When people play a game of &amp;ldquo;rock, paper, scissors&amp;rdquo; in front of the camera, this model can also judge everyone&amp;rsquo;s win or loss by recognizing gestures.&lt;/p&gt;
&lt;p&gt;More than that, many artificial intelligences can now understand people&amp;rsquo;s feelings and intentions by identifying people&amp;rsquo;s facial expressions. This also allows us to know how big a database is behind this to support the operation of these studies. But collecting these data about gesture recognition is not easy. Many times we need to worry about not only whether the data we input is correct, but also whether the target identified by artificial intelligence is clear and the output information is accurate.&lt;/p&gt;
&lt;h2 id=&#34;3-gesture-recognition&#34;&gt;3. Gesture Recognition&lt;/h2&gt;
&lt;p&gt;Gesture recognition is mainly divided into two categories, one is based on external device recognition, the specific application is data gloves, wearing it on user&amp;rsquo;s hand, to obtain and analysis information through sensors. This method has obvious shortcomings, though it is accurate and has excellent response speed, but it is costly and is not good for large-scale promotion. The other one is the use of computer vision. People do not need to wear gloves. As its name implies, this method collects and analyzes information through a computer. It is convenient, comfortable, and not so limited based on external device identification. In contrast, it has greater potential and is more in line with the trend of the times. Of course, this method needs more effective and accurate algorithms to support, because the gestures made by different people at different times, in different environments and at different angles also represent different meanings. So, if we want more accurate information feedback. Then the advancement of algorithms and technology is inevitable. The development of gesture recognition is also the development of artificial intelligence, a process of the development of various algorithms from data gloves to the development of computer vision-based optical technology plays a role in promoting it.&lt;/p&gt;
&lt;h3 id=&#34;31-hand-gesture&#34;&gt;3.1 Hand Gesture&lt;/h3&gt;
&lt;h4 id=&#34;311-hand-gesture-recognition-and-big-data&#34;&gt;3.1.1 Hand Gesture Recognition and Big Data&lt;/h4&gt;
&lt;p&gt;Hand gesture recognition is commonly used in gesture recognition because fingers are the most flexible and it is able to create different angles that will represent different meanings. The hand gesture itself is also an easy but efficient way for us human beings to communicate and send messages to each other. The existence of hand gestures can be considered easy but powerful. However, if we are using the application of hand gesture recognition, it is a much more complicated process. In real life, we can just ben our finger or simply make a fist so that other people will understand our message. But when using hand gesture recognition there are many processes that are being involved. Hand gesture is commonly used in geesture recoginitaion As we did our research and based on our life experiences, hand gesture recognition is a very hot topic and has all the potential to be the next wave. Hand gesture recognition has recently achieved big success in many fields. The advancement and development of hand gesture recognition is also the development of other technology such as the advancement of computer chips, the advancement of algorithms, the advancement of machine learning even advancement of deep learning, and the advancement of cameras from 2D to 3D. The most important part of hand gesture recognition is big data and machine learning. Because of the development of big data and machine learning, data scientists are able to have better datasets, build a more accurate and successful model and be able to process the information and predict the most accurate results. Hand gesture recognition is a significant link in Gesture recognition.However gesture recognition is also not only about hand gesture recognition, it also includes other body parts such as facial expression recognition and body gesture recognition. With the help of the whole system of different gesture recognitions, the data can be recorded and processed by AIs. The results or predictions can be used currently or later on for different purposes in different areas &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;312-principles-of-hand-gesture-recognition&#34;&gt;3.1.2 Principles of Hand Gesture Recognition&lt;/h4&gt;
&lt;p&gt;Hand gesture recognition is a complicated process involving many steps. And in order to get the most accurate result, it will need a large amount of quality data and a scientific model with high performance. Hand gesture recognition is also at a developing stage simply because there are so many possible factors that can influence the result. Possible factors include skin color, background color, hand gesture angle, and Bending angle, etc. To simplify the process of gesture recognition, AIs will use 3-D cameras to capture images. After that, the data of the image will be collected and processed by programs and built models.  And lastly, AIs will be able to use that model to get an accurate result in order to have a corresponding response or predict future actions. To explain all processes of hand gesture recognition in detail, it includes graphic gathering, retreatment, skin color segmentation, hand gesture segmentation, and finally hand gesture recognition. Hand Gesture Recognition can not achieve the best accuracy without all any of these steps. Within all these steps, skin color segmentation is the most crucial step in order to increase accuracy and this process will be explained in the next session &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;313-gesture-segmentation-and-algorithm-the-biggest-difficulty-of-gesture-recognition&#34;&gt;3.1.3 Gesture Segmentation and Algorithm, The Biggest Difficulty of Gesture Recognition.&lt;/h4&gt;
&lt;p&gt;If someone actually asks us a question which is what kind of recognition is going to have the maximum potential in the future? We will have Hand Gesture recognition as my answer without a doubt. Because in my opinion, Hand Gesture Recognition is really the next wave, as our technology is getting better and better, it will be a much easier and more efficient type of recognition that could possibly change our lives. If you compare Hand Gesture Recognition with Voice Recognition, you will see the biggest difference because everyone is using Hand Gesture all over the world in different ways while Voice is limited to people that are unable to make a sound and sound is a much more complicated type of data that in my opinion is not efficient enough to deliver a message, at least with lots of evidence indicating it is not easier than Hand Gesture Recognition. However, it doesn’t mean hand gesture doesn’t have any limit. Instead, Hand Gesture Recognition is influenced by the color in many ways including skin colors and the colors of the background. But skin color is also a great characteristic of recognition at the same time. So if we could overcome this shortcoming or obstacle, the biggest disadvantage of Hand Gesture Recognition could also become its biggest advantage since skin color has so many amazing characteristics that could be used as a huge benefit for Hand Gesture Recognition. Firstly, skin color is a unique attribute which means it has a similar meaning all over the world. For example, Asian people mostly have yellow skins, Western people mostly have white skins while African American people mostly have black skins. People might form different regions from all over the world but since their skins are similar in many ways, they are most likely to have at least similar hand gesture meanings according to different scientific studies. However, you might ask another realistic question which is what about many people who have similar skin colors but are coming from different groups of people who have a completely different cultural background which results in different Hand Gestures and people who have similar Hands Gesture but have much different skin colors. These are all realistic Hand Gesture Recognition problems and these are the problems that Hand Gesture Recognition already solved or is going to solve in the future. Firstly, for people who have similar skin colors but are coming from different groups of people who have a completely different cultural background, this is when skin color comes to play its role. Even though those people have similar skin color, their skin color can’t be exactly the same. Most of the time, it will be either darker or lighter and we might say it’s all yellow or white, but the machine will see it as its data format so even if it is all white, the type of white is still completely different. And this is when gesture segmentation or more accurately skin color segmentation makes a difference. Overall, us human read skin colors as the simple color we have learned from different textbooks but the computer or machine see the different color in the different color spaces and the data they receive and going to process will be much more accurate. In addition to that, scientists will need to do more in-depth research and studies in order to get the most accurate result. And for people who have similar Hands Gesture but have many different skin colors, scientists will need to collect more accurate data not only about the color and about the size, angles, etc. This more detailed information will help the machine read Hand Gesture more accurately in order to get the most beneficial feedback. The background color will undoubtedly provide lots of useless information and potentially negatively influence the result. In this way, Hand Gesture Recognition has developed its own color and gesture recognition algorithm and method to remove the most useless data or color and leave the valid ones. Lighting in different background settings will have a huge influence to and in most ways, it will negatively influence the result too. There are five most important steps in Hand Gesture Recognition which are Graphic Gathering, Pretreatment, Skin Color Segmentation, Gesture Segmentation, and lastly Gesture Recognition. All these different steps are all very crucial in order to get the most accurate feedback or result. It is pretty similar to the most data treatment process especially the first two steps where you first build a model, gather different types of data, clean the data after that, and use skin color segmentation and gesture segmentation before the last Gesture Recognition process &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;32-body-gesture&#34;&gt;3.2 Body Gesture&lt;/h3&gt;
&lt;h4 id=&#34;321-introduction-to-body-gesture&#34;&gt;3.2.1 Introduction to Body Gesture&lt;/h4&gt;
&lt;p&gt;Body gestures, which can also be called body language, refer to humans expressing their ideas through the coordinated activities of various body parts. In our lives, body language is ubiquitous. It is like a bridge for our human communication. Through body language expression, it is often easier for us to understand what the other person wants to express. At the same time, we can express ourselves better. The profession of an actor is a good example of body language. This is a compulsory course for every actor because actors can only use their performances to let us know what they are expressing &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. At this time, body language becomes extremely important. Different characters have different body movements in different situations, and actors need to make the right body language at a specific time to let the audience know their inner feelings. Yes, the most important point of body language is to convey mood through movement.&lt;/p&gt;
&lt;p&gt;In many cases, certain actions will make people feel emotions. For us who communicate with all kinds of people every day, there are also many body languages that we are more familiar with. For example, when a person hangs his head, it means that he is unhappy, walking back and forth is a sign of a person&amp;rsquo;s anxiety, and body shaking is caused by nervousness, etc.&lt;/p&gt;
&lt;h4 id=&#34;322-body-gesture-and-big-data&#34;&gt;3.2.2 Body Gesture and Big Data&lt;/h4&gt;
&lt;p&gt;As a piece of big data, body language requires data collected by studying human movements. Scientists found that when a person wants to convey a complete message, body language accounts for half. And because body language belongs to a person&amp;rsquo;s actions subconsciously, it is rarely deceptive. All of your nonverbal behaviors—the gestures you make, your posture, your tone of voice, how many eyes contact you make—send strong messages &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. In many cases, these unconscious messages from our bodies allow the people who communicate with us to feel our intentions. Even when we stop talking, these messages will not stop. This also explains why scientists want to collect data to let artificial intelligence understand human behavior. In order for artificial intelligence to understand human mood or intention from people&amp;rsquo;s body postures and actions, scientists have collected a lot of human body actions that show intentions in different situations through research. The music gesture artificial intelligence developed by MIT-IBM Watson AI Lab is a good example &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;. The music gesture artificial intelligence developed by MIT-IBM Watson AI Lab can enable artificial intelligence to judge and isolate the sounds of individual instruments through body and gesture movements. This success is undoubtedly created by the big data of the entire body and gestures. The research room collects a large number of human structure actions to provide artificial intelligence with a large amount of information so that the artificial intelligence can judge what melody the musician is playing through body gestures and key points of the face. This can improve its ability to distinguish and separate sounds when artificial intelligence listens to the entire piece of music.&lt;/p&gt;
&lt;p&gt;Most of the artificial intelligence&amp;rsquo;s analysis of the human body requires facial expressions and body movements. This recognition cannot be achieved only by calculation. What is needed is the collection of the meaning of different body movements of the human body by a large database. The more situations are collected, the more accurate the analysis of human emotions and intentions by artificial intelligence will be. The easiest way is to include more. Just like humans, broadening your horizons is a way to better understand the world. The way of recording actions is not complicated. Just set several key movable joints of the human body to several points, and then connect the red dots with lines to get the approximate shape of the human body. At this time, the actions made by the human body will be included in the artificial intelligence. In the recording process, the upper body and lower body can be recorded separately. In order to avoid in some cases, the existence of obstructions will cause artificial intelligence to fail to recognize correctly.&lt;/p&gt;
&lt;h4 id=&#34;323-random-forest-algorithm-in-body-gesture-recognition&#34;&gt;3.2.3 Random Forest Algorithm in Body Gesture Recognition&lt;/h4&gt;
&lt;p&gt;Body gesture recognition is pretty useful but pretty hard to achieve because of its limitations and harsh requirements. Without the development of all kinds of 3D cameras, body gesture recognition is just an unrealistic dream. In order to get important and precise data for the body gesture recognition to process, different angles, light, background all needs to be captured &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;. For body gestures, the biggest difficulty is that if you only capture data in the front, it will not give you the correct information and result in most of the time. In this way, you will need precise data from different angles. A Korean team has done an experiment using three 3D cameras and three stereo cameras to capture images and record data from different angles. The data were recorded in a large database that includes captured data both from outside and inside. One of the most popular algorithms used in body gesture recognition is the random forest algorithm. It is very famous and useful in all types of machine learning projects. It is a type of supervised learning algorithm. Because there are all types of data are needed to be a record and process. The random forest algorithm is perfect for that, the biggest advantage of this algorithm is that it can let each individual tree mainly focus on one part or one characteristic of body gesture data because of this algorithm’s ability to combine all weak classifiers into a strong one &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;. It is simple but so powerful and efficient. In addition to that, it works really well with body gesture recognition. With the algorithm and advanced cameras, precise data could be collected and AIs will be able to get useful information at different levels.&lt;/p&gt;
&lt;h3 id=&#34;33-face-gesture&#34;&gt;3.3 Face Gesture&lt;/h3&gt;
&lt;h4 id=&#34;331-introduction-to-face-gesture-facial-expression&#34;&gt;3.3.1 Introduction to Face Gesture (Facial Expression)&lt;/h4&gt;
&lt;p&gt;Body language is one of the ways that we can express ourselves without saying any words. It has been suggested that body language may account for between 60 to 65% of all communication &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. According to expert, body language is used every day for us to communicate with each other. During our communication, we not only use words but also use body gestures, hand gestures and most importantly, we use facial expression most. During communication with different people, our face communicate different thoughts, idea, and emotion and the reason why we use facial expression more than any other body gestures is that when we have certain emotion, it is express in our face automatically. Facial expression is often not under our control. That is why people often say that the word that come out of mouth cannot always be true, but their facial expression will reveal what those people are thinking about. So, what is facial expression exactly? According to Jason Matthew Harley, Facial expressions are configurations of different micromotor movements in the face that are used to infer a person’s discrete emotional state &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;. Some example of common facial expression will be: Happiness, Sadness, Anger, Surprise, Disgust, Fear, etc &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. Each facial expression will have some deep meaning behind it. For example, A simple facial expression like smiling can be translated into a sign of approval, or it can be translated into a sign of friendly. If we put all those emotion into big data, it will help us to understand ourselves much better.&lt;/p&gt;
&lt;h4 id=&#34;332-sense-organs-on-the-face&#34;&gt;3.3.2 Sense Organs on The Face&lt;/h4&gt;
&lt;p&gt;The facial expression expresses our emotion during the communication by micro movement of our sense organs. The most used organs are the eyes and mouth and sometimes, the eyebrows.&lt;/p&gt;
&lt;h5 id=&#34;3321-eye&#34;&gt;3.3.2.1 Eye&lt;/h5&gt;
&lt;p&gt;The eyes are one of the most important communication tools in our ways of communication with each other. When we communicate with each other, the eye contact will be inevitable. The signal in your eye will tell people what you are think. 
Eye gaze is a sample of paying attention when communicating with others. When you are talking to a person and if his eye is directly on you and both of you keep having eye contact. In this situation, this mean that he is interested in what you say and is paying attention to what you say. On the other hand, if the action of breaking eye contact happens very frequently, it means that he is not interested, distracted, or not paying attention to you and what you are saying.&lt;/p&gt;
&lt;p&gt;Blinking is another eye signal that is very often and will happen in communicating with other people. When talking to other people, blinking is very usual and will happen every time when you are going to communicate with different people. But the frequency of blanking can give away what are you feeling right now. People often blink more rapidly when they are feeling distressed or uncomfortable. Infrequent blinking may indicate that a person is intentionally trying to control his or her eye movements &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. For example, when A person is lying, he might try to control his blinking frequency to make other people feel like he is calm and saying the truth. In order to persuade other people that he is calm and telling the truth, he will need to blink less frequently.&lt;/p&gt;
&lt;p&gt;Pupil size is a very important facial expression. Pupil size can be a very subtle nonverbal communication signal. While light levels in the environment control pupil dilation, sometimes emotions can also cause small changes in pupil size &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. For example, when you are surprised by something, your pupil size will become noticeably larger than before. When having a communication, dilated eyes can also mean that the person is interesting in the communication.&lt;/p&gt;
&lt;h5 id=&#34;3322-mouth&#34;&gt;3.3.2.2 Mouth&lt;/h5&gt;
&lt;p&gt;Mouth expression and movement will also be a huge part in communicating with other and reading body language. The easiest example will be smiling. A micro movement of your mouth and lip will give signal to others about what do you think or how are you feeling. 
When you tighten your lips, it means that you either distaste, disapprove or distrust other people when having a conversation.
When you bite your lips, it means that you are worried, anxious, or stressed.
When someone tries to hide certain emotional reaction, they tend to cover their mouth in order not to display any facial expression through lip movement. For example, when you are laughing. 
The simple movement of turning up or down of the lip will also indicate what a person is feeling. When the mouth is slightly turn up, it might mean that the person is either feeling happy or optimistic. On the other hand, a slightly down-turned mouth can be an indicator of sadness, disapproval, or even an outright grimace &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;333-facial-expression-and-big-data&#34;&gt;3.3.3 Facial Expression and Big Data&lt;/h4&gt;
&lt;p&gt;Nowadays, since technology is so advance, everything around us can be turn into data and everything can be related to data. Facial expression is often study by different scientist in research because it allows us to understand more about human and communication between different people. One of the relatively new and promising trends in using facial expressions to classify learners&#39; emotions is the development and use of software programs the automate the process of coding using advanced machine learning technologies. For example, FaceReader is a commercially available facial recognition program that uses an active appearance model to model participant faces and identifies their facial expression. The program further utilizes an artificial neural network, with seven outputs to classify learner’s emotions &lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;. Also, facial expression can be analyzed in other software programs like the Computer Expression Recognition Toolbox. Emotion is a huge study field in the technology field, and facial expression is one of the best ways to study and analyze people&amp;rsquo;s emotion. Emotion technology is becoming huge right now and will be even more popular in the future according to MIT Technology Review, Emotion recognition – or using technology to analyze facial expressions and infer feelings-is, by one estimate, set to be a $25 billion business by 2023 &lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;. So back to the topic about big data and facial expression. Why are those things related? It is because, first everything is data around us. Your facial expression can be stored into data for other to learn and detect too. One of the examples is that, in 2003, The US Transportation Security Administration started training humans to spot potential terrorists by reading their facial expression. And by that, scientist believe that if human can do that, with data and AI technology, robot can detect facial expression more accurate than human.&lt;/p&gt;
&lt;h4 id=&#34;334-the-problem-with-detecting-emotion-for-technology-nowadays&#34;&gt;3.3.4 The Problem with Detecting Emotion for Technology Nowadays&lt;/h4&gt;
&lt;p&gt;Even though facial expression can reveal people&amp;rsquo;s emotion and what they think, but there has been &amp;ldquo;growing pushback&amp;rdquo; against the statement. A group of scientists brought together a research after reviewing more than 1,000 paper on emotion detection. After the research, the conclusion of it is hard to use facial expressions alone to accurately tell how someone is feeling is made. Human&amp;rsquo;s mind is very hard to predict. People do not always cry when they feel down and smile when they feel happy. The facial expression can not always reveal the true feeling the person is feeling. Not only that, because there is not enough data for facial expression, people will often mistakenly categorize other&amp;rsquo;s facial expression. For example, Kairos, which is a facial biometrics company, promise retailers that it can use a emotion recognition technology to figure out how their customers are feeling. But when they are labeling the data to feed the algorithm, one big problem reveals. An observer might read a facial expression as &amp;ldquo;surprised,&amp;rdquo; but without asking the original person, it is hard to know what the real emotion was &lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;. So the problems with technology that involves around facial expression are first, there is not enough data. Second is that facial expression sometimes can not be always true.&lt;/p&gt;
&lt;h4 id=&#34;335-classification-algorithms&#34;&gt;3.3.5 Classification Algorithms&lt;/h4&gt;
&lt;p&gt;Nowadays, since technology is growing so fast, there are a lot of interaction between humans and computer. Facial expression plays an essential role in social interaction with other people. It is not arguably one of the best ways to understand human. &amp;ldquo;It is reported that facial expression constitutes 55% of the effect of a communicated message while language and voice constitute 7% and 38% respectively. With the rapid development of computer vision and artificial intelligence, facial expression recognition becomes the key technology of advanced human computer interaction &lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;.&amp;rdquo; This quote from the research shows that facial expression is one of the main tools that we are using to communicate with other people and interact with computer. So being able to recognize and identify the facial expression becomes relatively important. The main objective for facial expression recognitions is to use its conveying information automatically and correctly. As a result, feature extraction is very important to the facial expression recognition process. The process needs to be smooth and without any mistakes. So, algorithms are needed in the processes. Classification analysis is an important component of facial recognition, it is mainly used to find data distribution that is valuable and at the same time, find data models in the potential data. At present it has further study of the database, data mining, statistics, and other fields &lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;. In addition to that, one of the major obstacles and limitation of facial expression recognition is face detection. To detect the face, you will need to locate the faces in an image or a photograph. This is where scientists applicate classification algorithm, machine learning and deep learning. Recently, convolutional neural network model has become so successful that facial recognition is the next top wave &lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;4-conclusion&#34;&gt;4. Conclusion&lt;/h2&gt;
&lt;p&gt;With the development of artificial intelligence, human-computer interaction, big data, and machine learning even deep learning is getting more mature. Gesture Recognition including Hand Gesture Recognition, Body Gesture Recognition, and Face Gesture Recognition has finally come true into a real-life application and already achieved huge success in many areas. But it still has much more potential in all possible areas that could change people&amp;rsquo;s lives drastically in a good way. Gestures are the simplest and the most natural language of all human beings. It sends the clearest message for communicating between people, and even human and computers. Because of the more powerful cameras, better big data technology, and more efficient and effective algorithms from deep learning, Scientists are able to use color and the Gesture Segmentation method to remove useless color data in order to maximize the accuracy of the result. As we are doing our research, we also find out Hand Gesture Recognition is not the only Recognition in this area, Body Gesture Recognition and Face Gesture Recognition or facial expression are also very important, they can also deliver messages in the simplest way. They are also very effective when building relationships between humans and machines. Face Gesture or facial expression could not only deliver messages but even deliver emotions. Micromovements of facial expressions studied by different scientists could be very useful in predicting the emotions of humans. Body Gesture Recognition is also helpful as we did our research with the body gesture data scientists collected from different musicians with different instruments. They are able to predict the melodies or even the songs played by that musician. This is mind-blowing because with this type of technology and applications we are able to achieve more and use it in many possible fields. With all these combined, scientists could build a very successful and mature Gesture Recognition model to get the most accurate result or prediction. According to the research and our own analysis, we come up with a conclusion that Gesture Recognition will be the next hot trendy topic and are applicable in many possible areas including Security, AI, economics, manufacture, the game industry, and even medical services. With Gesture Recognition being applied, scientists are able to develop much smarter AIs and machines that can interact with humans more efficiently and more fluently. AIs will be able to receive and understand messages from humans more easily and will able to function better. This is also a great message for many handicapped people. With Hand Gesture Recognition being used, their life will also be easier and happier and that’s definitely something we are want to see because the overall goal of all the technologies is to make people&amp;rsquo;s life easier and bring the greatest amount of happiness to the greatest amount of people. However, the technology we have right now is not advanced enough yet, in order to get a more accurate result, we still need to develop better cameras, better algorithms, and better models. But we all believe that this era is the big data era, and everything could happen as big data and deep learning technology get more and more advanced and mature. We believe in and look forward to the beautiful future of Gesture Recognition. And we also think people should really pay more and closer attention to this field since Gesture Recognition is the next wave.&lt;/p&gt;
&lt;h2 id=&#34;5-references&#34;&gt;5. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Srilatha, Poluka, and Tiruveedhula Saranya. &amp;ldquo;Advancements in Gesture Recognition Technology.&amp;rdquo; IOSR Journal of VLSI and Signal Processing, vol. 4, no. 4, 2014, pp. 01–07, iosrjournals.org/iosr-jvlsi/papers/vol4-issue4/Version-1/A04410107.pdf, 10.9790/4200-04410107. Accessed 25 Oct. 2020.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Bazarevdsky, V., &amp;amp; Zhang, F. (2019, August 19). On-device, real-time hand tracking with MediaPipe. Google AI Blog. &lt;a href=&#34;https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html&#34;&gt;https://ai.googleblog.com/2019/08/on-device-real-time-hand-tracking-with.html&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;F. Zhan, &amp;ldquo;Hand Gesture Recognition with Convolution Neural Networks,&amp;rdquo; 2019 IEEE 20th International Conference on Information Reuse and Integration for Data Science (IRI), Los Angeles, CA, USA, 2019, pp. 295-298, doi: 10.1109/IRI.2019.00054.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Di Zhang, DZ.(2019) Research on Hand Gesture Recognition Technology Based on Machine Learning, Nanjing University of Posts and Telecommunications.&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;A. Choudhury, A. K. Talukdar and K. K. Sarma, &amp;ldquo;A novel hand segmentation method for multiple-hand gesture recognition system under complex background,&amp;rdquo; 2014 International Conference on Signal Processing and Integrated Networks (SPIN), Noida, 2014, pp. 136-140, doi: 10.1109/SPIN.2014.6776936.&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Cherry, K. (2019, September 28). How to Read Body Language and Facial Expressions. Verywell Mind. Retrieved November 8, 2020, from &lt;a href=&#34;https://www.verywellmind.com/understand-body-language-and-facial-expressions-4147228&#34;&gt;https://www.verywellmind.com/understand-body-language-and-facial-expressions-4147228&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Segal, J., Smith, M., Robinson, L., &amp;amp; Boose, G. (2020, October). Nonverbal Communication and Body Language. HelpGuide.org. &lt;a href=&#34;https://www.helpguide.org/articles/relationships-communication/nonverbal-communication.htm&#34;&gt;https://www.helpguide.org/articles/relationships-communication/nonverbal-communication.htm&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Martineau, K. (2020, June 25). Identifying a melody by studying a musician’s body language. MIT News | Massachusetts Institute of Technology. &lt;a href=&#34;https://news.mit.edu/2020/music-gesture-artificial-intelligence-identifies-melody-by-musician-body-language-0625&#34;&gt;https://news.mit.edu/2020/music-gesture-artificial-intelligence-identifies-melody-by-musician-body-language-0625&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;N. Normani et al., &amp;ldquo;A machine learning approach for gesture recognition with a lensless smart sensor system,&amp;rdquo; 2018 IEEE 15th International Conference on Wearable and Implantable Body Sensor Networks (BSN), Las Vegas, NV, 2018, pp. 136-139, doi: 10.1109/BSN.2018.8329677.&amp;#160;&lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Bon-Woo Hwang, Sungmin Kim and Seong-Whan Lee, &amp;ldquo;A full-body gesture database for automatic gesture recognition,&amp;rdquo; 7th International Conference on Automatic Face and Gesture Recognition (FGR06), Southampton, 2006, pp. 243-248, doi: 10.1109/FGR.2006.8.&amp;#160;&lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:11&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Harley, J. M. (2016). Facial Expression. ScienceDirect. &lt;a href=&#34;https://www.sciencedirect.com/topics/computer-science/facial-expression&#34;&gt;https://www.sciencedirect.com/topics/computer-science/facial-expression&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:12&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Chen, A. (2019, July 26). Computers can’t tell if you’re happy when you smile. MIT Technology Review. &lt;a href=&#34;https://www.technologyreview.com/2019/07/26/238782/emotion-recognition-technology-artifical-intelligence-inaccurate-psychology/&#34;&gt;https://www.technologyreview.com/2019/07/26/238782/emotion-recognition-technology-artifical-intelligence-inaccurate-psychology/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:13&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Ou, J. (2012). Classification algorithms research on facial expression recognition. Retrieved from &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S1875389212006438&#34;&gt;https://www.sciencedirect.com/science/article/pii/S1875389212006438&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:13&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:14&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Brownlee, J. (2020, August 24). How to perform face detection with deep learning. Retrieved from &lt;a href=&#34;https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/&#34;&gt;https://machinelearningmastery.com/how-to-perform-face-detection-with-classical-and-deep-learning-methods-in-python-with-keras/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:14&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: Big Data in the Healthcare Industry</title>
      <link>/report/fa20-523-352/report/report/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-352/report/report/</guid>
      <description>
        
        
        &lt;p&gt;Cristian Villanueva, Christina Colon&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-352/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-352/workflows/Check%20Report/badge.svg&#34; alt=&#34;Check Report&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-352/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-352/workflows/Status/badge.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
Status: final, Type: Report&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-352/&#34;&gt;fa20-523-352&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-352/blob/main/report/report.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Healthcare is an organized provision of medical practices provided to individuals or a community. Over centuries the application of innovative healthcare has been needed increasingly as humans expand their life span and become more aware of better preventative care practices. The application of Big Data within the industry of Healthcare is of the utmost importance in order to quantify the effects of wide scale efficient and safe solutions. Pharmaceutical and Bio Data Research companies can use big data to intake large facets of patient record data and use this collected data to iterate how preventative care can be implemented before diseases actually present themselves in stages that are beyond the point of potential recovery. Data collected in laboratory settings and statistics collected from medical and state institutions of healthcare facilitate time, money, and life saving initiatives as deep learning can in certain instances perform better than the average doctor at detecting malignant cells. Big data within healthcare has proven great results for the advancement and diverse application of informed reasoning towards medical solutions.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1--introduction&#34;&gt;1.  Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-patient-records&#34;&gt;2. Patient Records&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-ehr-application-detecting-error-and-reducing-costs&#34;&gt;2.1 EHR Application: Detecting Error and Reducing Costs&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-ai-models-in-cancer-detection&#34;&gt;3. AI Models in Cancer Detection&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-early-detection-big-data-applications&#34;&gt;3.1 Early Detection Big Data Applications&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-detecting-cervical-cancer&#34;&gt;3.2 Detecting Cervical Cancer&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-artificial-intelligence-in-cardiovascular-disease&#34;&gt;4. Artificial intelligence in Cardiovascular Disease&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-deep-learning-techniques-for-genomics&#34;&gt;5. Deep Learning Techniques for Genomics&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-discussion&#34;&gt;6. Discussion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-conclusion&#34;&gt;7. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#8-acknowledgements&#34;&gt;8. Acknowledgements&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#9-references&#34;&gt;9. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; EHR, Healthcare, diagnosis, application, treatment, AI, network, records&lt;/p&gt;
&lt;h2 id=&#34;1--introduction&#34;&gt;1.  Introduction&lt;/h2&gt;
&lt;p&gt;Healthcare is a multi-dimensional system established with the aim of the prevention, diagnosis, and treatment of health-related issues or impairments in human beings&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. The many dimensions of Healthcare can be characterized by the influx of information coming and going from each level as there are multiple different applications of Healthcare. These applications can include but are not limited to vaccines, surgeries, x-rays, medicines/treatments. Big data plays a pivotal role in Healthcare diagnostics, predictions, and accelerated results/outcomes of these applications. Big Data has the ability to save millions of dollars through automating 40% of radiologist’s tasks, saving time on potential treatments through digital patients, and by providing improved outcomes&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. With higher accuracy rates of diagnosis and advanced AI is able to transform hypothetical analysis into data driven diagnosis and treatment strategies.&lt;/p&gt;
&lt;h2 id=&#34;2-patient-records&#34;&gt;2. Patient Records&lt;/h2&gt;
&lt;p&gt;EHR stands for &amp;lsquo;electronic health records&amp;rsquo; and is a digital version of a patient’s paper chart.The Healthcare industry utilizes EHR for maintaining records of everything related in their institutions. EHR are real-time, patient centred records that make information available instantly and securely to authorized users&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. EHR is capable of holding even more information as it is possible to include such information such as medical history, diagnoses, medications, treatment plans, immunization dates, allergies, radiology images, and laboratory and test results. According to Definitive Healthcare data from 2020, more than 89 percent of all hospitals have implemented inpatient or ambulatory EHR systems &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. A network of information surrounding a patient&amp;rsquo;s health record and medical data allows for the research and production of such progressive advancement in treatment. To underline the potential of the resources, more than 110 million EHRs around the continents were inspected for genetic disease research&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. This is the capability of EHRs as it holds information capable of diagnosing, preventing and treating other patients for early detection of an ailment or disease. Through the application of neural networks in Deep Learning models, EHR’s could be compiled and analyzed to identify inconspicuous indicators of disease development of patients in early stages far before a human doctor would be able to make a clear diagnosis. The application has the ability to work far ahead for preventive measures as well as the allocation of resources to make sure that patients are paying for the care at minimum costs, the appropriate method of medical intervention is applied, and physicians’ workload can become less strenuous.&lt;/p&gt;
&lt;h3 id=&#34;21-ehr-application-detecting-error-and-reducing-costs&#34;&gt;2.1 EHR Application: Detecting Error and Reducing Costs&lt;/h3&gt;
&lt;p&gt;In order to understand the impact that Big Data such as EHRs has on the Healthcare industry an example of research is presented in the form of collection before and after implementation of EHR. The research study collected data for the period of 1 year before EHR (pre-EHR) and 1 year after EHR (post-EHR) implementation. What was noticed in the analyzes of the data was in the area of &amp;lsquo;Medication errors and near misses&amp;rsquo; the research stated &amp;lsquo;medication errors per 1000 hospital days decreased 14.0%-from 17.9% in the pre-EHR period to 15.4% in the 9 months after CPOE implementation&amp;rsquo;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;. The research determined that with implementation of EHR with (CPOE) computerized provider order entry was able to reduce the costs of treatment and improvised upon the safety of their patients. Participants of the study mentioned that there was an increase in speed when it came to pharmacy, laboratory and radiology orders. The research also stated &amp;lsquo;our study demonstrated an 18% reduction in laboratory testing&amp;rsquo;. The study touched upon the rapidness that EHR can add to a process of treatment when orders are validated much quicker and hospitals and patients save money from the rapid diagnosis and treatment. This cuts out the middle-man of deliberate testing and examinations upon patients so they don’t have to cover the costs or undergo wasteful testing from their own EHR and other extensive EHR that it utilizes for comparison. Examples of models used in this example study include data mining through phenotyping and natural language processing. In this way data mining allows large sets of patient data to be aggregated in order to make inferences over a population or theories regarding how a disease will progress in any given patient. Phenotyping categorizes features of patients&#39; health and their DNA and ultimately their overall health. Association rule data mining helps automated systems in their predictions  in order to predict behavioral and health outcomes of patients’ circumstances.&lt;/p&gt;
&lt;h2 id=&#34;3-ai-models-in-cancer-detection&#34;&gt;3. AI Models in Cancer Detection&lt;/h2&gt;
&lt;p&gt;AI is modifying early detection of cancer as models are capable of being more accurate and precise with the analysis of mass and cell images. The difficulty of diagnosing cancer is because of the possibilities of either the mass being benign or malignant. The amount of time overlooking the cell nuclei and its features to either determine if it is malignant or benign can be staggering for oncologists. Utilizing the information of what&amp;rsquo;s known about cancer can train AI to be calibrated to scour through several images and screenings of cell nuclei to find the key indicators. These key indicators can also be whittled down even further as there is AI to determine which indicators have the highest correlation with malignant cancer. As a dataset from Kaggle consisting of 569 cases of malignant and benign breast cancer, it represented 357 cases of benign and 212 of malignant. With that information there were initially 33 features that may have indicated malignancy in these cases. The 33 features were reduced to 10 features as not all of them equally displayed the same level of contribution to the diagnosis. Across the 10 features there were 5 features that demonstrated the highest correlation to the malignancy. Several models were adapted to find the highest accuracy and precision. This form of AI detection improves upon the efficacy of early cancer detection.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-352/raw/main/report/images/aimodels.PNG&#34; alt=&#34;AI Models Demonstrate Accuracy &amp; Precision&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1.&lt;/strong&gt; Demonstrates how AI in this study used images to cross-analyze features of a patient&amp;rsquo;s results to verify what model is the most accurate and precise to determine which model can best serve a physician in their diagnostic report.&lt;/p&gt;
&lt;h3 id=&#34;31-early-detection-big-data-applications&#34;&gt;3.1 Early Detection Big Data Applications&lt;/h3&gt;
&lt;p&gt;&amp;lsquo;An ounce of prevention is worth more than a pound of a cure&amp;rsquo; is a common philosophy held by medical professionals. The meaning behind this ideology is found in that if one can prevent a disease from ever taking its final form through performing small routine tasks and check ups, a plethora of harm and suffering from trying to recage a disease can be avoided. Many medical solutions for diseases such as cancer or degenerative brain diseases rely on the idea that outside medical intervention will strengthen the patient enough for the human body to heal itself through existing biological principles &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. For example, vaccines work by injecting dead cells into a patient so that its antibodies can be learned and immunity can be built up by white blood cells naturally. Intervening before one is infected must be completed for these measures to be effective. If preventative care such as routine screenings on individuals with family history of diseases or those with general genetic predispositions then the power truly lies in having the discernment knowledge to catch the disease early. In many diseases once a patient is presenting symptoms, it is too late or survival/recovery probability percentages are slashed. This places immense pressures on patients themselves to work to have access to routine screenings and even more pressure on physicians to intake these patients and make preliminary diagnosis with little more than a visual analysis of the patient. Big data automates these tasks and gives physicians an incredible advantage and discernment as to what is truly happening within a patient’s circumstance.&lt;/p&gt;
&lt;h3 id=&#34;32-detecting-cervical-cancer&#34;&gt;3.2 Detecting Cervical Cancer&lt;/h3&gt;
&lt;p&gt;Cervical cancer in the past was one of the most common causes of cancer death for women in the United States. However preventive care in the form of pap test has been able to drop the death rate significantly. In the pap test images are taken of the women’s cervix to identify any changes that might indicate cancer is going to form. Cervical cancer has a much higher death rate without early detection as a cure is easier to take full effect in the early stages. Artificial Intelligence performs an algorithm and gives the computer the ability to act and reason based on a set of known information. Machine learning implements more data and allows the computer to work iteratively and make predictions and make decisions based on the massive amount of data provided. In this way, machines have had the ability to detect cervical cancer with greater precision and accuracy in some cases than gynecologists &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. Imaging of cervical screenings targeted by a convolution neural network is the key to unlocking correlations behind the large sum of images. By implementing further reasoning into the data set, the CNN is able to  classify enhanced recognition of cancer as or before it forms. This study using this method of machine learning has been able to perform with 90-96% accuracy and save lives. The CNN is able to identify the colors, shapes, sizes, edges and other features pertaining to cancerous cells.&lt;/p&gt;
&lt;p&gt;This is ground breaking for women in underdeveloped countries like India and Nigeria where the death rate for cervical cancer is much higher than the United States due to lack of access to routine pap smears. Women could get results on their cervical cancer status even if they do not get a pap smear every 3 years as recommended by doctors. For example if a woman in Nigeria has her first pap smear at the age of 40 when the recommended age to start pap smears is 21 she has gone unchecked for nearly 20 years and the early detection window is narrowed. However, if she is one of the 20% of women who get cervical cancer over the age of 65, a deep learning analysis of her pap smear at 40 could save her life and roadblock potential suffering. Early detection is key and big data optimizes early detection windows by providing a deeper analysis in the preventive care stages. From here doctors are able to implement the best care plan available on a case by case basis.&lt;/p&gt;
&lt;h2 id=&#34;4-artificial-intelligence-in-cardiovascular-disease&#34;&gt;4. Artificial intelligence in Cardiovascular Disease&lt;/h2&gt;
&lt;p&gt;AI in cardiovascular disease models are innovating disease detection by segmenting different types of analysis together for more efficient and accurate results. Being that cardiovascular diseases typically agitate/involve the heart and lungs there are numerous dynamics surrounding why a person is experiencing certain symptoms or at risk for development of a more critical diagnosis. Immense amount of labor is included in the diagnosis and treatment of individuals with cardiovascular disease on behalf of general physicians, specialists, nurses, and several other medical professionals. Artificial intelligence has the capability to add a layer of ease and accuracy that is involved in analyzing a patient&amp;rsquo;s status or risk for cardiovascular disease. AI is able to overcome the challenges of low quality pixelated images from analyzes and draw clearer and more accurate conclusions at a stage where more prevention strategies can be implemented. AI in this sense is able to analyze the systems of the human body as a whole as opposed to a doctor which might have several appointments with a patient to determine results from evaluations on lungs, heart, etc. By segmenting x-rays from numerous patients AI is able to learn and grow its data set to produce increasingly accurate and precise results[^8].
By using a combination of recurrent neural networks and convolutional neural networks artificial intelligence is able to go beyond what currently exists in terms of medical analysis and provide optimum results for patients in need. Recurrent neural networks function by building upon past data in order to create new output in series. They work hand in hand with Convolutional Neural networks which focus on analyzing advanced imagery based on qualitative data and can weigh biases on potential prescriptive outcomes.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-352/raw/main/report/images/cardioai.PNG&#34; alt=&#34;AI Learning Wireframe&#34;&gt;[^10]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.&lt;/strong&gt; Demonstrates a wireframe of how data is computed to draw relevant conclusions from thousands of images and pinpoint exact predictions of diagnosis. Risk analysis is crucial for heart attack prevention and understanding how suspeectable a person is to heart failure. Being that heart attacks can lead to strokes due to loss of blood and oxygen to the brain, these imaging tools serve as an invaluable life saving mechanism to help bring prevention to the forefront of these medical emergencies.&lt;/p&gt;
&lt;h2 id=&#34;5-deep-learning-techniques-for-genomics&#34;&gt;5. Deep Learning Techniques for Genomics&lt;/h2&gt;
&lt;p&gt;A digital patient is the idea that a patient’s health record can be compiled with live and exact biometrics for the purpose of testing. Through this method medical professionals will have the ability to propose new solutions to patients and monitor potential effects of operations or medicines over a period of time in a condensed/rapid results format. Essentially if a patient would be able to see how their body reacts to medical procedures before they are performed. The digital copy of a patient would receive simulated trial treatments to better understand what would happen over a period of time if the solution was adopted. For example, a patient would be able to verify with their physician what type of diuretics, beta inhibitors, or angiotensin receptor blocker medication would be the most effective solution to their hypertension regulatory needs[^11]. Physicians would be able to mitigate the risks and side effects associated with a certain solution given a patients expected behavior in response to what has been uploaded to the model.
In order to produce deep learning results, models must be implemented by indicating genetic markers by which computational methods can traverse the genetics strands and draw relevant conclusions. In this way data can be processed to propose changes to disease carrying chains of DNA or fortify immune based responses in those who are immunocompromised[^9].&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-352/raw/main/report/images/genomics.PNG&#34; alt=&#34;Genomics Illustration&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3.&lt;/strong&gt;  Illustrates how genes are analyzed through data collection methods such as EHR, personal biometric data, and family history in order to track what type of disease poses a threat and how to prevent, predict, and treat disease at the molecular level. Producing accurate methods of treatments, medications as well as predictions without having to put the patient through any trials.&lt;/p&gt;
&lt;h2 id=&#34;6-discussion&#34;&gt;6. Discussion&lt;/h2&gt;
&lt;p&gt;In considering the numerous innovations made possible by Big Data one can expect major impacts on society as we know it. Access to these types of data solutions should be made accessible to all those who are in need. Collectively an effort must be made to promote equitable access to life saving artificial intelligence discussed in this report. Processing  power and lack of resources stand as a barrier to widespread access to proper testing. However, governments and industries in the private sector must work together to avoid monopolies and price gouging limitations to such valuable data and computing models.
With further investment into deep learning models error margins can be narrowed and risk percentages and be slimmed pertaining to prescriptive analysis in specific use cases. The more access to information and examples are available, the better and more advanced a deep learning system can become. With the addition of electronic health records and past analysis artificial intelligence has the power to exponentially revolutionize the healthcare industry. By providing patients with services that could save their lives there is more incentive to stay involved in personal health as computation is optimized targeting patients for more results focused visits to the doctor. Doctors themselves are able to be relieved of a portion of the workload and foster a greater work life balance through cutting down on testing time and having more time to interact with patients for educational informative appointments. Legally medical professionals will be able to use prediction errors as alternative signals to further analyze a patient and justify treatment measures. Using data visualization of potential outcomes via a specific treatment method will empower patients and doctors to choose the pathway with the most favorable outcome.Convolutional Neural Networks within deep learning is one of the if not the most essential form of algorithm for AI in healthcare. CNN allows images to be input in a way that allows for learnable weights and biases to be calculated for and differentiate and match aspects of images that would go unknown to the human eye. Through identifying the edges, shape, size, color, amount of scarring CNN is able to identify cancerous and non-cancerous cells into five categories: normal, mild, moderate, severe, and carcinoma. Accuracy in this space is above 95% and creates a new opportunity space for medical professionals to provide their patients with a high level of accuracy and timely action planning for treatment and recovery[^13]. Beyond human healthcare CNN modeling has the potential to transfer into the realm of veterinary medicine, agricultural engineering, and sustainable environment initiatives to detect invasive species and similar disease development. Dogs or cats with cancer or heart worm could be analyzed in order to determine that with their heredity/breed and life span what are the chances and timeline for disease development. Crop production could be amplified with the processing of plant genomes in combination with soil to foresee what combination will produce the most abundant and profitable harvest. Lastly, ecosystems distrubed by global warming have the capability of being studied with CNN in order to factor in changes to the environment and what solutions could be on the horizon. With enough sample collection the power of CNN has the capability of securing a brighter future for tomorrow.&lt;/p&gt;
&lt;h2 id=&#34;7-conclusion&#34;&gt;7. Conclusion&lt;/h2&gt;
&lt;p&gt;Healthcare is an essential resource to living a long life and without it we can see our lifespan slashed nearly in half or even more for those who are hindered by hereditary ailments. Healthcare has been around as long as medicine and such other treatments have been around and that was centuries ago. The field has expanded well beyond what could’ve been expected for any medical professional or institution. Where the information and resources are available to save and care for the life before them even when a lack of training can hinder them the resources are present. It&amp;rsquo;s come to be such an accomplishment to mesh the medical practices of many medical professionals and Big Data to develop the largest compendium of medical practices in the world. By the allowance of such an asset many are able to collaborate with new findings and reinforcing old findings as these prevalent results allow physicians to work without faltering over inconclusive findings. The goal for this area of Big Data is to continue making the EHR system more secure and friendly towards medical professionals in different areas of practice as well as allowing easy access for patients who seek out their own medical history. The more advancements in this area of Healthcare can be applicable to other fields that must reference the compendium that maintains individuals and their history going forward. Such a structure will continue to aid generations of physicians and patients alike and can aid technological advancements along the way.&lt;/p&gt;
&lt;h2 id=&#34;8-acknowledgements&#34;&gt;8. Acknowledgements&lt;/h2&gt;
&lt;p&gt;We would like to thank Dr Gregor von Laszweski for allowing us to complete this report despite the delays there was as well as the lack of communication. We would also like to thank the AI team for their commitment to assisting in this class as even through a pandemic they continued to help the students complete the course. We would also like to thank Dr. Geoffrey Fox for teaching the course and making the class as informative as possible given his experience with the field of Big Data.&lt;/p&gt;
&lt;h2 id=&#34;9-references&#34;&gt;9. References&lt;/h2&gt;
&lt;p&gt;[^8] Arslan, M., Owais, M., &amp;amp; Mahmood, T. Artificial Intelligence-Based Diagnosis of Cardiac and Related Diseases (2020, March 23). Retrieved December 13, 2020 from &lt;a href=&#34;https://www.mdpi.com/2077-0383/9/3/871/htm&#34;&gt;https://www.mdpi.com/2077-0383/9/3/871/htm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[^9] Eraslan, G., Avsec, Z., Gagneur, J., &amp;amp; Theis, Fabian J.. Deep learning: new computational modelling techniques for genomics. (2019, April 10). Retrieved December 14, 2020 from &lt;a href=&#34;https://www.nature.com/articles/s41576-019-0122-6&#34;&gt;https://www.nature.com/articles/s41576-019-0122-6&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[^10] 1Regina. AI to Detect Cancer. (2019, November 22). Retrieved December 14, 2020 from &lt;a href=&#34;https://towardsdatascience.com/ai-for-cancer-detection-cadb583ae1c5&#34;&gt;https://towardsdatascience.com/ai-for-cancer-detection-cadb583ae1c5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[^11] Koumakis, L. Deep learning models in genomics; are we there yet? (2020). Retrieved December 14, 2020 from &lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S2001037020303068&#34;&gt;https://www.sciencedirect.com/science/article/pii/S2001037020303068&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[^12] Ross, M.K., Wei, W., &amp;amp; Ohno-Machado, L., &amp;lsquo;Big Data&amp;rsquo; and the Electronic Health Record (2014, August 15). Retrieved 15, 2020 from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4287068/&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4287068/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[^13] P, Shanthi. B., Faruqi, F., K, Hareesha, K., &amp;amp; Kudva, R., Deep Convolution Neural Network for Malignancy Detection and Classification in Microscopic Uterine Cervex Cell Images (2019, November 1). Retrieved December 15, 2020 from &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/31759371/&#34;&gt;https://pubmed.ncbi.nlm.nih.gov/31759371/&lt;/a&gt;&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Laney, D., AD. Mauro, M., Gubbi, J., Doyle-Lindrud, S., Gillum, R., Reiser, S., . . . Reardon, S. Big data in healthcare: Management, analysis and future prospects (2019, June 19). Retrieved December 10, 2020, from &lt;a href=&#34;https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0217-0&#34;&gt;https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0217-0&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;What is an electronic health record (EHR)? (2019, September 10). Retrieved December 10, 2020 from &lt;a href=&#34;https://www.healthit.gov/faq/what-electronic-health-record-ehr&#34;&gt;https://www.healthit.gov/faq/what-electronic-health-record-ehr&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Moriarty, A. Does Hospital EHR Adoption Actually Improve Data Sharing? (2020, October 23) Retrieved December 10, 2020 from &lt;a href=&#34;https://blog.definitivehc.com/hospital-ehr-adoption&#34;&gt;https://blog.definitivehc.com/hospital-ehr-adoption&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Cruciana, Paula A. The Implications of Big Data in Healthcare (2019, November 21) Retrieved December 11, 2020 from &lt;a href=&#34;https://ieeexplore.ieee.org/document/8970084&#34;&gt;https://ieeexplore.ieee.org/document/8970084&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Zlabek, Jonathan A. Early cost and safety benefits of an inpatient electronic health record (2011, February 2) Retrieved December 10, 2020 from &lt;a href=&#34;https://academic.oup.com/jamia/article/18/2/169/802487&#34;&gt;https://academic.oup.com/jamia/article/18/2/169/802487&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Artificial Intelligence-Oppurtunities in Cancer Research. (2020, August 31). Retrieved December 11, 2020 from &lt;a href=&#34;https://www.cancer.gov/research/areas/diagnosis/artificial-intelligence&#34;&gt;https://www.cancer.gov/research/areas/diagnosis/artificial-intelligence&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Zhang, R., Simon, G., &amp;amp; Yu, F. Advancing Alzheimer&amp;rsquo;s research: A review of big data promises. (2017, June 4) Retrieved December 11, 2020 from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5590222/&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5590222/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: Analysis of Various Machine Learning Classification Techniques in Detecting Heart Disease</title>
      <link>/report/fa20-523-309/project/project/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-309/project/project/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-309/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-309/workflows/Check%20Report/badge.svg&#34; alt=&#34;Check Report&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-309/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-309/workflows/Status/badge.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
Status: final, Type: Project&lt;/p&gt;
&lt;p&gt;Ethan Nguyen, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-309&#34;&gt;fa20-523-309&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-309/blob/main/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;As cardiovascular diseases are the number 1 cause
of death in the United States, the study of the factors and early detection and treatment could improve quality of life and lifespans. From investigating how the variety of factors related to cardiovascular health relate to a general trend, it has resulted in general guidelines to reduce the risk of experiencing a cardiovascular disease. However, this is a rudimentary way of preventative care that allows for those who do not fall into these risk categories to fall through. By applying machine learning, one could develop a flexible solution to actively monitor, find trends, and flag patients at risk to be treated immediately. Solving not only the risk categories but has the potential to be expanded to annual checkup data revolutionizing health care.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-datasets&#34;&gt;2. Datasets&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-dataset-cleaning&#34;&gt;2.1 Dataset Cleaning&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#22-dataset-analysis&#34;&gt;2.2 Dataset Analysis&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-machine-learning-algorithms-and-implementation&#34;&gt;3. Machine Learning Algorithms and Implementation&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-scikit-learn-and-algorithm-types&#34;&gt;3.1 Scikit-Learn and Algorithm Types&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-classification-algorithms&#34;&gt;3.2 Classification Algorithms&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#321-support-vector-machines&#34;&gt;3.2.1 Support Vector Machines&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#322-k-nearest-neighbors&#34;&gt;3.2.2 K-Nearest Neighbors&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#323-gaussian-naive-bayes&#34;&gt;3.2.3 Gaussian Naive Bayes&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#324-decision-trees&#34;&gt;3.2.4 Decision Trees&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#33-clustering-algorithms&#34;&gt;3.3 Clustering Algorithms&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#331-k-means&#34;&gt;3.3.1 K-Means&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#332-mean-shift&#34;&gt;3.3.2 Mean-shift&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#333-spectral-clustering&#34;&gt;3.3.3 Spectral Clustering&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#34-implementation&#34;&gt;3.4 Implementation&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#341-dataset-preprocessing&#34;&gt;3.4.1 Dataset Preprocessing&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-results--discussion&#34;&gt;4. Results &amp;amp; Discussion&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#41-algorithm-metrics&#34;&gt;4.1 Algorithm Metrics&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#411-support-vector-machines&#34;&gt;4.1.1 Support Vector Machines&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#412-k-nearest-neighbors&#34;&gt;4.1.2 K-Nearest Neighbors&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#413-gaussian-naive-bayes&#34;&gt;4.1.3 Gaussian Naive Bayes&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#414-decision-trees&#34;&gt;4.1.4 Decision Trees&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#415-k-means&#34;&gt;4.1.5 K-Means&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#416-mean-shift&#34;&gt;4.1.6 Mean-shift&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#417-spectral-clustering&#34;&gt;4.1.7 Spectral Clustering&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#42-system-information&#34;&gt;4.2 System Information&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#43-discussion&#34;&gt;4.3 Discussion&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-conclusion&#34;&gt;5. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-acknowledgements&#34;&gt;6. Acknowledgements&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; health, healthcare, cardiovascular disease, data analysis&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Since cardiovascular diseases are the number 1 cause of death in the United States, early prevention could help in extending one’s life span and possibly quality of life &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. Since there are cases where patients do not show any signs of cardiovascular trouble until an event occurs, having an algorithm predict from their medical history would help in picking up on early warning signs a physician may overlook. Or could also reveal additional risk factors and patterns for research on prevention and treatment. In turn this would be a great tool to apply in preventive care, which is the type of healthcare policy that focuses in diagnosing and preventing health issues that would otherwise require specialized treatment or is not treatable &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. This also has the potential to trickle down and increase the quality of life and lifespan of populations at a reduced cost as catching issues early most likely results in cheaper treatments &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;This project will take a high-level overview of common, widely available classification algorithms and analyze their effectiveness for this specific use case. Notable ones include, Gaussian Naive Bayes, K-Nearest Neighbors, and Support Vector Machines. Additionally, two data sets that contain common features will be used to increase the training and test pool for evaluation. As well as to explore if additional feature types contribute to a better prediction. The goal of this project being a gateway to further research in data preprocessing, tuning, or development of specialized algorithms as well as further ideas on what data could be provided.&lt;/p&gt;
&lt;h2 id=&#34;2-datasets&#34;&gt;2. Datasets&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/johnsmith88/heart-disease-dataset&#34;&gt;https://www.kaggle.com/johnsmith88/heart-disease-dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/sulianova/cardiovascular-disease-dataset&#34;&gt;https://www.kaggle.com/sulianova/cardiovascular-disease-dataset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The range of creation dates are 1988 and 2019 respectively with different features of which 4 are common between. This does bring up a small hiccup in preprocessing to consider. Namely the possibility of changing diet and culture trends resulting in significantly different trends/patterns within the same age group. As well as possible differences in measurement accuracy. However this large gap is within the scope of the project in exploring which features can help provide an accurate prediction.&lt;/p&gt;
&lt;p&gt;This possible phenomenon may be of interest to explore closely if time allows. Whether a trend itself is even present or there is an overarching trend across different cultures and time periods. Or to consider if this difference is significant enough that the data from the various sets needs to be adjusted to normalize the ages to present day.&lt;/p&gt;
&lt;h3 id=&#34;21-dataset-cleaning&#34;&gt;2.1 Dataset Cleaning&lt;/h3&gt;
&lt;p&gt;The datasets used have already been significantly cleaned from the raw data and has been provided as a csv file. These files were then imported into the python notebook as pandas dataframes for easy manipulation.&lt;/p&gt;
&lt;p&gt;An initial check was made to ensure the integrity of the data matched the description from the source websites. Then some preprocessing was completed to normalize the common features between the datasets. These features were gender, age, and cholesterol levels. The first two adjustments were trivial in conversion however, in the case of cholesterol levels, the 2019 set is on a 1-3 scale while the 1988 dataset provided them as real measurements. A conversion of the 1988 dataset was done based on guidelines found online for the age range of the dataset &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;22-dataset-analysis&#34;&gt;2.2 Dataset Analysis&lt;/h3&gt;
&lt;p&gt;From this point on, the 1988 dataset will be referred to as &lt;code&gt;dav_set&lt;/code&gt; and 2019 data set will be referred to as &lt;code&gt;sav_set&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To provide further insight on what to expect and how a model would be applied, the population of the datasets was analysed first. As depicted in Figure 2.1 the population samples of both datasets of gender vs age show the majority of the data is centered around 60 years of age with a growing slope from 30 onwards.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/agevssex.jpg&#34; alt=&#34;Figure 2.1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.1&lt;/strong&gt;: Age vs Gender distributions of the dav_set and sav_set.&lt;/p&gt;
&lt;p&gt;This trend appears to signify that the datasets focused solely on an older population or general trend in society of not monitoring heart conditions as closely in the younger generation.&lt;/p&gt;
&lt;p&gt;Moving on to Figure 2.2, we see an interesting trend with a significant growing trend in the sav_set in older population having more cardiovascular issues compared to the dav_set. While this cannot be seen in the dav_set. This may be caused by the additional life expectancy or a change in diet as noted in the introduction.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/agevstarget.jpg&#34; alt=&#34;Figure 2.2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.2&lt;/strong&gt;: Age vs Target distributions of the dav_set and sav_set.&lt;/p&gt;
&lt;p&gt;In Figure 2.3, the probability of having cardiovascular issues between the sets are interesting. In the dav_set the inequality of higher probability could be attributed to the larger female samples in the dataset. With the sav_set having a more equal probability between the genders.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/gendervsprobability.jpg&#34; alt=&#34;Figure 2.3&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.3&lt;/strong&gt;: Gender vs Probability of cardiovascular issues of the dav_set and sav_set.&lt;/p&gt;
&lt;p&gt;Finally, in Figure 2.4 is the probability vs cholesterol levels. This one is very interesting between the two datasets in terms of trend levels. With the dav_set having a higher risk at normal levels compared to the sav_set. This could be another hint of a societal change across the years or may in fact be due to the low sample size. Especially since the sav_set matches the general consensus of higher cholesterol levels increasing risk of cardiovascular issues &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/cholesterolvsprobability.jpg&#34; alt=&#34;Figure 2.4&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.4&lt;/strong&gt;: Cholesterol levels vs Probability of cardiovascular issues of the dav_set and sav_set.&lt;/p&gt;
&lt;p&gt;To close out this initial analysis is the correlation map of each of the features. From Figure 2.5 and 2.6 it can be concluded that both of these datasets are viable to conduct machine learning as the correlation factor is below the recommended value of 0.8 &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. Although we do see the signs of a low sample amount in the dav_set with a higher correlation factor compared to the sav_set.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/davsetcorrelation.jpg&#34; alt=&#34;Figure 2.5&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.5&lt;/strong&gt;: dav_set correlation matrix.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/savsetcorrelation.jpg&#34; alt=&#34;Figure 2.6&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2.6&lt;/strong&gt;: sav_set correlation matrix.&lt;/p&gt;
&lt;h2 id=&#34;3-machine-learning-algorithms-and-implementation&#34;&gt;3. Machine Learning Algorithms and Implementation&lt;/h2&gt;
&lt;p&gt;With many machine learning algorithms already available and many more in development. Selecting the optimal one for an application can be a challenging balance since each algorithm has both its advantages and disadvantages. As mentioned in the introduction, we will explore applying the most common and established algorithms available to the public.&lt;/p&gt;
&lt;p&gt;Starting off, is selecting a library from the most popular ones available. Namely Keras, Pytorch, Tensorflow, and Scikit-Learn. Upon further investigation it was determined that Scikit-Learn would be used for this project. The reason being Scikit-Learn is a great general machine learning library that also includes pre and post processing functions. While Keras, Pytorch, and Tensorflow are targeted for neural networks and other higher-level deep learning algorithms which are outside of the scope of this project at this time &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;31-scikit-learn-and-algorithm-types&#34;&gt;3.1 Scikit-Learn and Algorithm Types&lt;/h3&gt;
&lt;p&gt;Diving further into the Scikit-Learn library, its key strength appears to be the variety of algorithms available that are relatively easy to implement against a dataset. Of those available, they are classified under three different categories based on the approach each takes. They are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Classification
&lt;ul&gt;
&lt;li&gt;Applied to problems that require identifying the category an object belongs to.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Regression
&lt;ul&gt;
&lt;li&gt;For predicting or modeling continuous values.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clustering
&lt;ul&gt;
&lt;li&gt;Grouping similar objects into groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For this project, we will be investigating the Classification and Clustering algorithms offered by the library due to the nature of our dataset. Since it is a binary answer, the continuous prediction capability of regression algorithms will not fair well. Compared to classification type algorithms which are well suited for determining binary and multi-class classification on datasets &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. Along with Clustering algorithms being capable of grouping unlabeled data which is one of the key problem points mentioned in the introduction &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;32-classification-algorithms&#34;&gt;3.2 Classification Algorithms&lt;/h3&gt;
&lt;p&gt;The following algorithms were determined to be candidates for this project based on the documentation available on the Scikit-learn for supervised learning &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;321-support-vector-machines&#34;&gt;3.2.1 Support Vector Machines&lt;/h4&gt;
&lt;p&gt;This algorithm was chosen because classification is one of the target types and has a decent list of advantages that appear to be applicable to this dataset &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Effective in high dimensional spaces as well as if the number dimensions out number samples.&lt;/li&gt;
&lt;li&gt;Is very versatile.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;322-k-nearest-neighbors&#34;&gt;3.2.2 K-Nearest Neighbors&lt;/h4&gt;
&lt;p&gt;This algorithm was selected due to being a non-parametric method that has been successful in classification applications &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;. From the dataset analysis, it is appears that the decision boundary may be very irregular which is a strong point of this type of method.&lt;/p&gt;
&lt;h4 id=&#34;323-gaussian-naive-bayes&#34;&gt;3.2.3 Gaussian Naive Bayes&lt;/h4&gt;
&lt;p&gt;Is an implementation of the Naive Bayes theorem that has been targeted for classification. The advantages of this algorithm is its speed and requires a small training set compared to more advanced algorithms &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;324-decision-trees&#34;&gt;3.2.4 Decision Trees&lt;/h4&gt;
&lt;p&gt;This algorithm was chosen to investigate another non-parametric method to determine their efficacy against this dataset application. This algorithm also has some advantages over K-Nearest namely &lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Simple to interpret and visualize&lt;/li&gt;
&lt;li&gt;Requires little data preparation
&lt;ul&gt;
&lt;li&gt;Handles numerical and categorical data instead of needing to normalize&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Can validate the model and is possible to audit from a liability standpoint.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;33-clustering-algorithms&#34;&gt;3.3 Clustering Algorithms&lt;/h3&gt;
&lt;p&gt;The following algorithms were determined to be candidates for this project based on the table of clustering algorithms available on the Scikit-learn &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;331-k-means&#34;&gt;3.3.1 K-Means&lt;/h4&gt;
&lt;p&gt;The usecase for this algorithm is general purpose with even and low number of clusters &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. Of which the sav_set appears to have with the even distribution across most of the features.&lt;/p&gt;
&lt;h4 id=&#34;332-mean-shift&#34;&gt;3.3.2 Mean-shift&lt;/h4&gt;
&lt;p&gt;This algorithm was chosen for its strength in dealing with uneven cluster sizes and non-flat geometry &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. Though it is not easily scalable the application of our small dataset size might be of interest.&lt;/p&gt;
&lt;h4 id=&#34;333-spectral-clustering&#34;&gt;3.3.3 Spectral Clustering&lt;/h4&gt;
&lt;p&gt;As an inverse, this algorithm was chosen for its strength with fewer uneven clusters &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. In comparison to Mean-shift, this maybe the better algorithm for this application.&lt;/p&gt;
&lt;h3 id=&#34;34-implementation&#34;&gt;3.4 Implementation&lt;/h3&gt;
&lt;p&gt;The implementation of these algorithms were done under the direction of the documentation page for each respective algorithm. The jupyter notebook used for this project is available at &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-309/blob/main/project/data_analysis/ml_algorithms.ipynb&#34;&gt;https://github.com/cybertraining-dsc/fa20-523-309/blob/main/project/data_analysis/ml_algorithms.ipynb&lt;/a&gt; with each algorithm having a corresponding cell. A benchmarking library is also included to determine the efficiency of each algorithm in processing time. One thing of note is the lack of functions used for the classification compared to the clustering algorithms. The justification for this discrepancy is due to inexperience in creating optimal implementations as well as determining that not being implemented in a function would not have a significant impact on performance. Additionally, graphs representing the test data were included to help visualize the performance of the clustering algorithms utilizing example code from the documentation &lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;341-dataset-preprocessing&#34;&gt;3.4.1 Dataset Preprocessing&lt;/h4&gt;
&lt;p&gt;Pre-processing of the cleaned datasets for the classification algorithms was done under guidance of the scikit learn documentation &lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;. Overall, each algorithm was trained and tested with the same split for each run. While the split data could have been passed directly to the algorithms, they were normalized further using the built-in fit_transform function for the best results possible.&lt;/p&gt;
&lt;p&gt;Pre-processing of the cleaned datasets for the clustering algorithms was done under guidance of the scikit learn documentation &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. Compared to the classification algorithms, a dimensionality reduction was conducted using Principal component analysis (PCA). This step condenses the multiple features into a 2 feature array which the clustering algorithms were optimized for, increasing the odds for the best results possible. Another note is the dataset split was conducted during execution of the algorithm. Upon further investigation, it was determined that this does not have an effect on the ending results as the randomization was disabled due to setting the same random_state parameter for each call.&lt;/p&gt;
&lt;h2 id=&#34;4-results--discussion&#34;&gt;4. Results &amp;amp; Discussion&lt;/h2&gt;
&lt;h3 id=&#34;41-algorithm-metrics&#34;&gt;4.1 Algorithm Metrics&lt;/h3&gt;
&lt;p&gt;The metrics used to determine the viability of each of the algorithms are precision, recall, and f1-score. These are simple metrics based on the values from a confusion matrix which is a visualization of the False and True Positives and Negatives. Precision is essentially how accurate was the algorithm in classifying each data point. This however, is not a good metric to solely base performance as precision does not account for imbalanced distributions within a dataset &lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;This is where the recall metric comes in which is defined as how many samples were accurately classified by the algorithm. This is a more versatile metric as it can compensate for imbalanced datasets. While it may not be in our case as seen in the dataset analysis where we have a relatively balanced ratio. It still gives great insight on the performance for our application.&lt;/p&gt;
&lt;p&gt;Finally is the f1-score which is the harmonic mean of the precision and recall metric &lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;. This will be the key metric we will mainly focus on as it strikes a good balance between the two more primitive metrics. Since one may think in medical applications one would want to maximize recall, it is at the cost of precision which ends up in more false predictions which is essentially an overfitting scenario &lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;. Something that reduces the viability of the model to the application especially since we have a relatively balanced dataset, more customized weighting is not as necessary.&lt;/p&gt;
&lt;p&gt;The metrics for each algorithm implementation are as follows. The training time metric is provided by the cloudmesh.common benchmark library &lt;sup id=&#34;fnref:15&#34;&gt;&lt;a href=&#34;#fn:15&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;15&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h4 id=&#34;411-support-vector-machines&#34;&gt;4.1.1 Support Vector Machines&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Table 4.1:&lt;/strong&gt; dav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.94&lt;/td&gt;
&lt;td&gt;0.96&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.95&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.97&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;0.038 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Table 4.2:&lt;/strong&gt; sav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.94&lt;/td&gt;
&lt;td&gt;0.96&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.95&lt;/td&gt;
&lt;td&gt;0.99&lt;/td&gt;
&lt;td&gt;0.97&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;167.897 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;412-k-nearest-neighbors&#34;&gt;4.1.2 K-Nearest Neighbors&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Table 4.3:&lt;/strong&gt; dav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.88&lt;/td&gt;
&lt;td&gt;0.86&lt;/td&gt;
&lt;td&gt;0.87&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.87&lt;/td&gt;
&lt;td&gt;0.90&lt;/td&gt;
&lt;td&gt;0.88&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;0.025 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Table 4.4:&lt;/strong&gt; sav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.62&lt;/td&gt;
&lt;td&gt;0.74&lt;/td&gt;
&lt;td&gt;0.67&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.67&lt;/td&gt;
&lt;td&gt;0.54&lt;/td&gt;
&lt;td&gt;0.60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;10.116 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;413-gaussian-naive-bayes&#34;&gt;4.1.3 Gaussian Naive Bayes&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Table 4.5:&lt;/strong&gt; dav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.88&lt;/td&gt;
&lt;td&gt;0.81&lt;/td&gt;
&lt;td&gt;0.84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.83&lt;/td&gt;
&lt;td&gt;0.90&lt;/td&gt;
&lt;td&gt;0.86&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;0.011 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Table 4.6:&lt;/strong&gt; sav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.56&lt;/td&gt;
&lt;td&gt;0.90&lt;/td&gt;
&lt;td&gt;0.69&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.72&lt;/td&gt;
&lt;td&gt;0.28&lt;/td&gt;
&lt;td&gt;0.40&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;0.057 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;414-decision-trees&#34;&gt;4.1.4 Decision Trees&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Table 4.7:&lt;/strong&gt; dav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.92&lt;/td&gt;
&lt;td&gt;0.97&lt;/td&gt;
&lt;td&gt;0.95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.97&lt;/td&gt;
&lt;td&gt;0.93&lt;/td&gt;
&lt;td&gt;0.95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;0.009 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Table 4.8:&lt;/strong&gt; sav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.71&lt;/td&gt;
&lt;td&gt;0.80&lt;/td&gt;
&lt;td&gt;0.75&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.76&lt;/td&gt;
&lt;td&gt;0.66&lt;/td&gt;
&lt;td&gt;0.71&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;0.272 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;415-k-means&#34;&gt;4.1.5 K-Means&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Figure 4.1:&lt;/strong&gt; dav_set algorithm visualization. The axis have no corresponding unit due to the PCA operation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/davkmeans.jpg&#34; alt=&#34;Figure 4.1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 4.9:&lt;/strong&gt; dav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.22&lt;/td&gt;
&lt;td&gt;0.29&lt;/td&gt;
&lt;td&gt;0.25&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.12&lt;/td&gt;
&lt;td&gt;0.09&lt;/td&gt;
&lt;td&gt;0.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;0.376 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Figure 4.2:&lt;/strong&gt; sav_set algorithm visualization. The axis have no corresponding unit due to the PCA operation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/savkmeans.jpg&#34; alt=&#34;Figure 4.2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 4.10:&lt;/strong&gt; sav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.51&lt;/td&gt;
&lt;td&gt;0.69&lt;/td&gt;
&lt;td&gt;0.59&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.52&lt;/td&gt;
&lt;td&gt;0.34&lt;/td&gt;
&lt;td&gt;0.41&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;1.429 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;416-mean-shift&#34;&gt;4.1.6 Mean-shift&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Figure 4.3:&lt;/strong&gt; dav_set algorithm visualization. The axis have no corresponding unit due to the PCA operation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/davmeanshift.jpg&#34; alt=&#34;Figure 4.3&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 4.11:&lt;/strong&gt; dav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.47&lt;/td&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;0.64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.00&lt;/td&gt;
&lt;td&gt;0.00&lt;/td&gt;
&lt;td&gt;0.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;0.461 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Figure 4.4:&lt;/strong&gt; sav_set algorithm visualization. The axis have no corresponding unit due to the PCA operation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/savmeanshift.jpg&#34; alt=&#34;Figure 4.4&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 4.12:&lt;/strong&gt; sav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.50&lt;/td&gt;
&lt;td&gt;1.00&lt;/td&gt;
&lt;td&gt;0.67&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.00&lt;/td&gt;
&lt;td&gt;0.00&lt;/td&gt;
&lt;td&gt;0.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;193.93 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;417-spectral-clustering&#34;&gt;4.1.7 Spectral Clustering&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Figure 4.5:&lt;/strong&gt; dav_set algorithm visualization. The axis have no corresponding unit due to the PCA operation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/davspectral.jpg&#34; alt=&#34;Figure 4.5&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 4.13:&lt;/strong&gt; dav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.86&lt;/td&gt;
&lt;td&gt;0.74&lt;/td&gt;
&lt;td&gt;0.79&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.79&lt;/td&gt;
&lt;td&gt;0.89&lt;/td&gt;
&lt;td&gt;0.84&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;0.628 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Figure 4.6:&lt;/strong&gt; sav_set algorithm visualization. The axis have no corresponding unit due to the PCA operation.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-309/main/project/images/savspectral.jpg&#34; alt=&#34;Figure 4.6&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 4.14:&lt;/strong&gt; sav_set metrics&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Precision&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;th&gt;f1-score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;No Disease&lt;/td&gt;
&lt;td&gt;0.56&lt;/td&gt;
&lt;td&gt;0.57&lt;/td&gt;
&lt;td&gt;0.57&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Has Disease&lt;/td&gt;
&lt;td&gt;0.56&lt;/td&gt;
&lt;td&gt;0.56&lt;/td&gt;
&lt;td&gt;0.56&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Training Time&lt;/td&gt;
&lt;td&gt;208.822 sec&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;42-system-information&#34;&gt;4.2 System Information&lt;/h3&gt;
&lt;p&gt;Google Collab was used to train and evaluate the models selected. The specifications of the system in use is provided by the cloudmesh.common benchmark library and is listed in Table 4.15 &lt;sup id=&#34;fnref:15&#34;&gt;&lt;a href=&#34;#fn:15&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;15&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 4.15&lt;/strong&gt;: Training and Evaluation System Specifications&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Attribute&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;BUG_REPORT_URL&lt;/td&gt;
&lt;td&gt;&amp;ldquo;&lt;a href=&#34;https://bugs.launchpad.net/ubuntu/%22&#34;&gt;https://bugs.launchpad.net/ubuntu/&amp;quot;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DISTRIB_CODENAME&lt;/td&gt;
&lt;td&gt;bionic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DISTRIB_DESCRIPTION&lt;/td&gt;
&lt;td&gt;&amp;ldquo;Ubuntu 18.04.5 LTS&amp;rdquo;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DISTRIB_ID&lt;/td&gt;
&lt;td&gt;Ubuntu&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DISTRIB_RELEASE&lt;/td&gt;
&lt;td&gt;18.04&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HOME_URL&lt;/td&gt;
&lt;td&gt;&amp;ldquo;&lt;a href=&#34;https://www.ubuntu.com/%22&#34;&gt;https://www.ubuntu.com/&amp;quot;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ID&lt;/td&gt;
&lt;td&gt;ubuntu&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ID_LIKE&lt;/td&gt;
&lt;td&gt;debian&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NAME&lt;/td&gt;
&lt;td&gt;&amp;ldquo;Ubuntu&amp;rdquo;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PRETTY_NAME&lt;/td&gt;
&lt;td&gt;&amp;ldquo;Ubuntu 18.04.5 LTS&amp;rdquo;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PRIVACY_POLICY_URL&lt;/td&gt;
&lt;td&gt;&amp;ldquo;&lt;a href=&#34;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy%22&#34;&gt;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&amp;quot;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SUPPORT_URL&lt;/td&gt;
&lt;td&gt;&amp;ldquo;&lt;a href=&#34;https://help.ubuntu.com/%22&#34;&gt;https://help.ubuntu.com/&amp;quot;&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;UBUNTU_CODENAME&lt;/td&gt;
&lt;td&gt;bionic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VERSION&lt;/td&gt;
&lt;td&gt;&amp;ldquo;18.04.5 LTS (Bionic Beaver)&amp;rdquo;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VERSION_CODENAME&lt;/td&gt;
&lt;td&gt;bionic&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VERSION_ID&lt;/td&gt;
&lt;td&gt;&amp;ldquo;18.04&amp;rdquo;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cpu_count&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.active&lt;/td&gt;
&lt;td&gt;698.5 MiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.available&lt;/td&gt;
&lt;td&gt;11.9 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.free&lt;/td&gt;
&lt;td&gt;9.2 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.inactive&lt;/td&gt;
&lt;td&gt;2.6 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.percent&lt;/td&gt;
&lt;td&gt;6.5 %&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.total&lt;/td&gt;
&lt;td&gt;12.7 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mem.used&lt;/td&gt;
&lt;td&gt;1.6 GiB&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;platform.version&lt;/td&gt;
&lt;td&gt;#1 SMP Thu Jul 23 08:00:38 PDT 2020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;python&lt;/td&gt;
&lt;td&gt;3.6.9 (default, Oct  8 2020, 12:12:24)  [GCC 8.4.0]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;python.pip&lt;/td&gt;
&lt;td&gt;19.3.1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;python.version&lt;/td&gt;
&lt;td&gt;3.6.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sys.platform&lt;/td&gt;
&lt;td&gt;linux&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.machine&lt;/td&gt;
&lt;td&gt;x86_64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.node&lt;/td&gt;
&lt;td&gt;bc15b46ebcf6&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.processor&lt;/td&gt;
&lt;td&gt;x86_64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.release&lt;/td&gt;
&lt;td&gt;4.19.112+&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.system&lt;/td&gt;
&lt;td&gt;Linux&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;uname.version&lt;/td&gt;
&lt;td&gt;#1 SMP Thu Jul 23 08:00:38 PDT 2020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user&lt;/td&gt;
&lt;td&gt;collab&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;43-discussion&#34;&gt;4.3 Discussion&lt;/h3&gt;
&lt;p&gt;In analyzing the resulting metrics in section 4.1, two major trends between the algorithms are apparent.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The classification algorithms perform significantly better than the clustering algorithms.&lt;/li&gt;
&lt;li&gt;Significant signs of overfitting for the dav_set.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Addressing the first point, it is obvious from the metric performance where on average the classification algorithms were higher than the clustering algorithms. At a lower training time cost as well, which indicates that classification algorithms are well suited for this application than clustering. Especially when looking at the results for Mean-Shift in section 4.1.6 where the algorithm failed to identify any patient with a disease. This also illustrates the discussion on the metrics used to determine performance as the recall was 100% at the cost of missing every patient that would have required treatment illustrated by Figure 4.3 and 4.4. On this topic, comparing the actual data graphs for each of the clustering algorithms and comparing them to the example clustering figures within the scikit documentation, it solidifies that this is not the correct algorithm type for this dataset &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Moving on to the next point, it can be seen that overfitting is occurring for the dav_set in comparing the performance to the sav_set for the same algorithm which can be seen in the corresponding tables in sections 4.1.2, 4.1.3, and 4.1.4. Here the performance gap is at least 20% between the two compared to what one would assume should be relatively close to each other. While this could also illustrate the affect the various features have on the algorithm, it was determined that this is most likely due to the small dataset size having a larger influence than anticipated.&lt;/p&gt;
&lt;h2 id=&#34;5-conclusion&#34;&gt;5. Conclusion&lt;/h2&gt;
&lt;p&gt;Reviewing these results, a clear conclusion cannot be accurately be determined due to the considerable amount of variables involved that were not able to be isolated to a desirable level. Namely the  compromises that were mentioned in section 2.1 and general dataset availability. However, it was determined that the main goal of this project was accomplished where the Support Vector Machine algorithm was narrowed down as a viable candidate for future work. Due in part to the overall f1-score performance for both datasets, providing confidence that overfitting may not occur. While there is a downside in scalability due to the significant increase in training time between the smaller dav_set and larger sav_set. This could indicate that further research should be focused on either improving this algorithm or creating a new one based on the underlying mechanism.&lt;/p&gt;
&lt;p&gt;In relation to the types of features, it could be interpreted from this project that further efforts require a more expansive and modern dataset to perform to a level suitable for real world applications. As possible factors affecting the performance are in the accuracy and granularity of the measurements and factors available to learn from. This however, is seen to be a difficult challenge due to the nature of privacy laws on health data but, as proposed in the introduction. It would be very interesting to apply this project&amp;rsquo;s findings on more general health data that is retrieved in annual visits.&lt;/p&gt;
&lt;h2 id=&#34;6-acknowledgements&#34;&gt;6. Acknowledgements&lt;/h2&gt;
&lt;p&gt;The author would like to thank Dr. Gregor Von Laszewski, Dr. Geoffrey Fox, and the associate instructors in the &lt;em&gt;FA20-BL-ENGR-E534-11530: Big Data Applications&lt;/em&gt; course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their assistance and suggestions with regard to this project.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Centers for Disease Control and Prevention. 2020. Heart Disease Facts | Cdc.Gov. [online] Available at: &lt;a href=&#34;https://www.cdc.gov/heartdisease/facts.htm&#34;&gt;https://www.cdc.gov/heartdisease/facts.htm&lt;/a&gt; [Accessed 16 November 2020].&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Amadeo, K., 2020. Preventive Care: How It Lowers Healthcare Costs In America. [online] The Balance. Available at: &lt;a href=&#34;https://www.thebalance.com/preventive-care-how-it-lowers-aca-costs-3306074&#34;&gt;https://www.thebalance.com/preventive-care-how-it-lowers-aca-costs-3306074&lt;/a&gt; [Accessed 16 November 2020].&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;WebMD. 2020. Understanding Your Cholesterol Report. [online] Available at: &lt;a href=&#34;https://www.webmd.com/cholesterol-management/understanding-your-cholesterol-report&#34;&gt;https://www.webmd.com/cholesterol-management/understanding-your-cholesterol-report&lt;/a&gt; [Accessed 21 October 2020].&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;R, V., 2020. Feature Selection — Correlation And P-Value. [online] Medium. Available at: &lt;a href=&#34;https://towardsdatascience.com/feature-selection-correlation-and-p-value-da8921bfb3cf&#34;&gt;https://towardsdatascience.com/feature-selection-correlation-and-p-value-da8921bfb3cf&lt;/a&gt; [Accessed 21 October 2020].&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Stack Overflow. 2020. Differences In Scikit Learn, Keras, Or Pytorch. [online] Available at: &lt;a href=&#34;https://stackoverflow.com/questions/54527439/differences-in-scikit-learn-keras-or-pytorch&#34;&gt;https://stackoverflow.com/questions/54527439/differences-in-scikit-learn-keras-or-pytorch&lt;/a&gt; [Accessed 27 October 2020].&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 1.4. Support Vector Machines — Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/svm.html#classification&#34;&gt;https://scikit-learn.org/stable/modules/svm.html#classification&lt;/a&gt; [Accessed 27 October 2020].&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 2.3. Clustering — Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/clustering.html#clustering&#34;&gt;https://scikit-learn.org/stable/modules/clustering.html#clustering&lt;/a&gt; [Accessed 27 October 2020].&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 1. Supervised Learning — Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/supervised_learning.html#supervised-learning&#34;&gt;https://scikit-learn.org/stable/supervised_learning.html#supervised-learning&lt;/a&gt; [Accessed 27 October 2020].&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 1.6. Nearest Neighbors — Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/neighbors.html&#34;&gt;https://scikit-learn.org/stable/modules/neighbors.html&lt;/a&gt; [Accessed 27 October 2020].&amp;#160;&lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 1.9. Naive Bayes — Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/naive_bayes.html&#34;&gt;https://scikit-learn.org/stable/modules/naive_bayes.html&lt;/a&gt; [Accessed 27 October 2020].&amp;#160;&lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:11&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 1.10. Decision Trees — Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/tree.html&#34;&gt;https://scikit-learn.org/stable/modules/tree.html&lt;/a&gt; [Accessed 27 October 2020].&amp;#160;&lt;a href=&#34;#fnref:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:12&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. A Demo Of K-Means Clustering On The Handwritten Digits Data — Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py&#34;&gt;https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html#sphx-glr-auto-examples-cluster-plot-kmeans-digits-py&lt;/a&gt; [Accessed 17 November 2020].&amp;#160;&lt;a href=&#34;#fnref:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:13&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Scikit-learn.org. 2020. 6.3. Preprocessing Data — Scikit-Learn 0.23.2 Documentation. [online] Available at: &lt;a href=&#34;https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing&#34;&gt;https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing&lt;/a&gt; [Accessed 17 November 2020].&amp;#160;&lt;a href=&#34;#fnref:13&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:14&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Mianaee, S., 2020. 20 Popular Machine Learning Metrics. Part 1: Classification &amp;amp; Regression Evaluation Metrics. [online] Medium. Available at: &lt;a href=&#34;https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce&#34;&gt;https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce&lt;/a&gt; [Accessed 10 November 2020].&amp;#160;&lt;a href=&#34;#fnref:14&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:15&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Gregor von Laszewski, Cloudmesh StopWatch and Benchmark from the Cloudmesh Common Library, &lt;a href=&#34;https://github.com/cloudmesh/cloudmesh-common&#34;&gt;https://github.com/cloudmesh/cloudmesh-common&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:15&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: NBA Performance and Injury</title>
      <link>/report/fa20-523-301/project/project/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-301/project/project/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-301/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/workflows/Check%20Report/badge.svg&#34; alt=&#34;Check Report&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-301/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/workflows/Status/badge.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
Status: final, Type: Project&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gavin Hemmerlein, fa20-523-301&lt;/li&gt;
&lt;li&gt;Chelsea Gorius, fa20-523-344&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-301/blob/main/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Sports Medicine will be a $7.2 billion dollar industry by 2025. The NBA has a vested interest in predicting performance of players as they return from injury. The authors evaluated datasets available to the public within the 2010 decade to build machine and deep learning models to expect results. The team utilized Gradient Based Regressor, Light GBM, and Keras Deep Learning models. The results showed that the coefficient of determination for the deep learning model was approximately 98.5%. The team recommends future work to predicting individual player performance utilizing the Keras model.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-dataset&#34;&gt;3. Dataset&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-data-transformations-and-calculations&#34;&gt;3.1 Data Transformations and Calculations&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-methodology&#34;&gt;4. Methodology&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#41-development-of-models&#34;&gt;4.1 Development of Models&lt;/a&gt;
          &lt;ul&gt;
            &lt;li&gt;&lt;a href=&#34;#411-evaluation-metrics&#34;&gt;4.1.1 Evaluation Metrics&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#412-gradient-boost-regression&#34;&gt;4.1.2 Gradient Boost Regression&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#412-lightgbm-regression&#34;&gt;4.1.2 LightGBM Regression&lt;/a&gt;&lt;/li&gt;
            &lt;li&gt;&lt;a href=&#34;#413-keras-deep-learning-models&#34;&gt;4.1.3 Keras Deep Learning Models&lt;/a&gt;&lt;/li&gt;
          &lt;/ul&gt;
        &lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-inference&#34;&gt;5. Inference&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-conclusion&#34;&gt;6. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#61-limitations&#34;&gt;6.1 Limitations&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#71-work-breakdown&#34;&gt;7.1 Work Breakdown&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#8-references&#34;&gt;8. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; basketball, NBA, injury, performance, salary, rehabilitation, artificial intelligence, convolutional neural network, lightGBM, deep learning, gradient based regressor.&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;The topic to be investigated is basketball player performance as it relates to injury. The topic of injury and recovery is a multi-billion dollar industry.  The Sports Medicine field is expected to reach $7.2 billion dollars by 2025 &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.  The scope of this effort is to explore National Basketball Association(NBA) teams, but the additional uses of a topic such as this could expand into other realms such as the National Football League, Major League Baseball, the Olympic Committees, and many other avenues.  For leagues with salaries, projecting an expected return on the investment can assist in contract negotiations and cater expectations.  Competing at such a high level of intensity puts these players at a greater risk to injury than the average athlete because of the intense and constant strain on their bodies.  The overall valuation of the NBA in recent years is over 2 billion dollars, meaning each team is spending millions of dollars in the pursuit of a championship every season.  Injuries to players can cost teams not only wins but also significant profits.  Ticket sales alone for a single NBA finals game have reported greater than 10 million dollars in profit for the home team, if a team&amp;rsquo;s star player gets injured just before the playoffs and the team does not succeed, that is a lot of money lost.  These injuries can have an effect no matter the time of year, regular season ticket sales have been known to fluctuate with injuries from the team&amp;rsquo;s top performers.  Besides ticket sales these injuries can also influence viewership, TV or streaming, and potentially lead to a greater loss in profits.  With the health of the players and so much money at stake NBA team organizations as a whole do their best to take care of their players and keep them injury free.&lt;/p&gt;
&lt;h2 id=&#34;2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/h2&gt;
&lt;p&gt;The assumptions were made based on current literature as well. The injury return and limitations upon return of Anterior Cruciate Ligament (ACL) rupture (ACLR) are well documented and known. Interesting enough, forty percent of the players in the study occurred during the fourth quarter &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. This leads some credence to the idea that fatigue is a major factor in the occurrence of these injuries.&lt;/p&gt;
&lt;p&gt;The current literature also shows that a second or third injury can occur more frequently due to minor injuries. &lt;em&gt;&amp;ldquo;When an athlete is recovering from an injury or surgery, tissue is already compromised and thus requires far more attention despite the recovery of joint motion and strength. Moreover, injuries and surgical procedures can create detraining issues that increase the likelihood of further injury&amp;rdquo;&lt;/em&gt; &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;3-dataset&#34;&gt;3. Dataset&lt;/h2&gt;
&lt;p&gt;To compare performance and injury, a minimum of two datasets will be needed. The first is a dataset of injuries for players &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. This dataset created the samples necessary for review.&lt;/p&gt;
&lt;p&gt;Once the controls for injuries were established, the next requirement was to establish pre-injury performance parameters and post-injury parameters. These areas were where the feature engineering took place. The datasets needed had to include appropriate basketball performance stats to establish a metric to encompass a player&amp;rsquo;s performance. One example that ESPN has tried in the past is the Player Efficiency Rating (PER). To accomplish this, it was important to review player performance within games such as in the &lt;em&gt;NBA games data&lt;/em&gt; &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; dataset because of how it allowed the team to evaluate the player performance throughout the season, and not just the average stats across the year. In addition to that the data from the &lt;em&gt;NBA games data&lt;/em&gt; &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt; dataset was valuable in order to compare the calculated performance metrics just before an injury or after recovery to the player&amp;rsquo;s overall performance that season or in seasons prior. That comparison provided a solid baseline to understand how injuries can effect a player&amp;rsquo;s performance. With in depth information about each game of the season, and not just the teams and players aggregated stats, added to the data provided from the injury dataset &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt; the team was be able to compose new metrics to understand how these injuries are actually affecting the players performance.&lt;/p&gt;
&lt;p&gt;Along the way attempted to discover if there is also a causal relationship to the severity of some of the injuries, based on how the player was performing just before the injury. The term &lt;em&gt;load management&lt;/em&gt; has become popular in recent years to describe players taking rest periodically throughout the season in order to prevent injury from overplaying. This new practice has received both support for the player safety it provides and also criticism around players taking too much time off. Of course not all injuries are entirely based on the recent strain under the players body, but a better understanding about how that affects the injury as a whole could give better insight into avoiding more injuries. It is important to remember though that any pattern identification would not lead to an elimination of all injuries, any contact sport will continue to have injuries, especially one as high impact as the NBA. There is value to learn from why some players are able to return from certain injuries more quickly and why some return to almost equivalent or better playing performance than before the injury. This comparison of performance was attempted by deriving metrics based on varying ranges of games immediately leading up to injury and then immediately after returning from injury. In addition to that performed comparisons to the players known peak performance to better understand how the injury affected them. Another factor that was important to include is the length of time recovering from the injury. Different players take differing amounts of time off, sometimes even with similar injuries. Something will be said about the player’s dedication to recovery and determination to remain at peak performance, even through injury, when looking at how severe their injury was, how much time was taken for recovery, and how they performed upon returning.&lt;/p&gt;
&lt;p&gt;These datasets were chosen because they allow for a review of individual game performance, for each team, throughout each season in the recent decade. Aggregate statistics such as points per game (ppg) can be deceptive because duration of the metric is such a large period of time. The large sample of 82 games can lead to a perception issue when reviewing the data. These datasets include more variables to help the team determine effects to player injury, such as minutes per game (mpg) to understand how strenuous the pre-injury performance or how fatigue may have played a factor in the injury. Understanding more of the variables such as fouls given or drawn can help determine if the player or other team seemed to be the primary aggressor before any injury.&lt;/p&gt;
&lt;h3 id=&#34;31-data-transformations-and-calculations&#34;&gt;3.1 Data Transformations and Calculations&lt;/h3&gt;
&lt;p&gt;Using the Kaggle package the datasets were downloaded direct from the website and unzipped to a directory accessible by the ‘project_dateEngineering.ipynb’ notebook. The 7 unzipped datasets are then loaded into the notebook as pandas data frames using the ‘.read_csv()’ function. The data engineering performed in the notebook includes removal of excess data and data type transformations across almost all the data frames loaded. This data transformation includes transforming the games details column ‘MIN’, meaning minutes played, from a timestamp format to a numerical format that could have calculations like summation or average performed on it. This was a crucial transformation since minutes played have a direct correlation to player fatigue, which can increase a player’s chance of injury.&lt;/p&gt;
&lt;p&gt;One of the more difficult tasks was transforming the Injury dataset into something that would provide more information through machine learning and analysis. The dataset is loaded as one data set where 2 columns ‘Relinquished’ and ‘Acquired’ defined if the row in questions was a player leaving the roster due to injury or returning from injury, respectively.  In this case for each for one of those two columns contained a players name and the other was blank. Besides that the data frame contained information like the date, notes, and the team name. In order to appropriately understand each injury as whole the data frame needs to be transformed into one where each row contains the player, the start date of the injury, and the end date of the injury. In order to do this first the original Injury dataset was separated into rows marking the start of an injury and those marking the end of an injury. Data frames from the &lt;em&gt;NBA games data&lt;/em&gt; &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt; data set were used to join TeamID and PlayerID columns to the Injury datasets. An ‘iterrows():’ loop was then used on the data frame marking the start of an injury to specifically locate the corresponding row in the Injury End data frame with the same PlayerID and where the return date was the closest date after the injury date. As this new data frame was being transformed, it was noted that sometimes a Player would have multiple rows with the same Injury ending date but different injury start dates, this can happen if an injury worsens or the player did not play due to last minute decision. In order to solve this the table was grouped by the PlayerID and InjuryEnd Date while keeping the oldest Injury Start date, since the model will want to see the full length of the injury. From there it was simple to calculate the difference in days for each row between the Injury start and end dates. This data frame is called ‘df_Injury_length’ in the notebook and is much easier to use for improved understanding of NBA injuries than the original format of the Injury data set.&lt;/p&gt;
&lt;p&gt;Once created, the ‘df_Injury_length’ data frame was copied and built upon. Using ‘iterrows():’ loop again to filter down the games details data frame rows with the same PlayerId, over 60 calculated columns are created to produce the ‘df_Injury_stats’ data frame. The data frame includes performance statistics specifically from the game the player was injured and the game the player returned from that injury. In addition to this aggregate performance metrics were calculated based on the 5 games prior to the injury and the 5 games post returning from injury. At this time the season of when the injury occurred and when the player returned is also stored in the dataframe. This will allow comparisons between the ‘df_Injury_stats’ data frame and the ‘df_Season_stats’ data frame which contains the players average performance metrics for entire seasons.&lt;/p&gt;
&lt;p&gt;A few interesting figures were generated within the Exploratory Data Analysis (EDA) stage. &lt;strong&gt;Figure 1&lt;/strong&gt; gave a view of the load of the player returning from injury. The load to the player will show how recovered the player is upon completion of rehab. Many teams decide to slowly work a returning player in. Additionally, the amount of time for an injury can be seen on this graph. The longer the injury, the more unlikely the player will return to action.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/avg_min_played_post5.png&#34; alt=&#34;Average Minutes Played in First Five Games Upon Return over Injury Length in Days&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Average Minutes Played in First Five Games Upon Return over Injury Length in Days*&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt; shows the frequency in which a player is injured. The idea behind this graph is to see a relationship between the time leading up to the injury. Interesting enough, there is no key indication of where injury is more likely to occur. It can be assumed that there is a rarity of players who see playing time greater than 30 minutes. The histogram only shows a near flat relationship; which was surprising.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/frequencies_by_average_minutes.png&#34; alt=&#34;Frequency of Injuries by Average Minutes Played in Prior Five Games&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; Frequency of Injuries by Average Minutes Played in Prior Five Games*&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3&lt;/strong&gt; shows the length of injury over number of injuries. By reviewing this data, it can be seen that most injuries occur fewer rather than more often. A player that is deemed injury prone will be a lot more likely to be cut from the team. This data makes sense.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/injury_length.png&#34; alt=&#34;Injury Length in Days over Number of Injuries&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; Injury Length in Days over Number of Injuries&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 4&lt;/strong&gt; shows the injury length over average minutes played in the five games before injury. This graph attempts to show all of the previous games and the impacts to the players injury. The data looks evenly distributed, but the majority of plaers do not play close to 40 minutes per game. By looking at this data, it shows that minutes played does likely contribute to the injury severity.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/injury_length_over_avg_min.png&#34; alt=&#34;Injury Length in Days over Avg Minutes Played in Prior 5 Games&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 4:&lt;/strong&gt; Injury Length in Days over Avg Minutes Played in Prior 5 Games&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 5&lt;/strong&gt; shows that in general the number of games played does not have a significant relationship to the length of the injury.  There is a darker cluster between 500-1000 days injured that exists over the 40-82 games played, this could suggest that as more games are played there is likeliness for more severe injury.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/injurylength_gamesplayed.png&#34; alt=&#34;Injury Length in Days over Player Games Played that Season&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 5:&lt;/strong&gt; Injury Length in Days over Player Games Played that Season&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figures 6&lt;/strong&gt;, &lt;strong&gt;Figure 7&lt;/strong&gt;, and &lt;strong&gt;Figure 8&lt;/strong&gt; attempt to demonstrate if any relationship exists visually between a player&amp;rsquo;s injury length and their age, weight, or height.  For the most part &lt;strong&gt;Figure 6&lt;/strong&gt; shows most severe injuries occurring to younger players, which could make sense considering they can perform more difficult moves or have more stamina than older players.  Some severe injuries still exist among the older players, this also makes sense considering their bodies have been under stress for many years and are more prone to injury. It should be noted that there are more players in the league that fall into the younger age bucket than the older ages. It is difficult to identify any pattern on &lt;strong&gt;Figure 7&lt;/strong&gt;.  If anything the graph is somewhat normally shaped similar to the heights of players across the league. Suprisingly the injuries on &lt;strong&gt;Figure 8&lt;/strong&gt; are clustered a bit towards the left, being the lighter players.  This could be explained through the fact that the lighter players are often more athletic and perform more strenuous moves than heavier players.  It is also somewhat surprising since the argument that heavier players are putting more strain on their bodies could be used as a reason why heavier players would have worse injuries. One possible explanation could be the musculature adding more of the dense body mass could add protection to weakened joints. More investigation would be needed to identify an exact reason.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/injurylength_playerage.png&#34; alt=&#34;Injury Length in Days over Player Age that Season&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 6:&lt;/strong&gt; Injury Length in Days over Player Age that Season&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/injurylength_playerHeight.png&#34; alt=&#34;Injury Length in Days over Player Height in Inches&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 7:&lt;/strong&gt; Injury Length in Days over Player Height in Inches&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/injurylength_playerWeight.png&#34; alt=&#34;Injury Length in Days over Player Weight in Kilograms&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 8:&lt;/strong&gt; Injury Length in Days over Player Weight in Kilograms&lt;/p&gt;
&lt;p&gt;Finally, the team decided to use the z-score to normalize all of the data. By using the Z-score from the individual data in a column of df_Injury_stats, the team was able to limit variability of multiple metrics across the dataframe. A player&amp;rsquo;s blocks and steals should be a miniscule amount compared to minutes or points of some players. The same can be said of assists, technical fouls, or any other statistic in the course of an NBA game. The Z-score, by nature of the metric from the mean, allows for much less variability across the columns.&lt;/p&gt;
&lt;h2 id=&#34;4-methodology&#34;&gt;4. Methodology&lt;/h2&gt;
&lt;p&gt;The objective of this project was to develop performance indicators for injured players returning to basketball in the NBA. It is unreasonable to expect a player to return to the same level of play post injury immediately upon starting back up after recovery. It often takes a player months if not years to return to the same level of play as pre-injury, especially considering the severity of the injuries. In order to successfully analyze this information from the datasets, a predictive model will need to be created using a large set of the data to train.&lt;/p&gt;
&lt;p&gt;From this point, a test run was used to gauge the validity and accuracy of the model compared to some of the data set aside. The model created was able to provide feature importance to give a better understanding of which specific features are the most crucial when it comes to determining how bad the effects of an injury may or may not be on player performance. Feature engineering was performed prior to training the model in order to improve the chances of higher accuracy from the predictions. This model could be used to keep an eye out for how a player&amp;rsquo;s performance intensity and the engineered features could affect how long a player takes to recover from injury, if there are any warning signs prior to an injury, and even how well they perform when returning.&lt;/p&gt;
&lt;h3 id=&#34;41-development-of-models&#34;&gt;4.1 Development of Models&lt;/h3&gt;
&lt;p&gt;To help with review of the data, conditioned data was used to save resources on Google Colab. By conditioning the data and saving the files as a .CSV, the team was able to create a streamlined process. Additionally, the team found benefit by uploading these files to Google Drive to quickly import data near real time. After operating in this fashion for some time, the team was able to load the datasets into Github and utilize that feature. By loading the datasets up to Github, a url could be used to link the files directly to the files saved on Github without using a token like with Kaggle or Google Drive. The files saved were the following:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 1:&lt;/strong&gt; Datasets Imported&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Dataframe&lt;/strong&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;Title&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;df_Injury_stats&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;df_Injury_length&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;df_Season_stats&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;games&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;5.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;df_Games_gamesDetails&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;6.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;injuries_2010-2018&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;7.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;players&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;8.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;ranking&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;9.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;teams&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Every time Google Colab loads data, it takes time and resources. The team was able to utilize the cross platform connectivity of the Google utilities. The team could then focus on building models as opposed to conditioning data every time the code was ran.&lt;/p&gt;
&lt;h4 id=&#34;411-evaluation-metrics&#34;&gt;4.1.1 Evaluation Metrics&lt;/h4&gt;
&lt;p&gt;The metrics chosen were designed to give results on  Mean Absolute Error (MAE), Root Mean Square Error (RMSE), and the Explained Variance (EV) Score. MAE is a measure of errors between paired observations experiencing the same expression. RMSE is the standard deviation of the prediction errors for our dataset. EV is the relationship between the train data and the test data. By using these metrics, the team is capable of reviewing the data in a statistical manner.&lt;/p&gt;
&lt;h4 id=&#34;412-gradient-boost-regression&#34;&gt;4.1.2 Gradient Boost Regression&lt;/h4&gt;
&lt;p&gt;The initial model that was used was a Gradient Boosting Regressor (GBR) model. This model produced the results shown in Table 2. The GBR model builds in a stage-wise fashion; similarly to other boosting methods. GBR also generalizes the data and attempts to optimize the results utilizing a loss function. An example of the algorithm can be seen in &lt;strong&gt;Figure 5&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/gbr.png&#34; alt=&#34;Gradient Boosting Regressor&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 5:&lt;/strong&gt; Gradient Boosting Regressor &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;The team saw a relationship given the data. &lt;strong&gt;Table 2&lt;/strong&gt; shows the results of that model. The results were promising given the speed and utility of a GBR model. The team reviewed the data multiple times after multiple stages of conditioning the data.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 2:&lt;/strong&gt; GBR Results&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Category&lt;/strong&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;Value&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;MAE Mean&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-10.787&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;MAE STD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.687&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;RMSE Mean&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-115.929&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;RMSE STD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;96.64&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;EV Mean&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;1.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;EV STD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;After running a GBR model, the decision was made to try multiple models to see what gives the best results. The team settled on LightGBM and a Deep Learning model utilizing Keras built on the TensorFlow platform. These results will be seen in &lt;em&gt;4.1.2&lt;/em&gt; and &lt;em&gt;4.1.3&lt;/em&gt;.&lt;/p&gt;
&lt;h4 id=&#34;412-lightgbm-regression&#34;&gt;4.1.2 LightGBM Regression&lt;/h4&gt;
&lt;p&gt;Another algorithm chosen was a Light Gradient Boost Machine (LightGBM) model. LightGBM is known for its lightweight and resource sparse abilities. The model is built from decision tree algorithms and used for ranking, classification, and other machine learning tasks. By choosing LightGBM data scientists are able to analyze larger data a faster approach. LightGBM can often over fit a model if the data is too small, but fortunately for the purpose of this assignment the data available for NBA injuries and stats is extremely large. Availability of data allowed for smooth operation of the LightGBM model. Mandot explains the model really well in The Medium. Mandot said, &lt;em&gt;&amp;ldquo;Light GBM can handle the large size of data and takes lower memory to run. Another reason of why Light GBM is popular is because it focuses on accuracy of results. LGBM also supports GPU learning and thus data scientists are widely using LGBM for data science application development&amp;rdquo;&lt;/em&gt; &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;. There are a lot of benefits available to this algorithm.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/lightGBM_regressor.png&#34; alt=&#34;LightGBM Algorithm: Leafwise searching&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 6:&lt;/strong&gt; LightGBM Algorithm: Leafwise searching &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;When running the model &lt;strong&gt;Table 3&lt;/strong&gt; was generated. This table uses the same metrics as the GBR Results Table (&lt;strong&gt;Table 2&lt;/strong&gt;). After reviewing the results, the GBR model still appeared to be a viable avenue. The Keras model will be evaluated next to see most optimal model to use for repeatable fresults.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 3:&lt;/strong&gt; LightGBM Results&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Category&lt;/strong&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;Value&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;MAE Mean&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-0.011&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;MAE STD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;RMSE Mean&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;-0.128&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;RMSE STD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.046&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;EV Mean&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.982&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;EV STD&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.013&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;413-keras-deep-learning-models&#34;&gt;4.1.3 Keras Deep Learning Models&lt;/h4&gt;
&lt;p&gt;The final model attempted was a Deep Learning model. A few runs of different layers and epochs were chosen. They can be seen in &lt;strong&gt;Table 4&lt;/strong&gt; (shown later). The model was sequentially ran through the test layers to refine the model. When this is done, each predecessor layer acts as an input to the next layer&amp;rsquo;s input for the model. The results can produce accurate results while using unsupervised learning. The visualization for this model can be seen in the following figure:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-301/raw/main/project/images/simple_neural_network_vs_deep_learning.jpg&#34; alt=&#34;Neural Network&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 7:&lt;/strong&gt; Neural Network &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;When the team ran the Neural Networks, the data went through three layers. Each layer was built upon the previous similarly to the figure. This allowed for the team to capture information from the processing. &lt;strong&gt;Table 4&lt;/strong&gt; shows the results for the deep learning model.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Table 4:&lt;/strong&gt; Epochs and Batch Sizes Chosen&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;&lt;strong&gt;Number&lt;/strong&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;Regressor Epoch&lt;/strong&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;Regressor Batch Sizes&lt;/strong&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;KFolds&lt;/strong&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;Model Epochs&lt;/strong&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;strong&gt;R2&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;em&gt;1.&lt;/em&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;em&gt;25&lt;/em&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;em&gt;25&lt;/em&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;em&gt;10&lt;/em&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;em&gt;10&lt;/em&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;&lt;em&gt;0.985&lt;/em&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;2.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;40&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;25&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;20&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.894&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;3.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;20&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;25&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;20&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.966&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;20&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;20&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.707&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;5.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;25&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;25&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;5&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.611&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;6.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;25&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;25&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;10&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;20&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;0.982&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The team has decided that the results for the Deep Learning are the most desirable. This model would be the one that the team would recommend based on the results from the metrics available. The parameters the team recommends are italicized in &lt;em&gt;Line 1&lt;/em&gt; of &lt;strong&gt;Table 4&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;5-inference&#34;&gt;5. Inference&lt;/h2&gt;
&lt;p&gt;With the data available, some conclusions can be made. Not all injuries are of the same severity. By treating an ACL tear in the same manner as a bruise, the team doctors would take terrible approaches to rehab. The severity of the injury is a part of the approach to therapy. This detail is nearly impossible to capture in the model.&lt;/p&gt;
&lt;p&gt;Another aspect to come to a conclusion is that not every player recovers in the same timetable as another. Genetics, diet, effort, and mental health can all harm or reinforce the efforts from the medical staff. These areas are hard to capture in the data and cannot be appropriately reviewed with this model.&lt;/p&gt;
&lt;p&gt;It is also difficult to indicate where a previous injury may have contributed to a current injury. The kinetic chain is a structure of the musculoskeletal system that moves the body using the muscles and bones. If one portion of the chain is compromised, the entire chain will need to be modified to continue movement. This modification can result in more injuries. The data cannot provide this information.  It is important to remember these possible confounding variables when interpreting the results of the model.&lt;/p&gt;
&lt;h2 id=&#34;6-conclusion&#34;&gt;6. Conclusion&lt;/h2&gt;
&lt;p&gt;After reviewing the results, the team created a robust model to predict the performance of a player after an injury. The coefficient of determination for the deep learning model shows a strong relationship between the training and test sets. After conditioning the data, the results can be seen in &lt;strong&gt;Table 2&lt;/strong&gt;, &lt;strong&gt;Table 3&lt;/strong&gt;, and &lt;strong&gt;Table 5&lt;/strong&gt;. The team had an objective to find this correlation and build it to the point where injury and performance can be modeled. The team was able to accomplish this goal.&lt;/p&gt;
&lt;p&gt;Additionally, these results are consistent with the current scientific literature &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. The biological community has been able to record these results for decades. By leveraging this effort, the scientific community could move to a more proactive approach as opposed to reactive with respect to injury controls. This data will also allow for proper contract negotiations to take place in the NBA, considering potential decisions to avoid injury may include less playing time. The negotiations are pivotal to ensuring that expectations are met in the future seasons; especially when injury occurs in the final year of a player&amp;rsquo;s contract. Teams with an improved understanding of how players can or will return from injury have an opportunity to make the best of scenarios where other teams may be hesitant to sign an injured player.  These different opportunities for a team&amp;rsquo;s front office could be the difference between a championship ring and missing the playoffs entirely.&lt;/p&gt;
&lt;h2 id=&#34;61-limitations&#34;&gt;6.1 Limitations&lt;/h2&gt;
&lt;p&gt;With respect to the current work, the models could be continued to be refined. Currently the results are to the original intentions of the team, but improvements can be made. Feature Engineering is always an area where the models can improve. Some valuable features to be created in the future are the calculations for the player&amp;rsquo;s efficiency overall, as well as offensinve and defensive efficiencies in each game. The team would also like to develop a model to use the stats of a player in pre-injury and apply that to the post-injury set of metrics. Also, the team would like to move to where the same could be applied given the length of the injury to the player while considering the severity of the injury. Longer and more severe injury will lead to different future results than say a long not severe injury, or a short injury that was somewhat severe.  The number of varaibles that could provide more valuable information to the model are endless.&lt;/p&gt;
&lt;h2 id=&#34;7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/h2&gt;
&lt;p&gt;The authors would like to thank Dr. Gregor von Laszewski, Dr. Geoffrey Fox, and the associate instructors in the &lt;em&gt;FA20-BL-ENGR-E534-11530: Big Data Applications&lt;/em&gt; course (offered in the Fall 2020 semester at Indiana University, Bloomington) for their continued assistance and suggestions with regard to exploring this idea and also for their aid with preparing the various drafts of this article. In addition to that the community of students from the &lt;em&gt;FA20-BL-ENGR-E534-11530: Big Data Applications&lt;/em&gt; course also deserve a thanks from the author for the support, continued engagement, and valuable discussions through Piazza.&lt;/p&gt;
&lt;h3 id=&#34;71-work-breakdown&#34;&gt;7.1 Work Breakdown&lt;/h3&gt;
&lt;p&gt;For the effort developed, the team split tasks between each other to cover more ground. The requirements for the investigation required a more extensive effort for the teams in the ENGR-E 534 class. To accomplish the requirements, the task was expanded by addressing multiple datasets within the semester and building in multiple models to display the results. The team members were responsible for committing in Github multiple times throughout the semester. The tasks were divided as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Chelsea Gorius
&lt;ul&gt;
&lt;li&gt;Exploratory Data Analysis&lt;/li&gt;
&lt;li&gt;Feature Engineering&lt;/li&gt;
&lt;li&gt;Keras Deep Learning Model&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gavin Hemmerlein
&lt;ul&gt;
&lt;li&gt;Organization of Items&lt;/li&gt;
&lt;li&gt;Model Development&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Both
&lt;ul&gt;
&lt;li&gt;Report&lt;/li&gt;
&lt;li&gt;All Outstanding Items&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;8-references&#34;&gt;8. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;A. Mehra, &lt;em&gt;Sports Medicine Market worth $7.2 billion by 2025&lt;/em&gt;, [online] Markets and Markets.
&lt;a href=&#34;https://www.marketsandmarkets.com/PressReleases/sports-medicine-devices.asp&#34;&gt;https://www.marketsandmarkets.com/PressReleases/sports-medicine-devices.asp&lt;/a&gt; [Accessed Oct. 15, 2020].&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;J. Harris, B. Erickson, B. Bach Jr, G. Abrams, G. Cvetanovich, B. Forsythe, F. McCormick, A. Gupta, B. Cole,
&lt;em&gt;Return-to-Sport and Performance After Anterior Cruciate Ligament Reconstruction in National Basketball Association Players&lt;/em&gt;, Sports Health. 2013 Nov;5(6):562-8. doi: 10.1177/1941738113495788. [Online serial]. Available: &lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/24427434&#34;&gt;https://pubmed.ncbi.nlm.nih.gov/24427434&lt;/a&gt; [Accessed Oct. 24, 2020].&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;W. Kraemer, C. Denegar, and S. Flanagan, &lt;em&gt;Recovery From Injury in Sport: Considerations in the Transition From Medical Care to Performance Care&lt;/em&gt;, Sports Health. 
2009 Sep; 1(5): 392–395.[Online serial]. Available: &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3445177&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3445177&lt;/a&gt;  [Accessed Oct. 24, 2020].&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;R. Hopkins, &lt;em&gt;NBA Injuries from 2010-2020&lt;/em&gt;, [online] Kaggle. &lt;a href=&#34;https://www.kaggle.com/ghopkins/nba-injuries-2010-2018&#34;&gt;https://www.kaggle.com/ghopkins/nba-injuries-2010-2018&lt;/a&gt; [Accessed Oct. 9, 2020].&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;N. Lauga, &lt;em&gt;NBA games data&lt;/em&gt;, [online] Kaggle. &lt;a href=&#34;https://www.kaggle.com/nathanlauga/nba-games?select=games_details.csv&#34;&gt;https://www.kaggle.com/nathanlauga/nba-games?select=games_details.csv&lt;/a&gt; [Accessed Oct. 9, 2020].&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;J. Cirtautas, &lt;em&gt;NBA Players&lt;/em&gt;, [online] Kaggle. &lt;a href=&#34;https://www.kaggle.com/justinas/nba-players-data&#34;&gt;https://www.kaggle.com/justinas/nba-players-data&lt;/a&gt; [Accessed Oct. 9, 2020].&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;V. Aliyev, &lt;em&gt;A hands-on explanation of Gradient Boosting Regression&lt;/em&gt;, [online] Medium. &lt;a href=&#34;https://medium.com/@vagifaliyev/a-hands-on-explanation-of-gradient-boosting-regression-4cfe7cfdf9e&#34;&gt;https://medium.com/@vagifaliyev/a-hands-on-explanation-of-gradient-boosting-regression-4cfe7cfdf9e&lt;/a&gt; [Accessed Nov., 9 2020].&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;P. Mandon, &lt;em&gt;What is LightGBM, How to implement it? How to fine tune the parameters?&lt;/em&gt;, [online] Medium. &lt;a href=&#34;https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc&#34;&gt;https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc&lt;/a&gt; [Accessed Nov., 9 2020].&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;The Data Scientist, &lt;em&gt;What deep learning is and isn’t&lt;/em&gt;, [online] The Data Scientist.  &lt;a href=&#34;https://thedatascientist.com/what-deep-learning-is-and-isnt&#34;&gt;https://thedatascientist.com/what-deep-learning-is-and-isnt&lt;/a&gt; [Accessed Nov., 9 2020].&amp;#160;&lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: How Big Data Can Eliminate Racial Bias and Structural Discrimination</title>
      <link>/report/fa20-523-304/report/report/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-304/report/report/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-304/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-304/workflows/Check%20Report/badge.svg&#34; alt=&#34;Check Report&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-304/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-304/workflows/Status/badge.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
Status: final, Type: Report&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Robert Neubauer, fa20-523-304&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-304/blob/main/report/report.md&#34;&gt;Edit&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Healthcare is utilizing Big Data to to assist in creating systems that can be used to detect health risks, implement preventative care, and provide an overall better experience for patients. However, there are fundmental issues that exist in the creation and implementation of these systems. Medical algorithms and efforts in precision medicine often neglect the structural inequalities that already exist for minorities accessing healthcare and therefore perpetuate bias in the healthcare industry. The author examines current applications of these concepts, how they are affecting minority communities in the United States, and discusses improvements in order to achieve more equitable care in the industry.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-bias-in-medical-algorithms&#34;&gt;2. Bias in Medical Algorithms&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-disparities-found-with-data-dashboards&#34;&gt;3. Disparities Found with Data Dashboards&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-effect-of-precision-medicine-and-predictive-care&#34;&gt;4. Effect of Precision Medicine and Predictive Care&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#41-precision-public-health&#34;&gt;4.1 Precision Public Health&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-telehealth-and-telemedicine-applications&#34;&gt;5. Telehealth and Telemedicine Applications&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#51-limitations-of-teleheath-and-telemedicine&#34;&gt;5.1 Limitations of Teleheath and Telemedicine&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-conclusion&#34;&gt;6. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-references&#34;&gt;7. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; healthcare, machine learning, data science, racial bias, precision medicine, coronavirus, big data, telehealth, telemedicine, public health.&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Big Data is helping to reshape healthcare through major advancements in telehealth and precision medicine. Due to the swift increase in telehealth services due to the COVID-19 pandemic, researchers at the University of California San Francisco have found that black and hispanic patients use these services less frequently than white patients. Prior to the pandemic, research showed that racial and ethnic minorities were disadvantaged by the digital divide &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. These differences were attributed to disparities in access to technology and digital literacy &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. Studies like these highlight how racial bias in healthcare is getting detected more frequently; However, there are few attempts to eradicate it through the use of similar technology. This has implications in various areas of healthcare including major healthcare algorithms, telehealth, precision medicine, and overall care provision.&lt;/p&gt;
&lt;p&gt;From the 1985 &lt;em&gt;Report of the Secretary’s Task Force on Black and Minority Health&lt;/em&gt;, &amp;lsquo;Blacks, Hispanics, Native Americans and those of Asian/Pacific Islander heritage have not benefited fully or equitably from the fruits of science or from those systems responsible for translating and using health sciences technology&amp;rsquo; &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. The utilization of big data in industries largely acts to automate a process that was carried out by a human. This makes the process quicker to accomplish and the outcomes more precise since human error can now be eliminated. However, whenever people create the algorithms that are implemented, it is common that these algorithms will align with the biases of the human, or system, that created it. An area where this is happening that is especially alarming is the healthcare industry. Structural discrimination has long caused discrepencies in healthcare between white patients and minority patients and, with the introduction of big data to determine who should receive certain kinds of care, the issue has not been resolved but automated. Studies have shown that minority groups that are often at higher risk than white patients receive less preventative care while spending almost equal amounts on healthcare &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. National data also indicates that racial and ethnic minorities also have poorer health outcomes from preventable and treatable diseases such as cardiovascular disease, cancer, asthma, and HIV/AIDS than those in the majority &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;2-bias-in-medical-algorithms&#34;&gt;2. Bias in Medical Algorithms&lt;/h2&gt;
&lt;p&gt;In a research article published to &lt;em&gt;Science&lt;/em&gt; in October of 2019, the researchers uncovered that one of the most used algorithms in healthcare, widely adopted by non- and for-profit medical centers and government agencies, less frequently identified black patients for preventative care than white patients. This algorithm is estimated to be applied to around 200 million people in the United States every year in order to target patients for high-risk care management. These programs seek to improve the care of patients with complex health needs by providing additional resources. The dataset used in the study contained the algorithms predictions, the underlying ingredients that formed the algorithm, and rich data outcomes which allowed for the ability to quantify racial disparities and isolate the mechanisms by which they arise. The sample consisted of 6,079 self-identified black patients and 43,539 self-identified white patients where 71.2% of all patients were enrolled in commercial insurance and 28.8% were on Medicare. On average, the patient age was 50.9 years old and 63% of patients were female. The patients enrolled in the study were classified among risk percentiles, where patients with scores at or above the 97th percentile were auto-enrolled and patients with scores over the 55th percentile were encouraged to enroll &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;In order to measure health outcomes, they linked predictions to a wide range of outcomes in electronic health records, which included all diagnoses, and key quantitative laboratory studies and vital signs that captured the severity of chronic illnesses. When focusing on a point in the very-high-risk group, which would be patients in the 97th percentile, they were able to quantify the differences between white and black patients, where black patients had 26.3% more chronic illnesses than white patients&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. To get a corrected health outcome measurement among white and black patients, the researchers set a specific risk threshold for health outcomes among all patients, and repeated the procedure to replace healthier white patients with sicker black patients. So, for a white patient with a health risk score above the threshold, their data was replaced with a black patient whose score fell below the threshold and this continued until the health risk scores for black and white patients were equal and the predictive gap between patients would be eliminated. The health scores were based on the number of chronic medical conditions. The researchers then compared the data from their corrected algorithm and the original and found that the fraction of black patients at all risk thresholds above the 50th percentile increased when using the corrected algorithm. At the 97th percentile, the fraction of black patients increased to 46.5% from the original 17.7% &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. Black patients are likely to have more severe hypertension, diabetes, renal failure, and anemia, and higher cholesterol. Using data from clinical trials and longitudinal studies, the researchers found that for mortality rates with hypertension and diabetes black patients had a 7.6% and 30% increase, respectively&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;In the original and corrected algorithms, black and white patients spent roughly the same amount on healthcare. However, black patients spent more on emergency care and dialysis while white patients spent more on inpatient surgery and outpatient specialist care&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;. In a study that tracked black patients with a black versus a white primary care provider, it found the occurrence of a black primary care provider recommending preventative care was significantly higher than recommendations from a white primary care provider. This conclusion sheds additional light on the disparities black patients face in the healthcare system and further adds to the lack of trust black people have in the healthcare system that has been heavily documented since the Tuskegee study &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. The change recommended by the researchers that would correct the gap in the predictive care model was rather simple, shifting from predictions from purely future cost to an index that combined future cost prediction with health prediction. The researchers were able to work with the distributor of the original algorithm in order to make a more equitable algorithm. Since the original and corrected models from the study were both equal in cost but varied significantly in health predictions, they reworked the cost prediction based on health predictions, conditional on the risk factor percentiles. Both of the models excluded race from the predictions, but the algorithm created with the researchers saw an 84% reduction in bias among black patients, reducing the number of excess active chronic conditions in black patients to 7,758.&lt;/p&gt;
&lt;h2 id=&#34;3-disparities-found-with-data-dashboards&#34;&gt;3. Disparities Found with Data Dashboards&lt;/h2&gt;
&lt;p&gt;To relate this to a present health issue that is affecting everyone, more black patients are dying from the novel coronavirus than white patients. In the United States, in counties where more than 86% of residents are black, the COVID-19 death rates were 10 times higher than the national average &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. Considering how medical algorithms allocate resources to black patients, similar trends are expected for minorities, people who speak languages other than english, low-income residents, and people without insurance. At Brigham Health, a member of the not-for-profit Mass General Brigham health system, Karthik Sivashanker, Tam Duong, Shauna Ford, Cheryl Clark, and Sunil Eappen created data dashboards in order to assist staff and those in positions of leadership. The dashboards included rates of those who tested positive for COVID-19 sorted into different subgroups based on race, ethnicity, language, sex, insurance status, geographic location, health-care worker status, inpatient and ICU census, deaths, and discharges &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Through the use of these dashboards, the COVID-19 equity committee were able to identify emerging risks to incident command leaders, including the discovery that non-English speaking Hispanic patients had higher mortality rates when compared to English speaking Hispanic patients. This led to quality-improvement efforts to increase patient access to language interpreters. While attempting to implement these changes, it was discovered that efforts to reduce clinicians entering patient rooms to maintain social distancing guidelines was impacting the ability for interpreters to join at a patient&amp;rsquo;s bedside during clinician rounding. The incident command leadership expanded their virtual translation services by purchasing additional iPads to allow interpreters and patients to communicate through online software. The use of the geographic filter, when combined with a visual map of infection-rates by neighborhood, showed that people who lived in historically segregated and red-lined neighborhoods were tested less frequently but tested positive more frequently than those from affluent white neighborhoods &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. In a study conducted with survey data from the Pew Research Center on U.S. adults with internet access, black people were significantly more likely to report using telehealth services. In the same study, black and latino respondents had higher odds of using telehealth to report symptoms &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;However, COVID-19 is not the only disease that
researchers have found to be higher in historically segregated communities. In 1999, Laumann and Youm found that disparities segregation in social and sexual networks explained racial disparities in STDs which, they suggested, could also explain the disparities black people face in the spread of other diseases &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. Prior to 1999 researchers believed that some unexplained characteristic of black people described the spread of such diseases, which shows the pervasiveness of racism in healthcare and academia. Residential segregation may influence health by concentrating poverty, environmental pollutants, infectious agents, and other adverse conditions. In 2006, Morello-Frosch and Jesdale found that segregation increased the risk of cancer related to air pollution &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;. Big Data can assess national and local public health for disease prevention. An example is how the National Health Interview Survey is being used to estimate insurance coverage in different areas of the U.S. population and clinical data is being used to measure access and quality-related outcomes. Community-level data can be linked with health care system data using visualization and network analysis techniques which would enable public health officials and clinicians to effectively allocate resources and assess whether all patients are getting the medical services they need &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;. This would drastically improve the health of historically segregated and red-lined communities who are already seeing disparities during the COVID-19 pandemic.&lt;/p&gt;
&lt;h2 id=&#34;4-effect-of-precision-medicine-and-predictive-care&#34;&gt;4. Effect of Precision Medicine and Predictive Care&lt;/h2&gt;
&lt;p&gt;Public health experts established that the most important determinant of health throughout a person’s course of life is the environment where they live, learn, work, and play. There exists a discrepancy between electronic health record systems in well-resourced clinical practices and smaller clinical sites, leading to disparities in how they are able to support population health management. For Big Data technology, if patient, family, and community focus were implemented equally in both settings, it has shown that the social determinants of health information would both improve public health among minority communities and minimize the disparities that would arise. Geographic information systems are one way to locate social determinants of health. These help focus public health interventions on populations at greater risk of health disparities. Duke University used this type of system to visualize the distribution of individuals with diabetes across Durham County, NC in order to explore the gaps in access to care and self-management resources. This allowed them to identify areas of need and understand where to direct resources. A novel approach to identify place-based disparities in chronic diseases was used by Young, Rivers, and Lewis where they analyzed over 500 million tweets and found a significant association between the geographic location of HIV-related tweets and HIV prevalence, a disease which is known to predominantly affect the black community &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;One of the ways researchers call for strengthening the health of the nation is through community-level engagement. This is often ignored when it comes to precision medicine, which is one of the latest ways that big data is influencing healthcare. It has the potential to benefit racial and ethnic minority populations since there is a lack of clinical trial data with adequate numbers of minority populations. It is because of this lack of clinical data that predictions in precision medicine are often made off risks associated with the majority which give preferential treatment to those in the majority while ignoring the risks of minority groups, further widening the gap in the allocation of preventative health resources. These predictive algorithms are rooted in cost/benefit tradeoffs, which were proven to limit resources to black patients from the science magazine article on medical algorithms &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;. For the 13th Annual Texas Conference on Health Disparities, the overall theme was &amp;ldquo;Diversity in the Era of Precision Medicine.&amp;rdquo; Researchers at the event said diversity should be kept at the forefront when designing and implementing the study in order to increase participation by minority groups &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. Building a trusting relationship with the community is also necessary for increased participation, therefore the institution responsible for recruitment needs to be perceived as trustworthy by the community. Some barriers for participation shared among minority groups are hidden cost of participation, concern about misuse of research data, lack of understanding the consent form and research materials, language barrier, low perceived risk of disease, and fear of discrimination &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;. As discussed previously, overall lack of distrust in the research process is rooted in the fact that research involving minority groups often overwhelmingly benefits the majority by comparison. Due to the lack of representation of minority communities, big clinical data can be generated for the means of conducting pragmatic trials with underserved populations and distribute the lack of benefits &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;41-precision-public-health&#34;&gt;4.1 Precision Public Health&lt;/h3&gt;
&lt;p&gt;The benefit of the majority highlights the issue that one prevention strategy does not account for everyone. This is the motivation behind combining precision medicine and public health to create precision public health. The goal of this is to target populations that would benefit most from an intervention as well as identify which populations the intervention would not be suitable for. Machine learning applied to clinical data has been used to predict acute care use and cost of treatment for asthmatic patients and diagnose diabetes, both of which are known to affect black people at greater rates than white patients &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;. This takes into account the aforementioned factors that contribute to a person’s health and combines it with genomic data. Useful information about diseases at the population level are attributed to advancements in genetic epidemiology, through increased genetic and genomic testing. Integration of genomic technologies with public health initiatives have already shown success in preventing diabetes and cancers for certain groups, both of which affect black patients at greater rates than white patients. Specifically, black men have the highest incidence and mortality rates of prostate cancer. The presence of Kaiso, a transcriptional repressors present in human genes, is abundant in those with prostate cancer and, in black populations, it has been shown to increase cancer aggressive and reduce survival rates &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;. The greatest challenge affecting advancements made to precision public health is the involvement of all subpopulations required to get effective results. This demonstrates another area where there’s a need for the healthcare industry to prioritize building a stronger relationship with minority communities in order to assist in advancing healthcare.&lt;/p&gt;
&lt;p&gt;Building a stronger relationship with patients begins with having an understanding of the patient’s needs and their backgrounds, requiring multicultural understanding on the physicians side. This can be facilitated by the technological advances in healthcare. Researchers from Johns Hopkins University lay out three strategic approaches to improve multicultural communications. The first is providing direct services to minimize the gap in language barriers through the use of interpreters and increased linguistic competency in health education materials. The second is the incorporation of cultural homophily in care through staff who share a cultural background, inclusion of holistic medical suggestions, and the use of community health workers. Lastly, they highlight the need for more institutional accommodation such as increasing the ability of professionals to interact effectively within the culture of the patient population, more flexible hours of operation, and clinic locations &lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;. These strategic approaches are much easier to incorporate into practice when used in telehealth monitoring, providing more equitable care to minority patients who are able to use these services. There are three main sections of telehealth monitoring which include synchronous, asynchronous, and remote monitoring. Synchronous would be any real-time interaction, whether it be over the telephone or through audio/visual communication via a tablet or smartphone. This could occur when the patient is at their home or they are present with a healthcare professional while consulting with a medical provider virtually. Asynchronous communication occurs when patients communicate with their provider through a secure messaging platform in their patient portal. Remote patient monitoring is the direct transmission of a patient’s clinical measurements to their healthcare provider. Remote access to healthcare would be the most beneficial to those who are medically and socially vulnerable or those without ready access to providers and could also help preserve the patient-provider relationship &lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;. Connecting a patient to a provider that is from a similar cultural or ethnic background becomes easier through a virtual consultation, a form of synchronous telehealth monitoring. A virtual consultation would also help eliminate the need for transportation and open up the flexibility of meeting times for both the patient and the provider. From this, a way to increase minority patient satisfaction in regards to healthcare during the shift to telehealth services due to COVID-19 restrictions would be a push to increase technology access to these groups by providing them with low-cost technology with remote-monitoring capabilities.&lt;/p&gt;
&lt;h2 id=&#34;5-telehealth-and-telemedicine-applications&#34;&gt;5. Telehealth and Telemedicine Applications&lt;/h2&gt;
&lt;p&gt;Telehealth monitoring is evolving the patient-provider relationship by extending care beyond the in-person clinical visit. This provides an excellent opportunity to build a more trusting and personal relationship with the patient, which would be critical for minority patients as it would likely increase their trust in the healthcare system. Also, with an increase in transparency and involvement with their healthcare, the patient will be more engaged in the management of their healthcare which will likely have more satisfactory outcomes. Implementing these types of services will create large amounts of new data for patients, requiring big data applications in order to manage it. Similar to the issue of inequality in the common medical algorithm for determination of preventative care, if the data collected from minority groups using this method is not accounted for properly, then the issue of structural discrimination will continue. The data used in healthcare decision-making often comes from a patient’s electronic health record.  An issue that presents itself when considering the use of a patient’s electronic health record in the process of using big data to assist with the patient’s healthcare is missing data. In the scope of telehealth monitoring, since the visit and most of the patient monitoring would be done virtually, the electronic health record would need to be updated virtually as well &lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;For telehealth to be viable, the tools that accommodate it need to work seamlessly and be supported by the data streams that are integrated into the electronic health record. Most electronic health record systems are unable to be populated with remote self-monitoring patient-generated data &lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;. However, the American Telemedicine Association is advocating for remotely-monitored patient-generated data to be incorporated into electronic health records. The SMART Health IT platform is an approach that would allow clinical apps to run across health systems and integrate with electronic health records through the use of a standards-based open-source application programming interface (API) Fast Healthcare Interoperability Resources (FHIR). There are also advancements being made in technology that is capable of integrating data from electronic health records with claims, laboratory, imaging, and pharmacy data &lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;. There is also a push to include social determinants of health disparities including genomics and socioeconomic status in order to further research underlying causes of health disparities &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;51-limitations-of-teleheath-and-telemedicine&#34;&gt;5.1 Limitations of Teleheath and Telemedicine&lt;/h3&gt;
&lt;p&gt;The issue of lack of access to the internet and devices that would be necessary for virtual health visits would limit the participation of those from lower socioeconomic backgrounds. From this arises the issue of representativeness in remotely-monitored studies where the participant must have access to a smartphone or tablet. However, much like the Brigham Health group providing iPads in order to assist with language interpretation, there should be an incentive to provide access to these devices for patients in high risk groups in order to boost trust and representation in this type of care. From the article that discussed the survey results that found black and latino patients to be more responsive to using telehealth, the researchers contrasted the findings with another study where 52,000 Mount Sinai patients were monitored between March and May of 2020 that found black patients were less likely to use telehealth than white patients &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. One reason for the discrepancy the researchers introduce is that the Pew survey, while including data from across the country, only focused on adults that had internet access. This brings up the need for expanding broadband access, which is backed by many telehealth experts &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;The process of providing internet access and devices with internet capabilities to those without them should be similar to that from the science magazine study where patients whose risk scores are above a certain threshold should automatically qualify for technological assistance. Programs such as the Telehealth Network Grant Program would be beneficial for researchers conducting studies with a similar focus, as the grant emphasizes advancements in tele-behavioral health and tele-emergency medical services and providing access to these services to those who live in rural areas. Patients from rural areas are less likely to have access to technology that would enable them to participate in a study requiring remote monitoring. The grant proposal defines tele-emergency as an electronic, two-way, audio/visual communication service between a central emergency healthcare center, the tele-emergency hub, and a remote hospital emergency department designed to provide real-time emergency care consultation &lt;sup id=&#34;fnref:14&#34;&gt;&lt;a href=&#34;#fn:14&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;14&lt;/a&gt;&lt;/sup&gt;. This is especially important when considering that major medical algorithms show that black patients often spend more on emergency medical care.&lt;/p&gt;
&lt;h2 id=&#34;6-conclusion&#34;&gt;6. Conclusion&lt;/h2&gt;
&lt;p&gt;Big Data is changing many areas of healthcare and all of the areas that it’s affecting can benefit from making structural changes in order to allow minorities to get equitable healthcare. This includes how the applications are put into place, since Big Data has the ability to demonstrate bias and reinforce structural discrimination in care. It should be commonplace to consider race or ethnicity, socioeconomic status, and other relevant social determinants of health in order to account for this. Several studies have displayed the need for different allocations of resources based on race and ethnicity. From the findings that black patients were often given more equitable treatment when matched with a primary care provider that was black and that COVID-19 has limited in-person resources, such as a bedside interpreter for non-English speaking patients, there should be a development of a resource that allows people to be matched with a primary care provider that aligns with their identity and to connect with them virtually. When considering the lack of trust black people and other minority populations have in the healthcare system, there are a variety of services that would help boost trust in the process of getting proper care. Given the circumstances surrounding COVID-19 pandemic, there is already an emphasis on making improvements within telehealth monitoring as barriers to telehealth have been significantly reduced. Several machine-learning based studies have highlighted the importance of geographic location’s impact on aspects of the social determinants of health, including the effects in segregated communities. Recent work has shown that black and other ethnic minority patients report having less involvement in medical decisions and lower levels of satisfaction of care. This should motivate researchers who are focused on improving big data applications in the healthcare sector to focus on these communities in order to eliminate disparities in care and increase the amount of minority healthcare workers in order to have accurate representation. From the survey data showing that minority populations were more likely to use telehealth services, there needs to be an effort to highlight these communities in future work surrounding telehealth and telemedicine. Several studies have prepared a foundation for what needs to be improved and have already paved the way for additional research. With the progress that these studies have made and continued reports of inadequacies in care, it is only a matter of time before substantial change is implemented and equitable care is available.&lt;/p&gt;
&lt;h2 id=&#34;7-references&#34;&gt;7. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/kW1Y&#34;&gt;E. Weber, S. J. Miller, V. Astha, T. Janevic, and E. Benn, &amp;ldquo;Characteristics of telehealth users in NYC for COVID-related care during the coronavirus pandemic,&amp;rdquo; J. Am. Med. Inform. Assoc., Nov. 2020, doi: 10.1093/jamia/ocaa216.&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/Wsa3&#34;&gt;K. Senz, &amp;ldquo;Racial disparities in telemedicine: A research roundup,&amp;rdquo; Nov. 30, 2020. &lt;a href=&#34;https://journalistsresource.org/studies/government/health-care/racial-disparities-telemedicine/&#34;&gt;https://journalistsresource.org/studies/government/health-care/racial-disparities-telemedicine/&lt;/a&gt; (accessed Dec. 07, 2020).&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/VuXu&#34;&gt;C. L. F. Gilbert C. Gee, &amp;ldquo;STRUCTURAL RACISM AND HEALTH INEQUITIES: Old Issues, New Directions1,&amp;rdquo; Du Bois Rev., vol. 8, no. 1, p. 115, Apr. 2011, Accessed: Dec. 07, 2020. [Online].&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/NRPs&#34;&gt;Z. Obermeyer, B. Powers, C. Vogeli, and S. Mullainathan, &amp;ldquo;Dissecting racial bias in an algorithm used to manage the health of populations,&amp;rdquo; Science, vol. 366, no. 6464, pp. 447–453, Oct. 2019, Accessed: Dec. 07, 2020. [Online].&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/mDYj&#34;&gt;J. N. G. Chazeman S. Jackson, &amp;ldquo;Addressing Health and Health-Care Disparities: The Role of a Diverse Workforce and the Social Determinants of Health,&amp;rdquo; Public Health Rep., vol. 129, no. Suppl 2, p. 57, 2014, Accessed: Dec. 07, 2020. [Online].&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/IZ1k&#34;&gt;A. Mamun et al., &amp;ldquo;Diversity in the Era of Precision Medicine - From Bench to Bedside Implementation,&amp;rdquo; Ethn. Dis., vol. 29, no. 3, p. 517, 2019, Accessed: Dec. 07, 2020. [Online].&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/i6o0&#34;&gt;&amp;ldquo;A Data-Driven Approach to Addressing Racial Disparities in Health Care Outcomes,&amp;rdquo; Jul. 21, 2020. &lt;a href=&#34;https://hbr.org/2020/07/a-data-driven-approach-to-addressing-racial-disparities-in-health-care-outcomes&#34;&gt;https://hbr.org/2020/07/a-data-driven-approach-to-addressing-racial-disparities-in-health-care-outcomes&lt;/a&gt; (accessed Dec. 07, 2020).&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/euqs&#34;&gt;&amp;ldquo;Study: Black patients more likely than white patients to use telehealth because of pandemic,&amp;rdquo; Sep. 08, 2020. &lt;a href=&#34;https://www.healthcareitnews.com/news/study-black-patients-more-likely-white-patients-use-telehealth-because-pandemic&#34;&gt;https://www.healthcareitnews.com/news/study-black-patients-more-likely-white-patients-use-telehealth-because-pandemic&lt;/a&gt; (accessed Dec. 07, 2020).&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/E4t2&#34;&gt;X. Zhang et al., &amp;ldquo;Big Data Science: Opportunities and Challenges to Address Minority Health and Health Disparities in the 21st Century,&amp;rdquo; Ethn. Dis., vol. 27, no. 2, p. 95, 2017, Accessed: Dec. 07, 2020. [Online].&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/0HLR&#34;&gt;S. A. Ibrahim, M. E. Charlson, and D. B. Neill, &amp;ldquo;Big Data Analytics and the Struggle for Equity in Health Care: The Promise and Perils,&amp;rdquo; Health Equity, vol. 4, no. 1, p. 99, 2020, Accessed: Dec. 07, 2020. [Online].&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:11&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/A4tr&#34;&gt;Institute of Medicine (US) Committee on Understanding and Eliminating Racial and Ethnic Disparities, B. D. Smedley, A. Y. Stith, and A. R. Nelson, &amp;ldquo;PATIENT-PROVIDER COMMUNICATION: THE EFFECT OF RACE AND ETHNICITY ON PROCESS AND OUTCOMES OF HEALTHCARE,&amp;rdquo; in Unequal Treatment: Confronting Racial and Ethnic Disparities in Health Care, National Academies Press (US), 2003.&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:12&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/0RYU&#34;&gt;CDC, &amp;ldquo;Using Telehealth to Expand Access to Essential Health Services during the COVID-19 Pandemic,&amp;rdquo; Sep. 10, 2020. &lt;a href=&#34;https://www.cdc.gov/coronavirus/2019-ncov/hcp/telehealth.html&#34;&gt;https://www.cdc.gov/coronavirus/2019-ncov/hcp/telehealth.html&lt;/a&gt; (accessed Dec. 07, 2020).&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:13&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/lyDn&#34;&gt;&amp;quot;[No title].&amp;quot; &lt;a href=&#34;https://www.nejm.org/doi/full/10.1056/NEJMsr1503323&#34;&gt;https://www.nejm.org/doi/full/10.1056/NEJMsr1503323&lt;/a&gt; (accessed Dec. 07, 2020).&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:13&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:14&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://paperpile.com/b/9IXs7U/FjdO&#34;&gt;&amp;ldquo;Telehealth Network Grant Program,&amp;rdquo; Feb. 12, 2020. &lt;a href=&#34;https://www.hrsa.gov/grants/find-funding/hrsa-20-036&#34;&gt;https://www.hrsa.gov/grants/find-funding/hrsa-20-036&lt;/a&gt; (accessed Dec. 07, 2020).&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:14&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: Review of the Use of Wearables in Personalized Medicine</title>
      <link>/report/fa20-523-302/project/project/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-302/project/project/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-302/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-302/workflows/Check%20Report/badge.svg&#34; alt=&#34;Check Report&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-302/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-302/workflows/Status/badge.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
Status: final, Type: Project&lt;/p&gt;
&lt;p&gt;Adam Martin, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-302&#34;&gt;fa20-523-302&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-302/blob/main/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Wearable devices offer an abundant source of data on wearer activity and health metrics.  Smartphones and smartwatches have become increasingly
ubiquitous, and provide high-quality motion sensor data.  This research attempts to classify movement types, including running, walking, sitting, standing,
and going up and down stairs, to establish the practicality of sharing this raw data with healthcare workers.  It also addresses the existing research regarding
the use of wearable data in clinical settings and discusses shortcomings in making this data available.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#21-existing-devices&#34;&gt;2.1 Existing Devices&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#22-need-for-wearable-data-in-healthcare&#34;&gt;2.2 Need for Wearable Data in Healthcare&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-choice-of-dataset&#34;&gt;3. Choice of Dataset&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-methodology-and-code&#34;&gt;4. Methodology and Code&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-discussion&#34;&gt;5. Discussion&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#51-descriptive-analysis&#34;&gt;5.1 Descriptive Analysis&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#52-results&#34;&gt;5.2 Results&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-conclusion&#34;&gt;6. Conclusion&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#61-results&#34;&gt;6.1 Results&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#62-limitations&#34;&gt;6.2 Limitations&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#63-impact&#34;&gt;6.3 Impact&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#8-references&#34;&gt;8. References&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; Wearables, Classification, Descriptive Analysis, Healthcare, Movement Tracking, Precision Health, LSTM&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Wearables have been on the market for years now, gradually improving and providing increasingly insightful data on user health metrics. Most wearables contain an array of sensors allowing the user to track aspects of their physical health.
This includes heart rate, motion, calories burned, and some devices now support ECG and BMI measurements. This vast trove of data is valuable to consumers, as it allows for the measurement and gamification of key
health metrics. But can this data also be useful for health professionals in determining a patient’s activity levels and tracing important events in their health history?&lt;/p&gt;
&lt;h2 id=&#34;2-background-research-and-previous-work&#34;&gt;2. Background Research and Previous Work&lt;/h2&gt;
&lt;p&gt;Previous work exists on the use of sensors and wearables in assisted living environments.  Consumer wearables are commonplace and have been used primarily for tracking individual activity metrics.
This research attempts to establish the efficacy of these devices in providing useful data for user activity, and how this information could be useful for healthcare workers.
This paper examines the roadblocks in making this information available to healthcare professionals and examines what wearable information is currently being used in healthcare.&lt;/p&gt;
&lt;h3 id=&#34;21-existing-devices&#34;&gt;2.1 Existing Devices&lt;/h3&gt;
&lt;p&gt;Existing research focuses on a wide variety of inputs &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.  Sensors including electrodes, chemical probes, microphones, optical detectors, and blood glucose sensors are referenced as devices used for gathering healthcare information.  This research will focus on data that can be gathered with a modern smartphone or smartwatch.  Most of the sensors described are not as ubiquitous as consumer items like FitBits or Apple Watches.
Furthermore, many users report diminished enthusiasm towards wearables due to complex sensors and pairing processes &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.  Focusing on devices that are already successful in the consumer market
ensures that the impact of this study will not be confined to specific users and use cases.  Apple has released a suite of tools for interfacing with device sensors, and recently launched
ResearchKit and CareKit, providing a framework for researchers and healthcare workers to collect and analyze user data &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;.  There are several apps available that utilize these tools, including
Johns Hopkins&#39; CorrieHealth app, which helps users manage their heart health care and shares data with their doctors.  This is an encouraging step towards streamlining the sharing of
wearable data between patients and healthcare professionals, as Apple provides standards for privacy, consent, and data quality.&lt;/p&gt;
&lt;h3 id=&#34;22-need-for-wearable-data-in-healthcare&#34;&gt;2.2 Need for Wearable Data in Healthcare&lt;/h3&gt;
&lt;p&gt;Previous studies have indicated the significance of precision health and the need for patient-specific data from wearables to be integrated into a patient&amp;rsquo;s care strategy &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.
Wearable data outlining a patient&amp;rsquo;s sleep, motion habits, heart rate, and other metrics can be invaluable in diagnosing or predicting conditions.  Increased sedentary activity could indicate
depression, and could predict future heart problems. A patient&amp;rsquo;s health could be graphed and historical trends could be useful in determining factors that contribute to the patient&amp;rsquo;s condition.
It is often asserted that a person&amp;rsquo;s environmental factors are better predictors for their health than their genetic makeup &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.  Linking behavioral and social determinants with biomedical data
would allow professionals to better target certain conditions.&lt;/p&gt;
&lt;h2 id=&#34;3-choice-of-dataset&#34;&gt;3. Choice of Dataset&lt;/h2&gt;
&lt;p&gt;The dataset used for this project contains labeled movement data from wearable devices.  The goal is to establish the potential for wearable devices to provide high-quality data to users and healthcare professionals.&lt;/p&gt;
&lt;p&gt;A dataset gathered from 24 individuals with Apple devices measuring attitude, gravity, and acceleration was used to determine user states.  The dataset is labeled with six states (walking downstairs,
walking upstairs, sitting, standing, walking and jogging) and each sensor has several attributes describing its motion. The attitude, gravity, and acceleration readings each have three components corresponding to each
axis of freedom.  Many smartphones and wearables already offer comprehensive sleep tracking features, so sleep motion
data will not be considered for this study.  The CrowdSense iOS application was used to record user movements.  Each sensor was configured to sample at 50hz, and each user was instructed to start the recording,
and begin their assigned activity.&lt;/p&gt;
&lt;h2 id=&#34;4-methodology-and-code&#34;&gt;4. Methodology and Code&lt;/h2&gt;
&lt;p&gt;The IPython notebook used for this analysis is available on the &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-302/blob/main/project/code/Wearables.ipynb&#34;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The analysis of relevant wearable data is undertaken to determine the accuracy of activity information.  This analysis will consist of a brief descriptive analysis of the motion tracking data,
and will proceed with attempts to classify the labeled data.&lt;/p&gt;
&lt;p&gt;First, the data has to be downloaded from the MotionSense project on GitHub.  A basic descriptive analysis will be performed, visualizing the sensor values for each movement class over time.
During the data acquisition, the sensors are sampled at a 50hz rate.  Since the dataset is a timeseries, classification methods that take advantage of historical datapoints will be the most effective.
The Keras Long Short Term Memory classifier implementation is used for this task.  The dataset is first split into its various classes of motion using the one-hot-encoded matrix to filter out each
class.  Each class is then subdivided into one-second &amp;lsquo;windows&amp;rsquo;, each with 50 entries.  Each window is offset by 10 entries from the previous window.  The use of windows allows the model to remain small
in size, while still gathering enough information to make accurate classifications.  The hyperparameters that can be tuned include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Window size (50)&lt;/li&gt;
&lt;li&gt;Window offset (10)&lt;/li&gt;
&lt;li&gt;LSTM size (50)&lt;/li&gt;
&lt;li&gt;Dense layer size (50)&lt;/li&gt;
&lt;li&gt;Batch size (64)&lt;/li&gt;
&lt;li&gt;Epochs (15)&lt;/li&gt;
&lt;li&gt;Dropout ratio (0.5)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The resulting data structure is a 3-dimensional array of shape (107434, 12, 50) for the training set and (32439, 12, 50) for the testing set.  The dimensions correspond to the number of windows, the number of movement
features, and the number of samples per window, respectively.  These windows are then paired with their corresponding movement classifications and fed into a Keras LSTM workflow.  This workflow is executed on a standard (non-gpu)
Google Colab instance and benchmarked.  The workflow consists of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Long Short Term Memory layer with the cell count matching the size of the input window (50)&lt;/li&gt;
&lt;li&gt;A Dropout layer to minimize overfitting&lt;/li&gt;
&lt;li&gt;A fully connected layer with relu activation to help learn the weights of the LSTM output&lt;/li&gt;
&lt;li&gt;A fully connected output layer with a softmax activation to return the final classifications&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The model is trained in 15 epochs, and uses a batch size of 64 for each backpropagation.&lt;/p&gt;
&lt;p&gt;If a classification strategy of sufficient accuracy is possible, it will be determined that wearable data can potentially serve as a useful supplementary source of information to aid in establishing a patient&amp;rsquo;s
medical history.&lt;/p&gt;
&lt;p&gt;Reviewing relevant literature is important to determine the current state of wearables research regarding usefulness to healthcare workers and user well-being.
Much of this research will be focused on determining the state of wearables in the healthcare industry and determining if there is a need for streamlined data transfer to healthcare professionals.&lt;/p&gt;
&lt;h2 id=&#34;5-discussion&#34;&gt;5. Discussion&lt;/h2&gt;
&lt;p&gt;The dataset is comprised of six discrete classes of movement.  There are 12 parameters describing the readouts of the sensors over time.&lt;/p&gt;
&lt;h3 id=&#34;51-descriptive-analysis&#34;&gt;5.1 Descriptive Analysis&lt;/h3&gt;
&lt;p&gt;There is an imbalance in the number of datapoints for each class, which could lead to classification errors.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-302/main/project/images/occurence.png&#34; alt=&#34;Figure 1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; Data distribution per movement class.&lt;/p&gt;
&lt;p&gt;Only roll, pitch, and yaw are shown for clarity and to illustrate the quality of the readings obtained by the sensors.  Figures 2-7 illustrate sensor readouts over time for each class of movement.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-302/main/project/images/timeseries_run.png&#34; alt=&#34;Figure 2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; 10 second sensor readout of a jogging male.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-302/main/project/images/timeseries_downstairs.png&#34; alt=&#34;Figure 3&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; 20 second sensor readout of a female going downstairs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-302/main/project/images/timeseries_upstairs.png&#34; alt=&#34;Figure 4&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 4:&lt;/strong&gt; 20 second sensor readout of a male going upstairs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-302/main/project/images/timeseries_walk.png&#34; alt=&#34;Figure 5&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 5:&lt;/strong&gt; 10 second sensor readout of a female walking.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-302/main/project/images/timeseries_sit.png&#34; alt=&#34;Figure 6&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 6:&lt;/strong&gt; 10 second sensor readout of a male sitting.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-302/main/project/images/timeseries_stand.png&#34; alt=&#34;Figure 7&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 7:&lt;/strong&gt; 10 second sensor readout of a female standing.&lt;/p&gt;
&lt;p&gt;Interestingly, initial classification attempts involving random forests and knn methods performed fairly well despite their inherent lack of awareness of historical data.&lt;/p&gt;
&lt;h3 id=&#34;52-results&#34;&gt;5.2 Results&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-302/main/project/images/LSTM_benchmark.png&#34; alt=&#34;Figure 8&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 8:&lt;/strong&gt; Cloudmesh benchmark for LSTM train and test.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-302/main/project/images/lstm_curves.png&#34; alt=&#34;Figure 9&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 9&lt;/strong&gt; LSTM training and loss curves.&lt;/p&gt;
&lt;p&gt;The final accuracy measurement for the LSTM was &lt;strong&gt;%95.42&lt;/strong&gt;.  This proves that discrete movement classes can be determined through the analysis of basic sensor data regarding device movement.&lt;/p&gt;
&lt;h2 id=&#34;6-conclusion&#34;&gt;6. Conclusion&lt;/h2&gt;
&lt;h3 id=&#34;61-results&#34;&gt;6.1 Results&lt;/h3&gt;
&lt;p&gt;Using relatively basic machine learning methods, it is possible to determine with a high level of accuracy the type of movement being performed at a given moment.  Viewing the benchmarks,
the inference time is rapid, taking only 3 seconds to validate results for the entire testing dataset.  This model could be distilled for a production environment, and the rapid inference speed
would allow for faster analyses for end users.&lt;/p&gt;
&lt;h3 id=&#34;62-limitations&#34;&gt;6.2 Limitations&lt;/h3&gt;
&lt;p&gt;The classes of movement considered for this study were limited.  For more precise movements, or movement combinations, more data and a more complex model would be required.  For example;
classifying the type of activity being done while a user is seated, if they are typing or eating.  Future research could involve a wider review of timeseries classifiers, including transformers
convolutional neural networks, and recurrent neural networks, in order to establish what classification strategy would be best suited for this data.  Privacy is also important to consider; raw sensor data could provide malicious actors with
information regarding a users daily habits, their gender, their location, and other sensitive data.&lt;/p&gt;
&lt;p&gt;Existing research highlights some of the issues with the adoption of wearable devices in healthcare.  Inconsistent reporting, usage, and data quality are the most common concerns &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.  Addressing
these issues through an analysis of data quality and device usage could contribute towards the robustness of this study.&lt;/p&gt;
&lt;h3 id=&#34;63-impact&#34;&gt;6.3 Impact&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/cybertraining-dsc/fa20-523-302/main/project/images/service_prop.png&#34; alt=&#34;Figure 10&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 10&lt;/strong&gt; Proposal for integration of wearables data with other data sources and healthcare portals.&lt;/p&gt;
&lt;p&gt;Frameworks like Apple CareKit and Google Fit are emerging to address the increasing demand for health tracking applications.  There is a need for a more effective pipeline for sharing this information
securely with doctors and researchers, and these frameworks are a step in the right direction.  Furthermore, this research can be applied towards finding correlations between a patient&amp;rsquo;s condition and
their activity history, or helping a patient reach certain goals towards their overall well-being.  Comprehensive movement history can be combined with device usage patterns, eating habit data, self-reported
well-being data, and other relevant sources to establish a more holistic perspective of a patient&amp;rsquo;s health.
Giving users and healthcare workers access to and insights on the data that they generate every day can promote healthier habits, increase physician efficacy, and promote overall well-being.  The author proposes
the idea of a centralized system for user data tracking.  This could support cross-platform devices, and tie into other fitness and well-being apps to provide a centralized and holistic view of a user&amp;rsquo;s health.
A system of this nature could also tie in information from patient portals, including test results, checkup info, and prescription information.&lt;/p&gt;
&lt;h2 id=&#34;7-acknowledgements&#34;&gt;7. Acknowledgements&lt;/h2&gt;
&lt;p&gt;The author would like to thank Dr. Gregor von Laszewski for his invaluable feedback on this paper, and Dr. Geoffrey Fox for sharing his expertise in Big Data applications throughout this course.&lt;/p&gt;
&lt;h2 id=&#34;8-references&#34;&gt;8. References&lt;/h2&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Yetisen, Ali K. (2018, August 16).  I Retrieved November 15, 2020 from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6541866/&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6541866/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Piwek L, Ellis DA, Andrews S, Joinson A. The Rise of Consumer Health Wearables: Promises and Barriers (2016, February 02).  I Retrieved November 11, 2020 from &lt;a href=&#34;https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001953&#34;&gt;https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001953&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Loncar-Turukalo, Tatjana.  Literature on Wearable Technology for Connected Health: Scoping Review of Research Trends, Advances, and Barriers (2019, September 21).  I Retrieved December 1st from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6818529/&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6818529/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Glasgow, Russell E. Realizing the full potential of precision health: The need to include patient-reported health behavior, mental health, social determinants, and patient preferences data (2018, September 13). I Retrieved November 15, 2020 from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6202010/&#34;&gt;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6202010/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Malekzadeh, Mohammad. Mobile Sensor Data Anonymization (2018).  I Retrieved September 18, 2020 from &lt;a href=&#34;http://doi.acm.org/10.1145/3302505.3310068&#34;&gt;http://doi.acm.org/10.1145/3302505.3310068&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
    <item>
      <title>Report: Detect and classify pathologies in chest X-rays using PyTorch library</title>
      <link>/report/fa20-523-319/project/project/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>/report/fa20-523-319/project/project/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-319/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/workflows/Check%20Report/badge.svg&#34; alt=&#34;Check Report&#34;&gt;&lt;/a&gt;
&lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-319/actions&#34;&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/workflows/Status/badge.svg&#34; alt=&#34;Status&#34;&gt;&lt;/a&gt;
Status: final&lt;/p&gt;
&lt;p&gt;Rama Asuri, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-319/&#34;&gt;fa20-523-319&lt;/a&gt;, &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-319/blob/main/project/project.md&#34;&gt;Edit&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Code: &lt;a href=&#34;https://github.com/cybertraining-dsc/fa20-523-319/blob/main/project/project.ipynb&#34;&gt;project.ipynb&lt;/a&gt;&lt;/p&gt;


&lt;div class=&#34;pageinfo pageinfo-primary&#34;&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Chest X-rays reveal many diseases. Early detection of disease often improves the survival chance for Patients. It is one of the important tools for Radiologists to detect and identify underlying health conditions. However, they are two major drawbacks. First, it takes time to analyze a radiograph. Second,  Radiologists make errors. Whether it is an error in diagnosis or delay in diagnosis, both outcomes result in a loss of life. With the technological advances in AI, Deep Learning models address these drawbacks. The  Deep Learning models analyze the X-rays like a Radiologist and accurately predict much better than the Radiologists. In our project, first, we develop a Deep Learning model and train our model to use the labels for Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion that corresponds to 5 different diseases, respectively. Second, we test our model&amp;rsquo;s performance: how well our model predicts the diseases. Finally, we visualize our model&amp;rsquo;s performance using the AUC-ROC curve.&lt;/p&gt;
&lt;p&gt;Contents&lt;/p&gt;
&lt;div class=&#34;toc&#34;&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#1-introduction&#34;&gt;1. Introduction&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#2-overview-of-pytorch-library&#34;&gt;2. Overview Of PyTorch Library&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#3-overview-of-densenet&#34;&gt;3. Overview of DenseNet&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#31-dense-blocks&#34;&gt;3.1 Dense blocks&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#32-transition-layers&#34;&gt;3.2 Transition layers&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#4-overview-of-chexpert-dataset&#34;&gt;4. Overview of CheXpert Dataset&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#41-data-collection&#34;&gt;4.1 Data Collection&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#42-data-labelling&#34;&gt;4.2 Data Labelling&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#43-label-extraction&#34;&gt;4.3 Label Extraction&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#44-label-classification&#34;&gt;4.4 Label Classification&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#45-label-aggregation&#34;&gt;4.5 Label Aggregation&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#5-overview-of-auc-roc-curve&#34;&gt;5. Overview Of AUC-ROC Curve&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#51-sensitivitytrue-positive-rate-tpr&#34;&gt;5.1 Sensitivity/True Positive Rate (TPR)&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#52-false-negative-rate-fnr&#34;&gt;5.2 False Negative Rate (FNR)&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#53-specificitytrue-negative-rate-tnr&#34;&gt;5.3 Specificity/True Negative Rate (TNR)&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#54-false-positive-rate-fpr&#34;&gt;5.4 False Positive Rate (FPR)&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#55-purpose-of-auc-roc-curve&#34;&gt;5.5 Purpose of AUC-ROC curve&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#56-definition-of-auc-roc&#34;&gt;5.6 Definition of AUC-ROC&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#6-chest-x-rays---multi-image-classification-using-deep-learning-model&#34;&gt;6. Chest X-Rays - Multi-Image Classification Using Deep Learning Model&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#61-load-and-split-chest-x-rays-dataset&#34;&gt;6.1 Load and split Chest X-rays Dataset&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#62-build-and-train-baseline-deep-learning-model&#34;&gt;6.2 Build and train baseline Deep Learning model&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#63-evaluate-the-model&#34;&gt;6.3 Evaluate the model&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#64-predict-the-pathologies&#34;&gt;6.4 Predict the pathologies&lt;/a&gt;&lt;/li&gt;
        &lt;li&gt;&lt;a href=&#34;#65-calculate-the-auc-roc-score&#34;&gt;6.5 Calculate the AUC-ROC score&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#7-results-and-analysis&#34;&gt;7. Results and Analysis&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#8-conclusion&#34;&gt;8. Conclusion&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#9-future-plans&#34;&gt;9. Future Plans&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#10-acknowledgements&#34;&gt;10. Acknowledgements&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#11-references&#34;&gt;11. References&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#12-appendix&#34;&gt;12. Appendix&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&#34;#121-project-plan&#34;&gt;12.1 Project Plan&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Keywords:&lt;/strong&gt; PyTorch, CheXpert&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Radiologists widely use chest X-Rays to identify and detect underlying conditions. However, analyzing Chest X-Rays takes too much time, and accurately diagnosing without errors requires considerable experience. On the one hand, if the analyzing process is expedited, it might result in misdiagnosis, but on the other hand, lack of experience means long analysis time and/or errors; even with the correct diagnosis, it might be too late to prescribe a treatment. Radiologists are up against time and experience. With the advancements in AI, Deep Learning can easily solve this problem quickly and efficiently.&lt;/p&gt;
&lt;p&gt;Deep Learning methods are becoming very reliable at achieving expert-level performance using large labeled datasets. Deep learning is a technique to extract and transform data using multiple layers of neural networks. Each layer takes inputs from previous layers and incrementally refines it. An algorithm is used to train these layers to minimize errors and improve these layers&#39; overall accuracy &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;. It enables the network to learn to perform a specified task and gain an expert level performance by training on large datasets. The scope of this project is to identify and detect the following 5 pathologies using an image classification algorithm: Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion.  We use the CheXpert dataset, which consists of Chest X-rays. CheXpert dataset contains 224,316 chest Radiographs of 65,240 patients. The dataset has 14 observations in radiology reports and captures uncertainties inherent in radiograph interpretation using uncertainty labels. Our focus is on 5 observations (Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion). We impute uncertainty labels with randomly selected Boolean values.  Our Deep Learning models are developed using the PyTorch library, enabling fast, flexible experimentation and efficient production through a user-friendly front-end, distributed training, and ecosystem of tools and libraries &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. It was primarily developed by Facebook&amp;rsquo;s AI Research lab (FAIR) and used for Computer Vision and NLP applications. PyTorch supports Python and C++ interfaces. There are popular Deep Learning applications built using PyTorch, including Tesla Autopilot, Uber&amp;rsquo;s Pyro &lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;In this analysis, first, we begin with an overview of the PyTorch library and DenseNet. We cover DenseNet architecture and advantages over ResNet for Multi-Image classification problems. Second, we explain the CheXpert dataset and how the classifiers are labeled, including uncertainties. Next, we cover the AUC-ROC curve&amp;rsquo;s basic definitions and how it measures a model&amp;rsquo;s performance. Finally, we explain how our Deep Learning model classifies pathologies and conclude with our model&amp;rsquo;s performance and results.&lt;/p&gt;
&lt;h2 id=&#34;2-overview-of-pytorch-library&#34;&gt;2. Overview Of PyTorch Library&lt;/h2&gt;
&lt;p&gt;The PyTorch library is based on Python and is used for developing Python deep learning models. Many of the early adopters of the PyTorch are from the research community. It grew into one of the most popular libraries for deep learning projects. PyTorch provides great insight into Deep Learning. PyTorch is widely used in real-world applications. PyTorch makes an excellent choice for introducing deep learning because of clear syntax, streamlined API, and easy debugging. PyTorch provides a core data structure, the tensor, a multidimensional array similar to NumPy arrays. It performs accelerated mathematical operations on dedicated hardware, making it convenient to design neural network architectures and train them on individual machines or parallel computing resources &lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;3-overview-of-densenet&#34;&gt;3. Overview of DenseNet&lt;/h2&gt;
&lt;p&gt;We use a pre-trained DenseNet model, which classifies the images. DenseNet is new Convolutional Neural Network architecture which is efficient on image classification benchmarks as compared to ResNet &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;. RestNets, Highway networks, and deep and wide neural networks add more inter-layer connections than the direct connection in adjacent layers to boost information flow and layers. Similar to ResNet, DenseNet adds shortcuts among layers. Different from ResNet, a layer in dense receives all the outputs of previous layers and concatenate them in the depth dimension. In ResNet, a layer only receives outputs from the last two layers, and the outputs are added together on the individual same depth. Therefore it will not change the depth by adding shortcuts. In other words, in ResNet the output of layer of k is x[k] = f(w * x[k-1] + x[k-2]), while in DenseNet it is x[k] = f(w * H(x[k-1], x[k-2], &amp;hellip; x[1])) where H means stacking over the depth dimension. Besides, ResNet makes learn the identity function easy, while DenseNet directly adds an identity function &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Figure 1 shows the DenseNet architecture.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/densetnet.png&#34; alt=&#34;Figure 1&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; DenseNet Architecture &lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;As shown in Figure 1, DenseNet contains a feature layer (convolutional layer) capturing low-level features from images, several dense blocks, and transition layers between adjacent dense blocks &lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;31-dense-blocks&#34;&gt;3.1 Dense blocks&lt;/h3&gt;
&lt;p&gt;Dense block contains several dense layers. The depth of a dense layer output is called growth_rate. Every dense layer receives all the output of its previous layers. The input depth for the kth layer is (k-1)*growth_rate + input_depth_of_first_layer. By adding more layers in a dense block, the depth will grow linearly. For example, if the growth rate is 30 and after 100 layers, the depth will be over 3000. However, this could lead to a computational explosion. It is addressed by introducing a transition layer to reduce and abstract the features after a dense block with a limited number of dense layers to circumvent this problem &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;. A 1x1 convolutional layer (bottleneck layer) is added to reduce the computation, which makes the second convolutional layer always has a fixed input depth. It is also easy to see the size (width and height) of the feature maps keeps the same through the dense layer, making it easy to stack any number of dense layers together to build a dense block. For example, densenet121 has four dense blocks with 6, 12, 24, and 16 dense layers. With repetition, it is not that difficult to make 112 layers &lt;sup id=&#34;fnref:7&#34;&gt;&lt;a href=&#34;#fn:7&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;7&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;32-transition-layers&#34;&gt;3.2 Transition layers&lt;/h3&gt;
&lt;p&gt;In general, the size of every layer&amp;rsquo;s output in Convolutional Neural Network decreases to abstract higher-level features. In DenseNet, the transition layers take this responsibility while the dense blocks keep the size and depth. Every transition layer contains a 1x1 convolutional layer and a 2x2 average pooling layer to reduce the size to half. However, transition layers also receive all the output from all the last dense block layers. So the 1*1 convolutional layer reduces the depth to a fixed number, while the average pooling reduces the size.&lt;/p&gt;
&lt;h2 id=&#34;4-overview-of-chexpert-dataset&#34;&gt;4. Overview of CheXpert Dataset&lt;/h2&gt;
&lt;p&gt;CheXpert is a large public dataset. It contains an interpreted chest radiograph consisting of 224,316 chest radiographs
of 65,240 patients labeled for the presence of 14 observations as positive, negative, or uncertain &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Figure 2 shows the CheXpert 14 labels and the Probability &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;. Our analysis is to predict the probability of 5 different observations (Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion) from multi-view chest radiographs shown in Figure 2&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/chest_disease.png&#34; alt=&#34;Figure 2&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; Probability of different observations &lt;sup id=&#34;fnref:9&#34;&gt;&lt;a href=&#34;#fn:9&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;9&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;41-data-collection&#34;&gt;4.1 Data Collection&lt;/h3&gt;
&lt;p&gt;CheXpert dataset is a collection of chest radiographic studies from Stanford Hospital, performed between October 2002 and July 2017 in inpatient and outpatient centers, along with their associated radiology reports. Based on studies, a sampled set of 1000 reports were created for manual review by a board-certified radiologist to determine the feasibility for extraction of observations. The final set consists of 14 observations based on the prevalence in the reports and clinical relevance, conforming to the Fleischner Society’s recommended glossary. &lt;em&gt;Pneumonia&lt;/em&gt;, despite
being a clinical diagnosis, &lt;em&gt;Pneumonia&lt;/em&gt; was included as a label to represent the images that suggested primary infection as the diagnosis. The &lt;em&gt;No Finding&lt;/em&gt; observation was intended to capture the absence of all pathologies &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;42-data-labelling&#34;&gt;4.2 Data Labelling&lt;/h3&gt;
&lt;p&gt;Labels developed using an automated, rule-based labeler to extract observations from the free text radiology reports to be used as structured labels for the images &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;43-label-extraction&#34;&gt;4.3 Label Extraction&lt;/h3&gt;
&lt;p&gt;The labeler extracts the pathologies mentioned in the list of observations from the Impression section of radiology reports, summarizing the key findings in the radiographic study. Multiple board-certified radiologists manually curated a large list of phrases to match various observations mentioned in the reports &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;44-label-classification&#34;&gt;4.4 Label Classification&lt;/h3&gt;
&lt;p&gt;Labeler extracts the mentions of observations and classify them as negative (&amp;ldquo;no evidence of pulmonary edema, pleural effusions or pneumothorax&amp;rdquo;), uncertain (&amp;ldquo;diffuse reticular pattern may represent mild interstitial pulmonary edema&amp;rdquo;), or positive (&amp;ldquo;moderate bilateral effusions and bibasilar opacities&amp;rdquo;). The &amp;lsquo;uncertain&amp;rsquo; label can capture both the uncertainty of a radiologist in the diagnosis as well as the ambiguity inherent in the report (&amp;ldquo;heart size is stable&amp;rdquo;). The mention classification stage is a 3-phase pipeline consisting of pre-negation uncertainty, negation, and post-negation uncertainty. Each phase consists of rules that are matched against the mention; if a match is found, the mention is classified accordingly (as uncertain in the first or third phase and as negative in the second phase). If a mention is not matched in any of the phases, it is classified as positive &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;45-label-aggregation&#34;&gt;4.5 Label Aggregation&lt;/h3&gt;
&lt;p&gt;CheXpert dataset use the classification for each mention of observations to arrive at a final label for 14 observations that consist of 12 pathologies and the &amp;ldquo;Support Devices&amp;rdquo; and &amp;ldquo;No Finding&amp;rdquo; observations. Observations with at least one mention positively classified in the report are assigned a positive (1) label. An observation is assigned an uncertain (u) label if it has no positively classified mentions and at least one uncertain mention, and a negative label if there is at least one negatively classified mention. We assign (blank) if there is no mention of an observation. The &amp;ldquo;No Finding&amp;rdquo; observation is assigned a positive label (1) if there is no pathology classified as positive or uncertain &lt;sup id=&#34;fnref:8&#34;&gt;&lt;a href=&#34;#fn:8&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;8&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;5-overview-of-auc-roc-curve&#34;&gt;5. Overview Of AUC-ROC Curve&lt;/h2&gt;
&lt;p&gt;AUC-ROC stands for Area Under Curve - Receiver Operating Characteristics. It visualizes how well a machine learning classifier is performing. However, it works for only binary classification problems &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;. In our project, we extend it to evaluate Multi-Image classification problem. AUC-ROC curve is a performance measurement for classification problems at various threshold settings. ROC is a probability curve, and AUC represents the degree or measure of separability. Higher the AUC, the better the model is at predicting 0s as 0s and 1s as 1s. By analogy, the Higher the AUC, the model distinguishes between patients with the disease and no disease &lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Figure 3 shows Confusion Matrix. We use Confusion Matrix to explain Sensitivity and Specificity.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/confusion_matrix.png&#34; alt=&#34;Figure 3&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; Confusion Matrix&lt;/p&gt;
&lt;h3 id=&#34;51-sensitivitytrue-positive-rate-tpr&#34;&gt;5.1 Sensitivity/True Positive Rate (TPR)&lt;/h3&gt;
&lt;p&gt;Sensitivity/True Positive Rate (TPR) explains what proportion of the positive class got correctly classified. A simple example would be determining what proportion of the actual sick people are correctly detected by the model &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/TPR.png&#34; alt=&#34;Figure 4&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;52-false-negative-rate-fnr&#34;&gt;5.2 False Negative Rate (FNR)&lt;/h3&gt;
&lt;p&gt;False Negative Rate (FNR) explains what proportion of the positive class is incorrectly classified by the classifier. A higher TPR and a lower FNR means correctly classify the positive class &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/FNR.png&#34; alt=&#34;Figure 5&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;53-specificitytrue-negative-rate-tnr&#34;&gt;5.3 Specificity/True Negative Rate (TNR)&lt;/h3&gt;
&lt;p&gt;Specificity/True Negative Rate (TNR) indicates what proportion of the negative class is classified correctly. For example, Specificity determines what proportion of actual healthy people are correctly classified as healthy by the model &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/TNR.png&#34; alt=&#34;Figure 6&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;54-false-positive-rate-fpr&#34;&gt;5.4 False Positive Rate (FPR)&lt;/h3&gt;
&lt;p&gt;False Positive Rate (FPR) indicates what proportion of the negative class got incorrectly classified by the classifier. A higher TNR and a lower FPR means the model correctly classifies the negative class&lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/FPR.png&#34; alt=&#34;Figure 7&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;55-purpose-of-auc-roc-curve&#34;&gt;5.5 Purpose of AUC-ROC curve&lt;/h3&gt;
&lt;p&gt;A machine learning classification model can predict the actual class of the data point directly or predict its probability of belonging to different classes. The example for the former case is where a model can classify whether a patient is healthy or not healthy. In the latter case, a model can predict a patient&amp;rsquo;s probability of being healthy or not healthy and provide more control over the result by enabling a way to tune the model&amp;rsquo;s behavior by changing the threshold values. This is powerful because it eliminates the possibility of building a completely new model to achieve a different range of results &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;. A threshold value helps to interpret the probability and map the probability to a class label. For example, a threshold value such as 0.5, where all values equal to or greater than the threshold, is mapped to one class and rests to another class &lt;sup id=&#34;fnref:12&#34;&gt;&lt;a href=&#34;#fn:12&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;12&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Introducing different thresholds for classifying positive class for data points will inadvertently change the Sensitivity and Specificity of the model. Furthermore, one of these thresholds will probably give a better result than the others, depending on whether we aim to lower the number of False Negatives or False Positives &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.
As seen in Figure 8, the metrics change with the changing threshold values. We can generate different confusion matrices and compare the various metrics. However, it is very inefficient. Instead, we can generate a plot between some of these metrics so that we can easily visualize which threshold is giving us a better result. The AUC-ROC curve solves just that &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/aucroc.png&#34; alt=&#34;Figure 8&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 8:&lt;/strong&gt; Probability of prediction and metrics &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h3 id=&#34;56-definition-of-auc-roc&#34;&gt;5.6 Definition of AUC-ROC&lt;/h3&gt;
&lt;p&gt;The Receiver Operator Characteristic (ROC) curve is an evaluation metric for binary classification problems. It is a probability curve that plots the TPR against FPR at various threshold values and essentially separates the signal from the noise. The Area Under the Curve (AUC) is the measure of a classifier&amp;rsquo;s ability to distinguish between classes and is used as a summary of the ROC curve. The higher the AUC, the better the model&amp;rsquo;s performance at distinguishing between the positive and negative classes. When AUC = 1, the classifier can perfectly distinguish between all the Positive and the Negative class points correctly. If, however, the AUC had been 0, then the classifier would be predicting all Negatives as Positives and all Positives as Negatives. When 0.5&amp;lt;AUC&amp;lt;1, there is a high chance that the classifier will be able to distinguish the positive class values from the negative class values. This is because the classifier can detect more True positives and True negatives than False negatives and False positives. When AUC=0.5, then the classifier is not able to distinguish between Positive and Negative class points. It means either the classifier is predicting random class or constant class for all the data points. Therefore, the higher the AUC value for a classifier, the better its ability to distinguish between positive and negative classes. In the AUC-ROC curve, a higher X-axis value indicates a higher number of False positives than True negatives. Simultaneously, a higher Y-axis value indicates a higher number of True positives than False negatives. So, the choice of the threshold depends on balancing between False positives and False negatives &lt;sup id=&#34;fnref:10&#34;&gt;&lt;a href=&#34;#fn:10&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;10&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id=&#34;6-chest-x-rays---multi-image-classification-using-deep-learning-model&#34;&gt;6. Chest X-Rays - Multi-Image Classification Using Deep Learning Model&lt;/h2&gt;
&lt;p&gt;Our Deep Learning model loads and processes the raw data files and implement a Python class to represent data by
converting it into a format usable by PyTorch. We then, visualize the training and validation data.&lt;/p&gt;
&lt;p&gt;Our approach to predicting pathologies will have 5 steps.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Load and split Chest X-rays Dataset&lt;/li&gt;
&lt;li&gt;Build and train baseline Deep Learning model&lt;/li&gt;
&lt;li&gt;Evaluate the model&lt;/li&gt;
&lt;li&gt;Predict the pathologies&lt;/li&gt;
&lt;li&gt;Calculate the AUC-ROC score&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;61-load-and-split-chest-x-rays-dataset&#34;&gt;6.1 Load and split Chest X-rays Dataset&lt;/h3&gt;
&lt;p&gt;We load and split the dataset to 90% for training and 10% for validation randomly.&lt;/p&gt;
&lt;h3 id=&#34;62-build-and-train-baseline-deep-learning-model&#34;&gt;6.2 Build and train baseline Deep Learning model&lt;/h3&gt;
&lt;p&gt;We use the PyTorch library to implement and train DenseNet CNN as a baseline model. With initial weights from ImageNet, we retrain all layers. In PyTorch, we implement a subclass for the PyTorch to transform CheXpert Dataset and create a custom data loading process. The Image Augmentation is executed within this subclass. Additionally, a DataLoader also needs to be created. We shuffle the dataset for the training dataloader. We also create a validation dataloader, which is different from the training dataloader and does not require shuffling. In the baseline model, we use DenseNet pre-trained on the ImageNet dataset. The model&amp;rsquo;s classifier is replaced with a new dense layer and use the CheXpert labels to train &lt;sup id=&#34;fnref:11&#34;&gt;&lt;a href=&#34;#fn:11&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;11&lt;/a&gt;&lt;/sup&gt;. The number of trainable parameters 6968206 (~7  million).&lt;/p&gt;
&lt;h3 id=&#34;63-evaluate-the-model&#34;&gt;6.3 Evaluate the model&lt;/h3&gt;
&lt;p&gt;To evaluate the model, we implement a function to validate the model on the validation dataset.&lt;/p&gt;
&lt;h3 id=&#34;64-predict-the-pathologies&#34;&gt;6.4 Predict the pathologies&lt;/h3&gt;
&lt;p&gt;We use our model to predict 1 of the 5 pathologies - Atelectasis, Cardiomegaly, Consolidation, Edema, and Pleural Effusion. Our model uses a test dataset.&lt;/p&gt;
&lt;h3 id=&#34;65-calculate-the-auc-roc-score&#34;&gt;6.5 Calculate the AUC-ROC score&lt;/h3&gt;
&lt;p&gt;We have multiple labels, and we need to calculate the AUCROC-score for each class against the rest of the classifiers.&lt;/p&gt;
&lt;h2 id=&#34;7-results-and-analysis&#34;&gt;7. Results and Analysis&lt;/h2&gt;
&lt;p&gt;Figure 9 shows training loss, Validation loss and validation AUC-ROC score after training our Deep Learning model for 7 hours.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/Train.png&#34; alt=&#34;Figure 9&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 9:&lt;/strong&gt; Training loss, Validation loss and validation AUC-ROC score&lt;/p&gt;
&lt;p&gt;Figure 10 shows model predicts False Positives. Below is AUCROC table.
&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/roc.png&#34; alt=&#34;Figure 10&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 10:&lt;/strong&gt; AUC - ROC data&lt;/p&gt;
&lt;p&gt;This graph is taken from Stanford CheXpert dataset. Based on Figure 11 &lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;, our AUCROC value is around 85%.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/cybertraining-dsc/fa20-523-319/raw/main/project/images/aucroc_stanford.png&#34; alt=&#34;Figure 11&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Figure 11:&lt;/strong&gt; AUC - ROC Curve &lt;sup id=&#34;fnref:13&#34;&gt;&lt;a href=&#34;#fn:13&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;13&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id=&#34;8-conclusion&#34;&gt;8. Conclusion&lt;/h2&gt;
&lt;p&gt;Our model achieves the best AUC on Edema (0.89) and the worst on Plural(0.65). The AUC of all other observations is around 0.78. Our model achieves above 0.65 overall predictions.&lt;/p&gt;
&lt;h2 id=&#34;9-future-plans&#34;&gt;9. Future Plans&lt;/h2&gt;
&lt;p&gt;As the next steps, we will work to improve the model&amp;rsquo;s algorithm and leverage DenseNet architecture to train using smaller dataset.&lt;/p&gt;
&lt;h2 id=&#34;10-acknowledgements&#34;&gt;10. Acknowledgements&lt;/h2&gt;
&lt;p&gt;The author would like to thank Dr. Gregor Von Laszewski, Dr. Geoffrey Fox, and the associate instructors for providing continuous guidance and feedback for this final project.&lt;/p&gt;
&lt;h2 id=&#34;11-references&#34;&gt;11. References&lt;/h2&gt;
&lt;h2 id=&#34;12-appendix&#34;&gt;12. Appendix&lt;/h2&gt;
&lt;h3 id=&#34;121-project-plan&#34;&gt;12.1 Project Plan&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;October 26, 2020
&lt;ul&gt;
&lt;li&gt;Test train and validate functionality on PyTorch Dataset&lt;/li&gt;
&lt;li&gt;Update Project.md with project plan&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;November 02, 2020
&lt;ul&gt;
&lt;li&gt;Test train and validate functionality on manual uploaded CheXpert Dataset&lt;/li&gt;
&lt;li&gt;Update project.md with specific details about Deep learning models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;November 09, 2020
&lt;ul&gt;
&lt;li&gt;Test train and validate functionality on downloaded CheXpert Dataset using &amp;ldquo;wget&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Update project.md with details about train and validation data set&lt;/li&gt;
&lt;li&gt;Capture improvements to loss function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;November 16, 2020
&lt;ul&gt;
&lt;li&gt;Self review - code and project.md&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;December 02, 2020
&lt;ul&gt;
&lt;li&gt;Review with TA/Professor - code and project.md&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;December 07, 2020
&lt;ul&gt;
&lt;li&gt;Final submission - code and project.md&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Howard, Jeremy; Gugger, Sylvain. Deep Learning for Coders with fastai and PyTorch . O&amp;rsquo;Reilly Media. Kindle Edition &lt;a href=&#34;https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527/ref=sr_1_5?dchild=1&amp;amp;keywords=pytorch&amp;amp;qid=1606487426&amp;amp;sr=8-5&#34;&gt;https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527/ref=sr_1_5?dchild=1&amp;amp;keywords=pytorch&amp;amp;qid=1606487426&amp;amp;sr=8-5&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;An open source machine learning framework that accelerates the path from research prototyping to production deployment &lt;a href=&#34;https://pytorch.org/&#34;&gt;https://pytorch.org/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Overview of PyTorch Library &lt;a href=&#34;https://en.wikipedia.org/wiki/PyTorch&#34;&gt;https://en.wikipedia.org/wiki/PyTorch&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Introduction to PyTorch and documentation  &lt;a href=&#34;https://pytorch.org/deep-learning-with-pytorch&#34;&gt;https://pytorch.org/deep-learning-with-pytorch&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;The efficiency of densenet121 &lt;a href=&#34;https://medium.com/@smallfishbigsea/densenet-2b0889854a92&#34;&gt;https://medium.com/@smallfishbigsea/densenet-2b0889854a92&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Densetnet architecture &lt;a href=&#34;https://miro.medium.com/max/1050/1*znemMaROmOd1CzMJlcI0aA.png&#34;&gt;https://miro.medium.com/max/1050/1*znemMaROmOd1CzMJlcI0aA.png&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:7&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Densely Connected Convolutional Networks &lt;a href=&#34;https://arxiv.org/pdf/1608.06993.pdf&#34;&gt;https://arxiv.org/pdf/1608.06993.pdf&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:7&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:8&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Whitepaper - CheXpert Dataset and Labelling  &lt;a href=&#34;https://arxiv.org/pdf/1901.07031.pdf&#34;&gt;https://arxiv.org/pdf/1901.07031.pdf&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:8&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:9&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Chest X-ray Dataset &lt;a href=&#34;https://stanfordmlgroup.github.io/competitions/chexpert/&#34;&gt;https://stanfordmlgroup.github.io/competitions/chexpert/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:9&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:10&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Overview of AUC-ROC Curve in Machine Learning &lt;a href=&#34;https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/&#34;&gt;https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:10&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:11&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;PyTorch Deep Learning Model for CheXpert Dataset &lt;a href=&#34;https://www.kaggle.com/hmchuong/chexpert-pytorch-densenet121&#34;&gt;https://www.kaggle.com/hmchuong/chexpert-pytorch-densenet121&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:11&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:12&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Definition of Threshold &lt;a href=&#34;https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/#:~:text=The%20decision%20for%20converting%20a,in%20the%20range%20between%200&#34;&gt;https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/#:~:text=The%20decision%20for%20converting%20a,in%20the%20range%20between%200&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:12&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:13&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;AUCROC curves from CheXpert &amp;lt;&amp;gt;&amp;#160;&lt;a href=&#34;#fnref:13&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;

      </description>
    </item>
    
  </channel>
</rss>
